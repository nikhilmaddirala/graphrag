{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright (c) Microsoft Corporation.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas tiktoken graphrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search example\n",
    "\n",
    "Global search method generates answers by searching over all AI-generated community reports in a map-reduce fashion. This is a resource-intensive method, but often gives good responses for questions that require an understanding of the dataset as a whole (e.g. What are the most significant values of the herbs mentioned in this notebook?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.OpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load community reports as context for global search\n",
    "\n",
    "- Load all community reports in the `create_final_community_reports` table from the ire-indexing engine, to be used as context data for global search.\n",
    "- Load entities from the `create_final_nodes` and `create_final_entities` tables from the ire-indexing engine, to be used for calculating community weights for context ranking. Note that this is optional (if no entities are provided, we will not calculate community weights and only use the `rank` attribute in the community reports table for context ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"/workspaces/graphrag/nm-projects/asai/output/20240716-153628/artifacts/\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report records: 137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td># GPT and Related Entities\\n\\nThe community re...</td>\n",
       "      <td>4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>GPT and Related Entities</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community revolves around GPT, a versatile...</td>\n",
       "      <td>[{'explanation': 'Nikhil Maddirala provides de...</td>\n",
       "      <td>{\\n    \"title\": \"GPT and Related Entities\",\\n ...</td>\n",
       "      <td>a7fd871a-7311-4384-86ac-730b43f9ab3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td># Nikhil Maddirala and AI Technology\\n\\nThe co...</td>\n",
       "      <td>4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Nikhil Maddirala and AI Technology</td>\n",
       "      <td>The impact severity rating is high due to Nikh...</td>\n",
       "      <td>The community revolves around Nikhil Maddirala...</td>\n",
       "      <td>[{'explanation': 'Nikhil Maddirala is a key fi...</td>\n",
       "      <td>{\\n    \"title\": \"Nikhil Maddirala and AI Techn...</td>\n",
       "      <td>3379911d-8a50-4339-a5a4-58e1b1259711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td># Linear Regression and Home Price Prediction\\...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Linear Regression and Home Price Prediction</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community revolves around the topics of Li...</td>\n",
       "      <td>[{'explanation': 'Nikhil Maddirala demonstrate...</td>\n",
       "      <td>{\\n    \"title\": \"Linear Regression and Home Pr...</td>\n",
       "      <td>9fd58f28-de2a-463a-ac02-a9fdcfdac77c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td># Neural Networks and Discussions\\n\\nThe commu...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Neural Networks and Discussions</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community revolves around discussions rela...</td>\n",
       "      <td>[{'explanation': 'Nikhil Maddirala is a key fi...</td>\n",
       "      <td>{\\n    \"title\": \"Neural Networks and Discussio...</td>\n",
       "      <td>abcf7478-b4a6-42cb-a382-2f4e47a1749f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td># Machine Learning and Nikhil Maddirala\\n\\nThe...</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Machine Learning and Nikhil Maddirala</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "      <td>The community revolves around the concept of M...</td>\n",
       "      <td>[{'explanation': 'Nikhil Maddirala delves into...</td>\n",
       "      <td>{\\n    \"title\": \"Machine Learning and Nikhil M...</td>\n",
       "      <td>df56cb58-347c-43e9-ae6a-dc1d9f85be8c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       141  # GPT and Related Entities\\n\\nThe community re...      4   8.5   \n",
       "1       140  # Nikhil Maddirala and AI Technology\\n\\nThe co...      4   8.5   \n",
       "2       129  # Linear Regression and Home Price Prediction\\...      3   7.5   \n",
       "3       131  # Neural Networks and Discussions\\n\\nThe commu...      3   7.5   \n",
       "4       133  # Machine Learning and Nikhil Maddirala\\n\\nThe...      3   7.5   \n",
       "\n",
       "                                         title  \\\n",
       "0                     GPT and Related Entities   \n",
       "1           Nikhil Maddirala and AI Technology   \n",
       "2  Linear Regression and Home Price Prediction   \n",
       "3              Neural Networks and Discussions   \n",
       "4        Machine Learning and Nikhil Maddirala   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The impact severity rating is high due to the ...   \n",
       "1  The impact severity rating is high due to Nikh...   \n",
       "2  The impact severity rating is high due to the ...   \n",
       "3  The impact severity rating is high due to the ...   \n",
       "4  The impact severity rating is high due to the ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community revolves around GPT, a versatile...   \n",
       "1  The community revolves around Nikhil Maddirala...   \n",
       "2  The community revolves around the topics of Li...   \n",
       "3  The community revolves around discussions rela...   \n",
       "4  The community revolves around the concept of M...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'Nikhil Maddirala provides de...   \n",
       "1  [{'explanation': 'Nikhil Maddirala is a key fi...   \n",
       "2  [{'explanation': 'Nikhil Maddirala demonstrate...   \n",
       "3  [{'explanation': 'Nikhil Maddirala is a key fi...   \n",
       "4  [{'explanation': 'Nikhil Maddirala delves into...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"GPT and Related Entities\",\\n ...   \n",
       "1  {\\n    \"title\": \"Nikhil Maddirala and AI Techn...   \n",
       "2  {\\n    \"title\": \"Linear Regression and Home Pr...   \n",
       "3  {\\n    \"title\": \"Neural Networks and Discussio...   \n",
       "4  {\\n    \"title\": \"Machine Learning and Nikhil M...   \n",
       "\n",
       "                                     id  \n",
       "0  a7fd871a-7311-4384-86ac-730b43f9ab3f  \n",
       "1  3379911d-8a50-4339-a5a4-58e1b1259711  \n",
       "2  9fd58f28-de2a-463a-ac02-a9fdcfdac77c  \n",
       "3  abcf7478-b4a6-42cb-a382-2f4e47a1749f  \n",
       "4  df56cb58-347c-43e9-ae6a-dc1d9f85be8c  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build global context based on community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform global search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=False,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='width: 70ch;'>### Podcast Overview\n",
       "\n",
       "The podcast series delves into a wide array of topics within the realm of Artificial Intelligence (AI) and technology, featuring discussions involving prominent figures and entities in the industry. The podcast serves as a platform for exploring various facets of AI, its applications, and the implications of technological advancements on different sectors.\n",
       "\n",
       "### Main Topics Covered\n",
       "\n",
       "1. **AI Technology and Innovations**:\n",
       "   - Discussions on AI advancements, models, and applications.\n",
       "   - Exploration of AI technologies and their impact on different industries.\n",
       "\n",
       "2. **Key Industry Players**:\n",
       "   - Insights into the roles of influential figures like Nikhil Maddirala, Piyush Agarwal, and other tech giants.\n",
       "   - Interactions with companies such as Amazon, Apple, Google, and OpenAI.\n",
       "\n",
       "3. **Podcasting and AI Education**:\n",
       "   - Role of podcasting in disseminating AI-related content.\n",
       "   - Importance of AI education and knowledge sharing in the tech community.\n",
       "\n",
       "4. **AI Task and Email Classification**:\n",
       "   - Focus on machine learning and rule-based approaches in email classification.\n",
       "   - Significance of email classification in information processing and communication.\n",
       "\n",
       "5. **Historical Parallels and Technological Evolution**:\n",
       "   - Comparisons between historical events like the significance of fire in human evolution and the evolution of AI.\n",
       "   - Exploration of transformative technological advancements and their historical implications.\n",
       "\n",
       "### Key Takeaways\n",
       "\n",
       "1. **AI Ecosystem Engagement**:\n",
       "   - Active involvement of individuals like Nikhil Maddirala and Piyush Agarwal in AI applications, solutions, and technology discussions.\n",
       "   - Deep interest in exploring market trends and industry dynamics within the AI ecosystem.\n",
       "\n",
       "2. **Influence of Industry Leaders**:\n",
       "   - Impact of figures like Sam Altman, John Ivy, and Andrew Ng on the AI industry.\n",
       "   - Potential collaborations and partnerships shaping the future of AI technology.\n",
       "\n",
       "3. **Technological Advancements and Implications**:\n",
       "   - Discussions on Large Language Models (LLMs) and their influence on AI conversations.\n",
       "   - Critiques of LLMs, support for startups, and the evolving landscape of AI education and investment.\n",
       "\n",
       "4. **Community Interactions and Collaborations**:\n",
       "   - Interconnectedness of various entities like ChatGPT, Reddit, GEMINI, CLAUDE, and other AI-related communities.\n",
       "   - Collaborative efforts in exploring AI data retrieval, language models, and user interactions.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The podcast series serves as a comprehensive platform for exploring the multifaceted world of AI, technology, and their intersection with various industries. By engaging with key industry players, discussing cutting-edge technologies, and highlighting historical parallels, the podcast offers valuable insights into the evolving landscape of AI and its impact on society.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await search_engine.asearch(\n",
    "    \"Give me a full outline of this entire podcast including the main topics and key takeaways.\"\n",
    ")\n",
    "\n",
    "response = result.response\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f\"<p style='width: 70ch;'>{response}</p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inspect the data used to build the context for the LLM responses\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mcontext_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# inspect the data used to build the context for the LLM responses\n",
    "result.context_data[\"reports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 6. LLM tokens: 56271\n"
     ]
    }
   ],
   "source": [
    "# inspect number of LLM calls and tokens\n",
    "print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yfiles_jupyter_graphs\n",
    "\n",
    "Source: https://github.com/microsoft/graphrag/issues/418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install yfiles_jupyter_graphs==1.7.3 pandas notebook ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "entity_df = pd.read_parquet(\"/workspaces/graphrag/nm-projects/asai/output/20240716-171659/artifacts/create_final_nodes.parquet\")\n",
    "relationship_df = pd.read_parquet(\"/workspaces/graphrag/nm-projects/asai/output/20240716-171659/artifacts/create_final_relationships.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e088d6515cf24c728cb4871b86b269cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses yfiles-jupyter-graphs to visualize the dataframes.\n",
    "\n",
    "The dataframes are converted into supported nodes and relationships lists and then passed to yfiles-jupyter-graphs.\n",
    "Additionally, some values are mapped to visualization properties.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def show_graph(entity_df, relationship_df):\n",
    "    from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "    # converts the entities dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "    def convert_entities_to_dicts(df):\n",
    "        nodes_dict = {}\n",
    "        for index, row in df.iterrows():\n",
    "            # Create a dictionary for each row and collect unique nodes\n",
    "            node_id = row[\"title\"]\n",
    "            if not node_id in nodes_dict:\n",
    "                nodes_dict[node_id] = {\"id\": node_id, \"properties\": {col: value for col, value in zip(row.index, row.values)}}\n",
    "        return list(nodes_dict.values())\n",
    "\n",
    "    # converts the relationships dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "    def convert_relationships_to_dicts(df):\n",
    "        relationships = []\n",
    "        for index, row in df.iterrows():\n",
    "            # Create a dictionary for each row\n",
    "            relationships.append({\"start\": row['source'], \"end\": row['target'], \"properties\": {col: value for col, value in zip(row.index, row.values)}})\n",
    "        return relationships\n",
    "\n",
    "\n",
    "    w = GraphWidget()\n",
    "    # use the converted data to visualize the graph\n",
    "    w.nodes = convert_entities_to_dicts(entity_df)\n",
    "    w.edges = convert_relationships_to_dicts(relationship_df)\n",
    "    w.directed = True\n",
    "    # show title on the node\n",
    "    w.node_label_mapping = \"title\"\n",
    "    # map community to a color\n",
    "    def community_to_color(community):\n",
    "        colors = [\"crimson\", \"darkorange\", \"indigo\", \"cornflowerblue\", \"cyan\", \"teal\", \"green\"]\n",
    "        return colors[int(community) % len(colors)] if community is not None else \"lightgray\"\n",
    "    def edge_to_source_community(edge):\n",
    "        source_node = next((entry for entry in w.nodes if entry[\"properties\"][\"title\"] == edge[\"start\"]), None)\n",
    "        source_node_community = source_node[\"properties\"][\"community\"]\n",
    "        return source_node_community if source_node_community is not None else None\n",
    "    w.node_color_mapping = lambda node : community_to_color(node[\"properties\"][\"community\"])\n",
    "    w.edge_color_mapping = lambda edge : community_to_color(edge_to_source_community(edge))\n",
    "    # map size data to a reasonable factor\n",
    "    w.node_scale_factor_mapping = lambda node : 0.5 + node[\"properties\"][\"size\"] * 1.5 / 20\n",
    "    # use weight for edge thickness\n",
    "    w.edge_thickness_factor_mapping = \"weight\"\n",
    "    # Use the circular layout for this visualization. For larger graphs, the default organic layout is often preferable.\n",
    "    w.circular_layout()\n",
    "    display(w)\n",
    "\n",
    "show_graph(entity_df, relationship_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
