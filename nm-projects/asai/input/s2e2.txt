Piyush (00:00)
Like this is the iPhone moment of the AI enabled by Apple by building it into the iPhone. Wow.

Nikhil Maddirala (00:05)
For end users, this is like a great step forward. And it's probably a key turning point in AI's iPhone moment. But for almost everyone else in the AI ecosystem, it's probably really bad news.

Welcome to the Art and Science of AI podcast about the science of how AI works and the art of using AI to reimagine your life, business and society. I'm one of your hosts, Nikhil Madhiraala. I'm an AI product manager and I love helping people learn about AI.

Piyush (00:48)
And I'm your other host, Piyush, and I'm super curious about AI. And we're two best friends who love talking about AI. Nikhil, I feel like the whole world has been talking about just one thing over the last one week. That's Apple's recent event and announcements. And I've been extremely busy this week, so I didn't get a chance to follow exactly what happened, what they announced. So I'm very curious to just learn more about what is it that they announced. But there is one thing that...

Nikhil Maddirala (01:05)
Yup.

Piyush (01:16)
trickled into my consciousness. There's a meme that Elon Musk shared. I want to share this actually with you. I don't know if you've seen this, perhaps you have already seen this, but I love internet memes and I love so hard when I saw this meme. So it just, it was like one of the funniest memes I've ever seen. But I think like Elon Musk is saying that he's going to stop a ban Apple devices.

Nikhil Maddirala (01:23)
Okay.

Wait, before you do that, let's describe this for people who are listening to it. So, all right, let me try. So there's a picture of a couple and one person is drinking from a coconut. On the coconut it says iPhone and the person, the woman, it says Apple and supposedly Apple is trying to drink from the iPhone. And then there's a guy who has a straw into her mouth and it's drinking.

Piyush (01:43)
I don't even know how to describe it, do you mind describing what you're seeing on the screen?

Heheheheh

Nikhil Maddirala (02:08)
from that and it says your data and on the guy it says open AI. So I guess what he's saying is how Apple intelligence works is that Apple sucks your data out of your iPhone and then open AI sucks your data out of Apple. I guess that's what.

Piyush (02:24)
Whoever is listening to this, I'm telling you, no matter how you pictured this image, you cannot possibly imagine what we're seeing right now. So I would highly recommend just like looking at this one meme. But I mean, I found it hilarious, but I'm just like super curious to know like what's going on, like what did Apple announce? Why do they keep rebranding everything? Like there's already a word for AI, artificial intelligence. Why do they have to come up with their own brand name? But...

Nikhil Maddirala (02:31)
Hehehe

Yeah.

Piyush (02:53)
Yeah, and what is with the Elon Musk's apprehension? Is there some truth to it? So I'm just very curious. Can you help me understand what happened this week?

Nikhil Maddirala (03:02)
Yeah, I think these are great questions. Yeah, I think privacy is a big topic. We should definitely talk about that. Maybe let's just first jump in by talking about what Apple even announced this week and let's go through that and then let's talk about some of these questions about privacy, how it all works, and then we can think about what are some of the implications of this for users and for businesses and society. So.

Let's start by summarizing all the AI stuff Apple announced in their event last week. So the event for context is WWDC. It's called Worldwide Developer Conference. It's their annual event where they announce updates on their software side to their operating system and to their apps. And this is separate from the hardware event. So Apple has two major events every year. One is DubDub, as it's commonly known for WWDC.

That's the software event and then they have a hardware event later. And often what they do is they pre -announce some cool software stuff that they say is coming soon and that'll only work with the new hardware. In this case, they didn't do that. All the stuff they announced, it works with last year's iPhone. So that's the context of this event. And it's supposed to...

Piyush (04:12)
I didn't know that they had like two separate events, one's focused on software and one's on hardware. That's interesting. I didn't know.

Nikhil Maddirala (04:19)
Yeah. And technically when it first started, this software event was supposed to be focused on developers. That's why it's called worldwide developer conference. So it's really supposed to be for developers to know what are the new features coming out? How can I build cool apps using these new features? And then the hardware event was more focused on consumers, but over time,

Piyush (04:39)
interesting.

Nikhil Maddirala (04:41)
it's kind of morphed and even DubDub is like a big PR event. So they know that it's not just developers who are watching this, consumers, investors, everyone's watching it. So yeah, there's a lot of pressure to make it like a big event and announce a lot of things. And of course, like this is coming at the tail end of like a bunch of other companies, big events. We've seen Google, Microsoft and others have their big events. And this is kind of the last one of the season.

but it was probably the most, the one that has the most implications, I think, for the ecosystem. But yeah, we can talk about why, but let's jump into what they actually announced. Actually, I have a really cool video I wanted to share. So maybe let's break down the category of things. I would say there are like two main ways in which I would break down the stuff they announced. They organized their event differently. They went through it by...

Piyush (05:16)
really? Okay.

Nikhil Maddirala (05:37)
device and operating system. So they talked about like iPhone, iPad, watch, and they went through in that order. But since we're focused on AI, let's just cut through all that. And I'm going to break it down into two segments of things that they announced. First was they announced a bunch of new AI capabilities in their own apps. So there's things like making the calculator smarter, making mail smarter, making photos smarter. And we can talk a little bit about those.

But then the second type of thing they announced is making Siri smarter. And that's an AI assistant that works across multiple apps. So let's first talk about what they're doing in their apps to put AI in there. And then we'll talk about what they're doing with Siri and the operating system. The second one I think is a lot more interesting. Sure, shall we jump into it? yeah, so I think the coolest in the first category of things of like,

Piyush (06:27)
Yeah, what video are... yeah, what are we...

Nikhil Maddirala (06:34)
new AI features and apps. One of the coolest things they showed was the iPad calculator app, how it does handwriting recognition and math for you. So I'm going to share a quick video snippet from MKBHD's review of this. And let's start there.

So let's play this.

Piyush (07:12)
that's cool.

And the answer is also in your handwriting. That's so cool.

I was thinking exactly the same that how I wish that this was available when we're in, I don't know if Marcus Brown, he was learning all this in sixth grade, like he's some kind of a genius. I think we learned it much later in our schooling, but yeah, that would have been awesome. This is so cool.

Nikhil Maddirala (07:59)
Okay, let's pause there.

And this is what Apple does.

Hehehe

And this is the stuff Apple does really well, right? They don't, they're not the first to enter any new technology or new area, but when they do it, they do it in a way that just really delights customers. And this is, I think, a delightful customer experience. And like Marques said, I would love to be in school right now and have access to this tool. So yeah.

Piyush (08:27)
Hmm.

Hmm.

Yeah, that's true. Yeah, it is. Yeah, that's so true. Yeah, it is. It was delightful just watching him play around with it. So I can't imagine how it would be. Can I do like I have an iPad? Can I try it now? Like, is it is it something that's coming soon or?

Nikhil Maddirala (08:42)
Yeah.

I'm actually not sure, I don't remember if they said, and I don't know if it's something that works on all, you have an iPad with the Apple Pencil?

Piyush (08:59)
Well, I have a pencil.

Nikhil Maddirala (09:01)
I think it's possibly something that's only supported on the iPad Pro. I'm not 100 % sure. Okay, well, try it and report back. Yeah, if it works. So that was the first category of things they announced. Like I said, it's making their apps smarter with AI and infusing AI capabilities into a bunch of Apple's apps. And this I think was the coolest example of a...

Piyush (09:06)
I have a Pro. I have a Pro. And I have a pencil. I've never used a pencil. I have one. But now I won't use it. Okay, that's cool. That's awesome.

Nikhil Maddirala (09:31)
truly delightful customer experience. But some of the other things they announced was one is AI in the mail app. So if you're using the mail app on your iPhone or iPad or Mac OS, it does things for you like it can proofread emails you're writing, it can help you rewrite emails, it can help categorize your emails for you. So this is the kind of stuff.

that people are commonly doing with chat GPT, for example, you were talking about it at some point previously. You take an email, you copy it into chat GPT and you ask it to rephrase it for you. So now that's going to be done directly in the mail app and you don't need to go elsewhere to do that. That was really cool. Then they announced AI capabilities in the photos app. You can do things like cleaning up images. If you have an image and you have a random people in your background, say it's a family photo.

Piyush (10:01)
Yeah, I do that a lot.

Nikhil Maddirala (10:25)
You can just quickly remove other people. They also announced a thing called the Image Playground, where you can do image generation. You can create your own images and emojis. And so this is stuff that is not new to us, like people who have...

Piyush (10:39)
Yeah, I was just going to say it looks like Apple is just catching up like the email thing Gmail has had that for a while photos Google photos has had that for a while What was the last thing you mentioned? The playground Yeah Yeah

Nikhil Maddirala (10:45)
Right.

Playground and one other thing there are a few other examples nothing really mind -blowing like the calculator thing was the coolest but they also have some updates in Safari Where if you're reading an article it'll automatically give you highlights of the article and like I think it gives you a summary So you're right. This is stuff that like has been in many apps now, especially Google's apps They've been doing this a lot but Apple has been behind on putting AI features into these apps and

I think now they're doing it. And the advantage of that for users is that it's right there in the apps they already use and they don't have to go elsewhere to do these AI workflows. Like you were talking about.

Piyush (11:33)
And I guess they're very thoughtful about the implementation and to your point, like the way it is done, it's a delightful experience. So it's also done in a very elegant way. Right.

Nikhil Maddirala (11:43)
Yeah, that's true. And that's, I think, their unique strength and why customers love Apple. I use Apple myself as a user. I love their products.

Piyush (11:53)
Yeah, there's this thing that Warren Buffet once said about an iPhone. It's like, if someone paid you $10 ,000 to get rid of your iPhone, you still wouldn't do it. And which is why I think they're like Berkshire Hathaway so heavily invested into Apple. And it's kind of like against like the diversification principle, but he still is okay with it because, and it's such a nice way of thinking about it. Right. And that's true. Right. Like if I gave you $10 ,000, never to use an iPhone again, I feel like you wouldn't take that money.

Nikhil Maddirala (12:10)
Hehehe

interesting. I actually have many reasons why I wish I didn't use an iPhone. There are many things I hate about Apple. Actually, we'll talk about them later in this episode. The way they lock you into a closed system and don't let you choose alternatives. And I think philosophically, my company Meta is just very opposed to Apple's view on this. And...

Piyush (12:33)
Hmm.

Yeah, you're perhaps not the right person to ask this question, but like a normal person who like is a...

Nikhil Maddirala (12:45)
but I'm just saying consider that despite all that I'm still using the iPhone just because of the lock -in and the convenience like I use a Mac for work and then I got one of these Apple watches many years ago Yeah Yeah

Piyush (12:51)
right, right.

That's actually interesting. That is such a good point. Like despite that, you're still in the ecosystem that proves Warren Buffet's point. Yeah. Right.

Nikhil Maddirala (13:08)
is just like ecosystem lock -in. So for me to switch out, I would love to go and try an Android phone, but it's gonna be so disruptive to my workflow. My watch won't sync with it. I have these AirPods that work well with the iPhone and then it syncs between my Mac and I. So once you kind of get into the ecosystem, it's hard to leave and that's how they keep you and that's their strategy.

Piyush (13:28)
That's interesting. So the mode that Warren Buffet was explaining was more like brand love and just the passion that people have. But what you're explaining is the other side of it, which is just the lock -in aspect of the ecosystem. Everything just works so seamlessly. So, interesting.

Nikhil Maddirala (13:39)
The ecosystem lock -in, yeah. And I think they retain customers way better once the customers are using multiple Apple products and devices, because at that point it's just a huge inconvenience. And they also use a lot of proprietary tech that is not accessible to other people. So for example, the way the iPhone connects to the Apple Watch, no other.

Piyush (13:50)
Right. Yeah.

Nikhil Maddirala (14:05)
watch manufacturer can have that level of integration because they have this deep hardware and software integration and they don't expose that to third parties. In fact, there was recently a lawsuit about this. The Department of Justice in the US filed a lawsuit against Apple for being anti -competitive for exactly this reason. And one of the examples they cited was this. They said if somebody wants to compete in the watch market, it's really impossible because no one else can make.

a watch that's as good as Apple because Apple just doesn't expose those APIs that Apple Watch uses to other companies. So I can never make another watch that'll have.

Piyush (14:45)
Yeah, as you're saying this, I'm now reflecting back on what you said earlier about these companies like Humane and Rabbit wanting to make their own hardware is because they just couldn't do it on the iPhone, which is which would have been their preferred modality, right? Like they're just using an existing device as opposed to selling a new device, which is so difficult, like to get people to switch. But they had to because they don't have any options, right?

Nikhil Maddirala (14:58)
Yeah.

Absolutely, yeah.

Ahem.

Yep, so let's table that. Let's spend a lot more time on that when we come back to discussing the implications of this. Yeah, so there's.

Piyush (15:18)
Okay, so coming back to this, you said that they had two sets of anonymous. One set was integrating AI into already existing Apple apps, like the calculator, photos, and mail. And what was the other type of?

Nikhil Maddirala (15:31)
So again, this is my categorization. This is not how they framed it, but this is how I think is a relevant way for people to think about this distinction. The other one is AI in Siri. So Siri is becoming a really smart AI assistant that works across multiple apps. And here are some examples that they provided themselves. One example was they said, you can say, hey Siri, send the photos from the barbecue on Saturday to Piyush.

Sorry, this actually like woke up my, I'll stop saying that word. Yeah. Okay. But just repeating that, send the photos from the barbecue on Saturday to Piyush. So what that means is that the assistant is finding your photos that are relevant to the question, selecting the ones that are relevant and then performing an action for you, which is sending them to you. And I...

Piyush (16:03)
I don't have that problem because I'm an Android person.

So it's very contextually aware, like whoopie ooshies and like barbecuing and it's very cool. That's very cool.

Nikhil Maddirala (16:30)
Yeah, and it's a workflow across multiple apps. So that's one example. Another example they gave was play the podcast that Jamie recommended. So we have to find out what podcast Jamie recommended. Maybe he sent you a message, a text message or an email about this podcast and you have to find out what that is and then you have to perform an action.

Piyush (16:53)
You don't even have to mention like where, which app he recommended it on like that. I mean, wow, that's, that's cool. Like the Siri figures out Jamie and figures out all the way Jamie talks because like we both talk on WhatsApp, but we also text and then we like, I don't know, email as well. So like the Siri figured out.

Nikhil Maddirala (17:11)
Okay, so for let's put aside the question of like third party apps for now. That's a bigger question mark. Let's assume right now that all this is within Apple's app. So you're using iMessage to for your conversations, you're using Apple Mail for your emails and using Apple Podcast to listen to your podcast. So this stuff, what it can do is since all this, these apps are Apple owned apps and Apple has access to that data.

Piyush (17:18)
Right.

Okay fair enough.

Right, right.

Nikhil Maddirala (17:40)
they search through that data and find the relevant information to perform the relevant actions. So we talked about, and the last example, which is pretty cool is, I mean, it's similar to this, but it says, when is mom's flight landing? And imagine you have to go pick up your mom at the airport. And I've often had to do this. If I have to pick up someone at the airport, I have to first go through my messages. Often it's on WhatsApp or somewhere, and I have to scroll a while to see where did they send me the info about their flight.

And then I take that info, I copy it into like Google and look for like the flight status. And then I see the time. And then maybe I perform some other action after that. Like I open maps to navigate, or maybe I call an Uber or something like that. So it's kind of automating.

Piyush (18:10)
Yeah.

Yeah, no, that resonates with me. Yeah, that's same thing. Like I'll, whenever I have to go pick up my parents from the airport, like figuring out which terminal, which flight information, then I'll have to go back into my messages that we exchanged three or four months back when they shared the ticket or whatever. Right. And that is such a hassle. So yeah, that's awesome.

Nikhil Maddirala (18:45)
So think about the reason why you can't do that with existing AI solutions. Like if you use Chad GPT to ask this question, it wouldn't work, right? Like because Chad GPT, yeah.

Piyush (18:54)
You wouldn't know who my mom is. You wouldn't have history to like all my messages with my mom. Yeah.

Nikhil Maddirala (19:00)
Yeah, so what Apple is saying is that this has your personal context. It has your personal data and your personal context and it's using that. And last season we talked about AI agents, right? And they're based on having access to a knowledge base and then using that to perform, to get the relevant information and perform actions. So this is actually an AI agent. And it's the first, like I think,

full -fledged AI agent that consumers will have access to and I think that's really cool because so far the examples we've seen like Rabbit, Humane and others just haven't worked. They haven't been useful because they didn't have access to the relevant information or the ability to perform the relevant actions and both of these problems are being solved.

Piyush (19:49)
That's very interesting. You said actions. So, so far all the actions seems to be bringing up the information and displaying that.

Nikhil Maddirala (19:58)
No, remember we said when is mom's flight landing, right? So that you have to retrieve the information, which is like, what's the flight number, the date.

Piyush (20:07)
Right, right. I see. I understand. So technically that's an action because it's a retrieval. But when you say action, I'm also thinking of like book me an Uber.

Nikhil Maddirala (20:12)
Well, no, there's the second step of the action, which is looking it up on the flight status. Or we talked about other examples. It said send the photos from the barbecue on Saturday to Piyush. So sending photos is an action.

Piyush (20:26)
Yeah, that's a good one. I forget. Yeah. But can you do stuff that Rabbit promised that Rabbit R1 could do? Like book me an Uber.

Nikhil Maddirala (20:33)
Yes, so this is actually the, this does exactly what Rabbit promised. Like I said, for now, let's put aside the question of third -party apps. If you're limited to Apple's apps, it can do everything. It's like the Rabbit R1. It realizes the promise that Rabbit made about the large action model. It's a large language model combined with retrieval, augmented generation and action capabilities. So if you're limited to Apple apps, it can do all of that.

Piyush (20:42)
Okay, yeah.

That's very cool.

Nikhil Maddirala (21:02)
it finds the relevant context and then it performs whatever actions you need. So yeah, I think then the, I think this is kind of a huge like moment in AI's iPhone moment because.

Piyush (21:14)
Like this, it's so funny you said that I was thinking the exact same thing. This is AI's iPhone moment being enabled by literally iPhone. It's so funny. Wow.

Nikhil Maddirala (21:20)
Mm -hmm by the iPhone Yeah But think back to the iPhone moment, right?

We talked about that a few times in the past The iPhone came out in 2007 and when the iPhone first launched there was no concept of third -party apps It was only first -party apps. You would only use apps that Apple provided

And then the iPhone moment really came about or took off when third party apps, yeah, with the app store and with third party apps. And that's when we had apps like Uber and Airbnb and Instagram and all of those really famous iPhone apps that kickstarted the mobile era.

Piyush (21:49)
the App Store. Yeah.

I see now why you said earlier that this you believe that this is like one of those, because I was surprised when you said that. It's like, wow, that's saying a lot, right? That this is a big thing for the whole ecosystem. And I can see what you mean now. Like this is the iPhone moment of the AI enabled by Apple by building it into the iPhone. Wow.

Nikhil Maddirala (22:12)
Yeah.

But it's still questionable because, so as we said, in the iPhone, the entire power of that came from third party apps. Like if there are no third party apps, there would be no iPhone moment. Like, you know, if the world of the iPhone was limited to only things that Apple made, it would be like a fraction as useful, like 1 % maybe. Most of the great...

Piyush (22:45)
But I'm assuming because they announced it in Dubdub, as you said, and that that one's targeted more for the developers. I'm assuming that they also announced.

Nikhil Maddirala (22:52)
Yeah, so let's talk about the third party integrations now. So in this example, we said, when is mom's flight landing? And if the information was in messages or mail, Apple can go fetch that information and find the flight number. But what if you got this text on WhatsApp? You know, we both use WhatsApp a lot, like in India, almost everyone use it. How will Apple find that information? So for that, Apple is releasing their own API.

Piyush (22:55)
Right.

Nikhil Maddirala (23:20)
It's called the App Intense API and third party developers have to integrate with that API if they want their applications to work with Siri and work with the AI assistant. So, you know, if the information is in Gmail or it's in WhatsApp, right now, that's not going to be useful to me as a consumer unless Google and Meta.

decide to start connecting their apps and their data to this API.

Piyush (23:51)
Wow, interesting. How, like help me understand, do you know how it would work? Like in my mind, I'm envisioning like a rack type system where if a third party developer gave Apple access to this API, it would like somehow enrich the prompt or add to the context, whatever's available only within that third party ecosystem.

Nikhil Maddirala (24:08)
Yes.

Yeah, so that's exactly how it works. Regardless of whether it's first party or third party apps, the overall architecture is like that. When you make a request to the assistant, sorry, I have to prevent myself from saying the word. When you make a request to the assistant, it has to first go and figure out which apps and which relevant actions can be called, or they're called intents here instead of actions. And then,

Piyush (24:17)
Right.

intent, like I N T E N T not intense. got it. Wow.

Nikhil Maddirala (24:40)
intent yeah

no, yeah, it's like, I intend to do this. This is my intention. So it's about translating a user's request into intentions and actions. So one of the intentions is like search and retrieval. So the first thing you need to do is search and retrieval, find the relevant information. And then suppose you have to send a message, then the intent is something like send message. And Apple, their iMessage will obviously expose that functionality to Siri because it's their own app.

Piyush (24:56)
Right.

Right.

Right.

Nikhil Maddirala (25:13)
but whether WhatsApp and Gmail decide to expose that functionality to Siri depends on decisions they make about whether they want to integrate with this API or not. So.

Piyush (25:23)
Hmm. Hmm. That's very interesting. Wow. So that's that, that could enable the iPhone moment of AI, right? Like if a lot of developers start building and using the Apple Intense API.

Nikhil Maddirala (25:36)
It absolutely could. So maybe let's get to that question. Before that, let's dive a little deeper into the architecture. I think you had a good question about how does this work? Is this like a retrieval augmented generation system? So I have another visual I wanna share. I found this from a user on threads called CSPen. I don't know who this is, but he provided like a pretty good architecture diagram of how this works. Give me one sec.

Piyush (26:04)
Why are you pulling that up? Are there people who are exclusively on threads and not on other Twitter like things? I'm curious.

Nikhil Maddirala (26:13)
I have no idea. I don't like using Twitter. I never got into it. I just search it sometimes. I got into threads because obviously like...

Piyush (26:20)
You're a great meta employee. I hope Mark Zuckerberg listens to this podcast at some point. Like Mark, if you're ever listening, like this guy needs to be your like second in command or something. Like he loves meta and he's, he's like one of the smartest people I know, if not the smartest person I know. What are we looking at? And also just describe it as you keep going.

Nikhil Maddirala (26:35)
I would be honored if Zuck ever chose to listen to this podcast. But okay, we're looking at the architecture. yeah, right, yeah, let's describe it. This is the architecture of Apple Intelligence. I don't know actually if this is an official diagram that they provided or if this was made by this guy on threads. In either case, I think it's sufficient for our purposes. It explains generally how this stuff works. So the way it starts is first,

It's the request originates with a system wide experience. In this case, let's talk about the AI assistant and you provide a request to the assistant. You say something like, when is mom's flight landing? And then.

Piyush (27:20)
Right, that would be equivalent of a prom.

Nikhil Maddirala (27:23)
Yeah, yeah, it's the equivalent of a prompt. So that's the request. And then what it does is it looks up this thing called the app intense toolbox, where it's looking at what are the relevant intents that could help with this task. And simultaneously, it's also looking up a knowledge base that's called a semantic index here. So they are building up a personal knowledge base about you in this thing called a semantic index.

which is basically my understanding is that this is a vector database that stores vector representations of some text about you. This could be information retrieved from your messages, from your personal information and so on. So that's the retrieval part. And my guess is that if the information...

Piyush (28:11)
So hold on, I wanna make sure that we're going through this a little bit slowly so I can like reflect on what you're saying. So semantic index as I understand is Apple's understanding of your context in some sense based on like your personal context. App intense toolbox, help me understand what that is.

Nikhil Maddirala (28:18)
Mm -hmm.

Yes, of your personal context.

App Intents Toolbox is all the actions that apps can take. So the mail app will have some, let's just call them actions instead of intents, just to be clear. Mail will have actions like search, send, reply, those kind of things. So the, and.

Piyush (28:46)
Got it, got it, got it, got it, got it, okay.

Got it. Got it. Are these things an abstract version of actions or are they specific to apps? So for example, would Gmail send be an action separate from Apple's mail send or is this like a more abstracted version of an action?

Nikhil Maddirala (29:13)
It's a more abstracted version. So they provide some predefined intents and then each app can develop their own custom ones if they want. So if it's something like send email, that'll be probably a general action that many apps can use. But if there's something that's hyper specific to your individual app, then you can define a custom intent for that. So based on your request, the assistant is breaking that down into its components parts.

Piyush (29:18)
Okay.

Got it. Got it.

Got it, got it.

Nikhil Maddirala (29:42)
and trying to find the relevant information and retrieve like the relevant actions that are needed. And then, so there are three layers.

Piyush (29:51)
This is interesting. Sorry again. I apologize. I'll keep interrupting you because this is fascinating, by the way. So if you take a simplistic understand of RAG, which stands for Retrieval Augmented Generations, so far the retrieval was like one thing. But now there's like two categories of retrieval. There's your semantic retrieval, which is an understanding of you. And then there is a retrieval of the relevant actions based on the prompt or based on the system -wide experience.

Nikhil Maddirala (29:55)
yeah, of course.

Mm -hmm.

Yes. It's probably also semantic ultimately because the actions will have descriptions and it's probably going to be looking for which action is most closely similar to the request that you provided.

Piyush (30:32)
But what I'm trying to get at is like a fundamentally different type of thing that gets retrieved. It's an action.

Nikhil Maddirala (30:36)
Yes, that's right. And that's why like when the Rabbit founder released Rabbit R1, he was talking a lot about how there's this new thing called the Large Action Model, the LAM, and how that is specifically trained to perform actions. So yeah, this is a version of that basically. This searches through the list of possible actions from Apple's own apps and actions that have been exposed by third -party apps to find the relevant actions. And...

Piyush (30:46)
action model. Right.

interesting.

Very interesting.

very cool.

Nikhil Maddirala (31:05)
The models that are being used to do all of this, so there are a couple of different options here. So one is their on -device models. So Apple has made their own on -device models. These are...

Piyush (31:18)
Wait, so did Apple invent a foundational model, much like a Gemini and a GPT?

Nikhil Maddirala (31:23)
Yeah, so basically what we discovered through this announcement was yes, they've been working on their own foundation. I mean, I don't know if you would call it a foundation model, but these are large language models essentially. And they have two flavors of these. There are some models that can run on device. That means they're small enough that can fit on your phone. It has enough memory and processing power to run those models. Yeah.

Piyush (31:47)
Something like a Gemini Nano, right? Which is like an on -device, right?

Nikhil Maddirala (31:50)
I forgot what it's called, like Flash or NAND, yeah, something like that. So that can run on device. It can run small workloads. And then they also have larger models that they've developed that are going to be running on what's called the Apple Private Cloud. So that's the second layer. So what it'll do is it'll decide whether based on the complexity of the action, the amount of context that needs to be processed.

whether that can be processed by an on -device model or whether it needs to be sent to the Apple private cloud to be processed by a server model.

Piyush (32:27)
Wait, so that's very interesting. But like which entity is deciding that?

Nikhil Maddirala (32:33)
Yeah, so there's an on -device model that must be doing this orchestration. So it's called the orchestration in this diagram.

Piyush (32:40)
So that's that should be different from the on device. So, OK. So the thing that's deciding if it should be using an on device, LLM model or an on server LLM model, that thing is separate from the on device LLM model. Or is it the. OK.

Nikhil Maddirala (32:51)
Mm -hmm.

Yeah, it's separate. You can think like we don't know the exact details of this and we probably never will. This is proprietary to Apple, but at a high level we can infer that that sounds about right. That's a good way to conceptualize it. So think of it as a multi -agent workflow. So there's one orchestrator agent. What that agent is doing is taking the task and then maybe the orchestrator agent spins up two other agents. One is a retriever agent says go.

Piyush (33:07)
Right.

This is very interesting.

Right.

Nikhil Maddirala (33:27)
retrieve from the semantic index what context we can get, what data and information we can get that's relevant to this. Maybe there's an intent finder agent that goes and retrieves the relevant intents or actions.

Piyush (33:40)
Right. Can we use an example maybe that we talked about before? So let's take the example of the mom flight. Yeah. Yeah. Yeah.

Nikhil Maddirala (33:45)
Yeah, when is mom's flight landing? Yeah, when is mom's flight landing? Right? So...

Piyush (33:52)
So mom would come from the semantic index and retrieval of flight information perhaps would come from the.

Nikhil Maddirala (33:58)
Well, first this would have to be broken down into multiple different questions. So you would have to break it down into a question like who is mom? And then it would have to be broken down into like what flight is mom on? And then the next question would be what time is that flight arriving? So the first thing that has to be done is a breakdown of the relevant questions for any multi -agent system that that's a typical flow. So once it's broken down, probably what it's doing is it's assigning the right.

Piyush (34:19)
Interesting.

Nikhil Maddirala (34:27)
Agents for each of those tasks. So for who is mom that information is probably retrieved from the semantic index which has information about my Contacts and information we got from my mail and messages and so on so it retrieves that mom corresponds to so -and -so and Then the next question is like when is mom's flight? So this is where you have to search across your Mail and messages. So if you didn't specify where this information came from

probably it has to find all the places where this information might be. That includes mail, messages. And so depending on how many messages you have and how many seem relevant, if there are only a small number of messages retrieved that seem relevant to this question, probably it could do this computation on device. But probably if you retrieved like a large number of emails,

Piyush (35:18)
Ahhhh, got it, got it. Okay, okay, okay.

Nikhil Maddirala (35:25)
And then it cannot be done on device then it would send it to the server and that's where it gets processed. So it Depending on the workload. It's either on device or in the server and This is where the privacy angle comes in because if something is done on device That means your data is totally private is never leaving your device your data The messages the raw data itself is on your device

Piyush (35:30)
Right. That makes a lot of sense. Okay. Okay.

Nikhil Maddirala (35:53)
Actually, it's not clear depending on if you have iCloud sync enabled, then your messages and mail could also be on.

Piyush (35:59)
Well, the pro no, but I get your point. The processing of that is done on device. Like maybe you'll get some data from your iCloud, but the inference of that will happen on device.

Nikhil Maddirala (36:07)
Yeah, so this index, yeah. Yes, and the index is stored on your device. So yeah, if it's done on device, it's totally private. There's no risk of your data being leaked to any third party. So, but in the second case, if it decides that this task is too complex and I have to go and run a model on the server to answer this question, then it does what's called a

Apple private cloud. And that is not entirely clear what it is, but what they're claiming is that it's a version of cloud computation, which is as secure as on device. They say that as soon as your data is processed, it's like immediately deleted after that. And I think they're using this concept of a trusted execution environment where they can, they published externally verifiable

papers that other people can prove that this is actually what's happening over there. So there, I don't understand like the details of the cryptographic protocols involved here, but there are ways to externally verify that what you're saying is happening is actually happening without looking into the data itself. So I think.

Piyush (37:25)
Right. Yeah, there's a concept. This is reminding me of a concept from the blockchain ecosystem. It's something like a zero zero trust. I forget the name of it, but it has a zero in it. Anyway. Yeah.

Nikhil Maddirala (37:38)
Yeah, it could be zero trust, but yeah, they're all based on some cryptographic protocols which enable you to verify something without actually looking into that thing that you're verifying. Like passwords, for example, are like that.

Piyush (37:43)
Right, right.

Yeah. Yeah, yeah, I remember. Yeah. Yeah, yeah, yeah. I know about this concept. The founder of Ethereum, his name is Vitalik Buterin. I don't know if you've heard of this guy. He's like a genius, right? You can actually see his body's energy being used up by his big brain. Anyways, he was talking about this whole idea of like...

Nikhil Maddirala (38:01)
Yeah.

Piyush (38:10)
and validating and proving something without revealing what that thing is. And there was some innovation in that in the blockchain ecosystem. So yeah, I have an intuition for what you're talking about. Yeah.

Nikhil Maddirala (38:15)
Hmm.

Okay, so that's what's going on in the Apple private cloud. So either the task is small enough that they can do it on device, your data never goes anywhere else, or the task is sufficiently complex that it needs to be running on the server model, in which case it goes to Apple's private cloud. And I guess like coming back to this meme and Elon's question,

Piyush (38:44)
I was just going to say that what Elon Musk's problem with this?

Nikhil Maddirala (38:46)
Yeah, so there's one part of this that is not represented in this diagram and that's OpenAI. So if Apple determines that this question cannot be answered neither on device nor on its private cloud with its own models, then it will send the query to OpenAI to a third party model, but only with your permission. So it'll always prompt you. It'll say, hey, we're going to send this query to OpenAI. Can we do that or not? And you will have to say, okay.

Piyush (39:05)
Bye.

every time or is it like a blanket approval that hey we might

Nikhil Maddirala (39:16)
and it'll do that.

It's unclear right now what kind of settings they'll offer. Maybe it will be every time. Hopefully there will be some blanket approval.

Piyush (39:25)
that makes sense now. So like Elon Musk's worry is that that data going to open AI. Well, actually I'm curious about this. If I'm prompting something to chat GPT does, I have two questions. Yeah. Okay. So I have two questions about this. If I, if I'm talking to chat GPT, one is my prompt.

Nikhil Maddirala (39:41)
Mm -hmm here. I'm gonna stop sharing this. I think we don't need it anymore. We can keep talking

Mm -hmm.

Piyush (39:54)
completely private, like how WhatsApp has end -to -end encryption, meaning WhatsApp has no visibility into the chat between Nikhil and Piyush, right? End -to -end encryption. And number two, if it's not, then could the LLM foundational model, or in this case, GPT -440, learn from what I asked in the prompt?

Nikhil Maddirala (40:01)
Mm -hmm.

Okay, yeah, so let's go through these step by step. The first question you asked, it's kind of complicated because you get the example of in WhatsApp, your chat between Nikhil and Piyush is encrypted and that means that nobody other than Nikhil and Piyush can read that. But in this case, your chat is between you and chat GPT. So chat GPT is the other person on the chat.

Piyush (40:37)
Yeah, I guess that's a wrong analogy. What I'm trying to say is like, does does OpenAI discard my prompt once it's been used or like can they?

Nikhil Maddirala (40:45)
No, it so okay. They have different levels of plans that they offer. There's the free plan and then there's a consumer pro plan and then there's an enterprise plan. I think as far as I know, only the enterprise plan has the guarantee that your data will not be used for training their models. So if normal consumer plans, whatever.

info you're sharing with OpenAI, they are absolutely saving all of that. And they use that as further training data for their models. And not only is it that they're using it as training data, it just exposes you to a security risk that if somebody hacks OpenAI servers at some point in future, like your data could be breached as a result of that hack.

Piyush (41:34)
interesting. And when you say that OpenAI could potentially use my prompt for training data. okay. Do you mean that in the next training batch for GPT -5 or do you mean that when the model runs an inference, and by the way, I don't know what running an inference is at some point, I would like to understand that, but I know.

Nikhil Maddirala (41:39)
they will definitely use it. It's not good potentially. Yeah.

Okay, this is really simple. Running an inference is just like getting a model output. That's all it means. Yeah.

Piyush (42:03)
Okay, so my question is in doing so does the model digest it and update the foundational model? Okay, okay. Okay, so nothing happens to its knobs and dials or the parameters. Okay, okay.

Nikhil Maddirala (42:10)
no, it's not immediate. Like you're just interacting with a pre -trained model. So -

not in the moment, it's just later as they go through the next iteration when they're like we're making GPT 4 .5 or five or something, they'll be informed by this data. But I think maybe I don't know if I would be so worried about my data being used to train that model. I mean, sure, that could be concerning, but I think the bigger risk is that just your data is there sitting on their server somewhere and it's just there. You know, it could be misused if somebody hacks.

Piyush (42:23)
Right.

Right, right, right.

Got it.

Nikhil Maddirala (42:46)
OpenAI, they would get access to it. They could further misuse that data. So, so there are both of these risks, I guess. They're, they're both.

Piyush (42:51)
Got it. Elon Musk worry that if the orchestrator decides to send this request from an Tesla employee potentially to OpenAI, Tesla is vulnerable to OpenAI one, having access to Tesla employees prompt data and two, OpenAI training the next models on said data.

Nikhil Maddirala (43:12)
Mm -hmm and whatever context. Yeah. Yeah, that's true. But I mean, I don't know how much sense it makes. Tesla employees are probably already using OpenAI and Chad GPT. Sure, so this is a legitimate concern, but I think it's based on a misunderstanding that by default Apple is going to do this. And as we just saw, that's the third step and the last resort. Let's think about like.

how often this may happen. We don't have any data, but if I were to guess, I would use this 80 -20 rule. And I'd say first, you figure out can it be handled on device or not. Maybe 80 % of the requests are handled on device and 20 % are sent off device. And then out of the off device requests, probably 80 % of those can be handled by Apple's private cloud. Only 20 % of those are sent to OpenAI. So 20 % times 20%, that's like four.

Piyush (43:57)
writing.

Yeah. I mean, let's play the devil's advocate here on the 80 -20. I completely agree with you. One could also make an argument that the types of requests that you'd be most worried about not sharing are maybe the more complicated ones that would largely be representative of the ones that go to a third party model. Right? I don't know. Maybe.

Nikhil Maddirala (44:26)
Okay, let's actually talk about what goes to a third party model. And Apple actually hasn't been very explicit about what determines this decision. One of the main things they've been talking about in their presentations on this is that if your question only needs personal knowledge, you don't need to send that outside. But if your question needs world knowledge to answer, then they'll send it to an external third party model provider like.

Piyush (44:30)
Okay.

Nikhil Maddirala (44:55)
So if you're asking some general knowledge, and actually I think it's inverse then, it's less likely that personal questions that involve your sensitive data are going to be sent out because that's more for like things that require world knowledge.

Piyush (45:07)
Interesting that makes sense. Yeah, that makes a lot of sense is is open ai The first partner to have been offered this option or is it an exclusive partnership or could tomorrow? Google's gemini be one of those models that the orchestrators like all now figure out like which is the best third party model

Nikhil Maddirala (45:27)
Yeah, that's a good question. We don't know the details, but here's what we do know. There was a lot of speculation before about who's paying who in this relationship. Is Apple paying OpenAI or is OpenAI paying Apple? And I think now mostly the consensus is that it's not, that Apple is definitely not paying OpenAI for this, that it's either happening for free.

Piyush (45:50)
Yeah, OpenAI should be grateful that all Apple devices are now there. Like Google pays, I don't know if you know this, Google pays billions of dollars to Apple for Apple to set Google search as the default search engine.

Nikhil Maddirala (46:06)
Yeah, this is a very famous thing. In fact, I think it's something like 20 billion dollars and it corresponds to... Right.

Piyush (46:11)
Yeah, it's called a traffic acquisition cost in the industry. And it's yeah, it's it's in the order of magnitude of tens of billions of dollars. So you're right. So like.

Nikhil Maddirala (46:19)
And actually what's more interesting is that it corresponds to about 30 % of the revenue that Google generates from that search traffic that's coming. Right.

Piyush (46:29)
Yeah, because I work in Google Ads. I know a lot of things, but I can't obviously share, but you're right. I mean, think about it. Apple users are presumably slightly more wealthy than Android users just because of the range of Android prices, right? So in the world of digital advertising, which you're also a part of, a lot of the buys happens on the potential of the audience.

Nikhil Maddirala (46:39)
Yeah.

Piyush (46:55)
or their wallet, right? So like that makes sense. And that's why Google is willing to pay so much money. So let's just leave it at that.

Nikhil Maddirala (46:58)
Mm -hmm.

No, I agree with that. I think in this case that may very well be the case actually that Apple shopped this around to various people and took the highest bidder or maybe

Piyush (47:12)
I wouldn't be surprised if OpenAI is paying for a service that Apple is using. Because Google is that's what it's doing, right? Google's providing a search service to Apple's users and paying for it. Like that's Apple.

Nikhil Maddirala (47:16)
Yeah.

right.

Yeah. Yeah. That's true. But I mean, Google is monetizing that, right? I think the main difference is that like OpenAI doesn't really have a good way like Google of monetizing these queries. Yeah. True. Not yet. Yes, that's true. So actually, you're right.

Piyush (47:30)
Very good, I understand.

Not yet. Not yet. But they have distribution now, like at the scale of Apple. But I don't know. So you said consensus, meaning no one knows what's going on.

Nikhil Maddirala (47:46)
I meant the consensus of expert opinions on this. I think is more aligned with what you're saying that definitely people believe that Apple is not paying OpenAI. That's not happening here. It's quite likely that OpenAI is paying Apple for this, for the distribution rights. I don't know why they would be doing that. I'm not sure. It will be interesting to see what is their monetization model.

Piyush (47:58)
Yeah, yeah.

Like branding, right? Like it just, look, we're answering what Apple can't answer. Like that's a great storyline, right? Yeah.

Nikhil Maddirala (48:16)
Yeah, but it's coming at a huge cost because they're paying for all the requests that are coming from the Apple users. Yeah.

Piyush (48:23)
Yeah, maybe some smart people have done the cost benefit analysis that having your brand being positioned like that for like in front of the world or being part of this AI's iPhone moment or enabling that just is worth it in the short.

Nikhil Maddirala (48:38)
But one thing that is very clear is that Apple 100 % has the clear upper hand in this relationship between Apple and OpenAI. Yeah.

Piyush (48:46)
they own the orchestrator.

Nikhil Maddirala (48:49)
And they only, even if you look at how this happened in the presentation, they literally mentioned it just at the very end as an afterthought after they went through all of their AI and the AI assistant and on device and private cloud. And at the very end, they said, and for some queries that require world knowledge, we're going to send them to, open AI. And they also clearly said that this is not exclusive, that in future they will also be integrating other.

third party model providers. And for example, Sam Altman was invited to this event and he was like tweeting from there, but he was never invited on stage to come and talk about this partnership or anything like that. So.

Piyush (49:30)
Yeah, maybe that's because he's apparently been in talks with John Ivy. You know, the British guy who used to come for all the, yeah. yeah. Sorry. My bad. Yeah. Johnny Ive and presumably they're working on some kind of a competitor to the iPhone. Right. So, I mean, I mean, one thing that definitely can be said is this is such an interesting space that's like developing in front of our eyes and yeah, it's just the way it's blowing up. All right. Let's come back to the iPhone moment.

Nikhil Maddirala (49:35)
Johnny Ive. Yeah.

okay. Okay, that's possible.

The implications. Yeah, okay.

Piyush (49:59)
Yeah, the implications, right? That's why I'm coming back. So first of all, thank you so much. The architecture is now like, yeah, I have a good intuition for what's happening under the hood. And I also understand what Elon Musk's apprehensions were. But I want to come back to like what you said. It kind of caught my attention. Is you think that this is a big, like big thing for the ecosystem. So like coming back to like the art and science, I feel like you did such a good job of explaining the science of it, like under the hood.

Nikhil Maddirala (50:18)
Mm -hmm. Yeah.

Piyush (50:27)
So as a business or as a developer, what's the art of how do I use this? Or I don't know, what is the art behind it? What is the art of this now?

Nikhil Maddirala (50:36)
Yeah, so in terms of how you can use this, right? Let's think about it from two perspectives. First is the end user and second is like the rest of the ecosystem. For end users, this is like a great step forward. And like I said, it's probably a key turning point in AI's iPhone moment. But for almost everyone else in the AI ecosystem, it's probably really bad news.

Piyush (50:43)
Mm -hmm.

Nikhil Maddirala (50:59)
Let's talk about why this is great. So I think you can...

differentiate between three levels of AI, each of which is better than the previous level. The first is like a standalone freestanding AI, which is like a chat GPT or Claude or whatever, where you go and just have a chat experience with it. It has no context about you, your workflow or anything like that. So that's like the most basic form of AI. Second is AI integrated into specific applications. So like we saw these examples of

the calculator app, the mail app. In that case, it's better than the freestanding version because it has context of that specific application. If I'm writing an email, it has that email. It probably has my previous emails. It has all that context, so it's more powerful. But still it doesn't... Yes, exactly. So the holy grail of like making AI...

Piyush (51:48)
but context only limited to that particular app.

Nikhil Maddirala (51:56)
useful and a true AI assistant is an AI assistant that's integrated into your overall workflow and knowledge base. Like that's a real AI assistant. And that's what companies like Rabbit and Humane were trying to deliver, but failed. And now...

Piyush (52:10)
Why is Google sleeping on this? They had Google assistant, which is like, I don't understand. Like they invented the T in chat GPT. Like Sundar announced that Google is going to be an AI first company in 2016. Like why isn't this in Android?

Nikhil Maddirala (52:19)
Yeah.

That actually is a bit odd. There were rumors earlier about something called Pixie, P -I -X -I -E, that Google was supposed to release for Android. That's very similar to this. But I don't doubt that Google will very soon release something like this. I don't think it's...

Piyush (52:40)
Yeah, I would love to see that. Like this would be so great for the ecosystem. And I love Android. I love Google. Like I want to see the same thing being done by other players as well.

Nikhil Maddirala (52:45)
Yeah.

Well, let's talk about like why this is actually potentially a bad thing. Let me start by talking about how this is. Yeah, the negative implications for it. So first of all, we talked about the fact that no one else can do this. Like if I'm a company and I decide, I have a great idea for an AI assistant, there's no way for me to do that. Apple just won't let any other AI assistant do this. So the only.

Piyush (52:57)
Hmm. What is the bad thing? Like other, like Google also doing some things.

Nikhil Maddirala (53:18)
entity that can have access to the semantic index and these workflows is Siri. No one else gets access to that. So it is fundamentally a closed model. It's a closed system. And that is something that I think is concerning. Actually, before we get into this in more detail, I want to play another video clip about some of the concerns regarding closed models. Give me one sec.

Piyush (53:29)
Right. Right.

Yeah, but I see what you're saying. Yeah, that makes sense.

Nikhil Maddirala (53:45)
Ahem.

Give me one sec, let's find this one. Okay, so this is a podcast interview that Mark Zuckerberg did with Dwarkesh Patel. It's a pretty cool podcast. This was about a month or so ago. And here's what he says about open versus closed systems.

Piyush (53:52)
The only say that the third party apps would have is this API.

Wow, that is so Christian.

Nikhil Maddirala (55:12)
I can stop there. So this is...

Piyush (55:14)
That is so Christian. I was saying like that what he said, if he said this just a month before the announcement, I mean, being in his position, he probably had an intuition that this is about to come. But yeah, that is so relevant to just literally what we talked about five minutes. Right.

Nikhil Maddirala (55:26)
That what he said is this closed model. There are a handful of companies that control the models and more importantly, that control the closed APIs that everyone else has to just use. And if you either follow their rules or you don't get to exist.

And I think this is the fundamental problem with these closed systems. And this is something that Zuck has been taught. I mean, he didn't even need to know.

about this announcement, if you just understand Apple's philosophy, it was like always obvious that this is how they're gonna do it. Like just think of examples in the past, like this is my frustration with the iPhone, like you can't choose your default apps. Like I love using Google Maps, for example, instead of Apple Maps, but yeah.

Piyush (56:10)
Really? You couldn't set Google Maps as default? Because Apple Maps sucks.

Nikhil Maddirala (56:15)
I mean, default has multiple aspects to it, but there's some privileged access that only Apple Maps gets. For example, if you're navigating somewhere and your phone is locked, it'll show you the navigation on your lock screen. But that privilege, no other app can have, only Apple Maps. So if I use Google Maps, that means I have to give up this quality of life feature. Similarly, they privilege their own photos over Google Photos or other apps. So in general, it's a...

Piyush (56:22)
Mmm.

Nikhil Maddirala (56:43)
closed model. They don't, they have their own integrations.

Piyush (56:47)
It's anti -competitive, it's not good for the end consumer.

Nikhil Maddirala (56:51)
I agree with this, but I do also want to provide the other side of the argument just to be fair to Apple and the yeah, which is privacy and security, which is that if they open this up and they said Rabbit can make their own assistant app or let's even take the example of like OpenAI can make their own assistant app that can do all the stuff Siri can that presents a pretty large risk to Apple that your

Piyush (56:59)
Privacy angle.

Nikhil Maddirala (57:19)
personal private data is being used by OpenAI and stored on their servers and

Piyush (57:23)
Yeah. No, that's such a good point. And I want to, I want to be very balanced in this podcast. You said some very nice things about meta and I know you love meta, but there was a time where that Cambridge Analytica scandal happened and essentially it was just the leakage of private data and people use that to like manipulate people's, I don't know, like intuitions and drive consent or whatever. So having this semantic understanding and like, is so powerful.

Nikhil Maddirala (57:38)
Yeah, that's true.

Piyush (57:53)
And if the wrong third party app had access to it, I can't even imagine what it would be like. Like back when Cambridge Analytica had, we didn't have LLM. So we just had certain data points and it was more statistical, but now it's more semantic and yeah. What is the solution to this? This is, so I see both sides.

Nikhil Maddirala (57:53)
Yeah.

I agree, this is a huge risk. So...

I mean, my preferred solution is give users the choice. If I'm fine with accepting the risks of my data going to OpenAI, I should be allowed to do that. And you can set as a default that look by default, you can't do this. You can only use Apple's solution, but provide me the option. Bury it somewhere in settings and say, hey, if you click this option is really, really dangerous, please don't click this option. You can put whatever text you want, but like I still want that option.

to click that button and say, is my data, like, I want to take the risk. Sorry, Stim Flossia is what? Cigarettes, yeah.

Piyush (58:43)
Like cigarettes, basically, you're saying apply the same philosophy that's applied to cigarettes. Yeah. Cigarettes basically has like a very obvious warning, like a graphic warning. Right. So you're saying something on the similar lines. Let's just make it very obvious that this is going to send them like it's going to basically send an understanding of what you are as a person to this third party. Are you OK with that? Yeah. Yeah.

Nikhil Maddirala (59:08)
Yeah, yeah. And actually recently, so Microsoft, I mean, I think the general theme I'm trying to make here is that AI assistants are kind of dead and no one else can do this except the operating system and ecosystem like controllers. That's Apple, Google, Microsoft. So there are these three big companies that are gonna be in control of this. Historically, desktop platforms have been more open and mobile platforms have been more closed.

But recently there was an incident. So Microsoft had their own version of an AI event a few weeks ago where they announced something kind of similar though a little less sophisticated. It was called Copilot PCs. And one of the, so they introduced a new line of hardware which has a bunch of on -device AI and machine learning on it. And one of the things that it does is this feature called Recall where,

It remembers everything you're doing on your device. It periodically takes some screenshots and then you can ask it questions like, last week I was browsing this website. Remind me what website that was or like, you know, yesterday I was on a call with this person. Remind me what time this was, what happened in that call, those kinds of things. And they recently got hacked, I think. And some of that data got breached. And imagine this is like very...

private data, like if it's taking screenshots, maybe I was entering my password in that screenshot, maybe I was having my financial institution or like some health record like on my screen at the time and they were capturing this data and for whatever reason they didn't implement good security practices. So anyway, now they rolled that back. Previously it was on by default and now they've made it an explicit opt -in.

Piyush (1:00:44)
Right, right.

Nikhil Maddirala (1:00:57)
And also I suspect as a result of this, what's going to happen is that they're going to lock down that access and say only Microsoft can access this data and use the, so I think we've been focusing a lot on the data part, but this control applies not just to data, it's also to like the control of the actions. So I can't like, yeah, I can't make a third party assistant that can compete with Siri. Apple just won't allow that.

Piyush (1:01:17)
Yeah, yeah, yeah, yeah, the intent.

Nikhil Maddirala (1:01:25)
So again, going back to the question about rabbit and humane, they could have just said, hey, let me make an asset. And even if they say, look, I don't want to use any personal data, just let me do some actions, let me perform actions for the user. Apple doesn't allow that. I think Google is slightly more open than Apple with Android, but even they are pretty strict about this. So yeah, I think we're actually heading to the world that like Zuck was describing, which is that AI is just...

further entrenching the power of the large players that control the existing ecosystems. And it's just going to make them more powerful, I think. And some of the implications of that are, one, it's the commodification of models. So now you can see that model providers are becoming almost irrelevant. So Apple talked about how there's chat GPT with OpenAI. That's one provider. Soon there'll be others.

Piyush (1:02:20)
Right, right.

Nikhil Maddirala (1:02:20)
probably there'll be some open source options and many others. And really the user interface is being controlled by Apple and that's just something that's happening on the backend. So they're making it irrelevant. They're making the thing that's prominent is your user experience and interaction with Siri. And the model is just like, some backend like stuff. You don't need to worry about that. I think that's a clear threat. So, and this is something...

Piyush (1:02:38)
Right.

Right, right, right.

Wait, why is that a thread? Why is that a bad thing that the models are commodified? Is commodification inherently a bad thing?

Nikhil Maddirala (1:02:53)
yes, for the companies that are getting commodified, it is a bad thing because if you're a commodity, that means you're undifferentiated and then like you can't charge, you have no pricing power, you have no market power because you're...

Piyush (1:03:07)
But it's good for the consumer, no? Like maybe it's, and maybe you can innovate on like a computational power or I don't know, like making it cheaper or something. Yeah. I see why it could be bad for like, right.

Nikhil Maddirala (1:03:11)
OI

I agree with this. No, no, I didn't mean it's bad. So I started by saying, I think this is great for consumers, just bad for other people in the ecosystem. So model providers is one. And we talked about this even in the last season, which is that I don't think there's like a decent, a defensible competitive moat you can build around being a model provider. Even if you're at the cutting edge, your main advantage is like, I'm six months or 12 months ahead of the other guys.

Piyush (1:03:26)
Right.

Right, right. Got it. Got it.

Nikhil Maddirala (1:03:47)
because the other guys are gonna catch up with you in six to 12 months. There's not much differentiation in models now.

Piyush (1:03:49)
Yeah. Yeah. Yeah. So what is the opportunity here then for budding entrepreneurs or for aspirants in the ecosystem?

Nikhil Maddirala (1:04:01)
Yeah, actually, if you're talking about doing something specifically with AI, I think this is bad news.

Piyush (1:04:07)
No, let me be more specific in my question. So they announced this in DubDub, as you said, it's meant for developers. What is the opportunity for me? And I'm fine. Like there's things to check and control things which I can control. And there are things that are just beyond me, right? Like this whole, this ecosystem war and all of that is beyond me. But can I do something as an entrepreneur based on these announcements? Like what?

Nikhil Maddirala (1:04:12)
Yeah.

Okay, so let's think about if you're an app developer, you have some popular app on the app store right now, the main decision that you're faced with now is should I integrate with Apple Intelligence or not? That's the main thing you have to decide right now. And I think it will be really interesting to see the decisions that various app developers are making in this regard, because so far, most apps have been providing their own AI solutions within the product.

And they've been trying to like upsell that as an add -on. Often it's like, you have to pay a few dollars extra to get this AI. So, you know, there's like Notion AI, there's Adobe Acrobat AI, there's AI in so many apps. And what they're saying is that, look, we will make this app like AI enhanced for you and you pay us a little extra. I think that's probably going away now because, I mean, well, whether or not it's going away depends.

Piyush (1:05:19)
Really? Well, I mean, yeah, I see what you mean. I mean, it'll stay for some like for Adobe, for example, it's such a nuanced thing. It'll maybe stay because like editing images or videos with AI, you might.

Nikhil Maddirala (1:05:31)
sorry, I was talking about Adobe Acrobat AI, which is for the PDFs.

Piyush (1:05:36)
And what's the feature that it enables the acrobat?

Nikhil Maddirala (1:05:39)
It enables you to chat with your PDFs. You can ask questions. You can say, if you store all, say, you store all your PDFs in Acrobat.

Piyush (1:05:42)
right, right, right.

Yeah, yeah, I agree with you. I think that's going to go away. Yeah. I mean, it's just going to be, Hey Siri, what am I looking at? Like, Hey Siri, help me summarize what I'm looking at or something like that, which is a much, much, what was the word you used? Delightful user experience then opening that thing from Acrobat and whatever modality Acrobat provides for you to ask that.

Nikhil Maddirala (1:05:53)
Exactly.

Yeah. And also things like Notion AI, like again, it's all this text based stuff, right? Where the people are providing. So what is Notion AI doing? Notion AI enables you to find relevant notes. You can chat with your notes and second, it enables you to have better writing experiences. You can say improve this draft that I'm writing. Now Apple is putting that at the operating system level and it's saying, Hey Notion, you just need to expose your...

Piyush (1:06:10)
Yeah.

Nikhil Maddirala (1:06:31)
data and actions to us to let this happen. So I'm actually really curious to see Notion, are they gonna connect with Apple intelligence or not? If they do, they can't continue charging $10 a month or whatever they are for Notion AI, because that doesn't make any sense. So what, and there's a whole like ecosystem of this, like so many apps have started offering their own AI capabilities. So on the one hand, I do think for consumers, it's better to have it in a somewhat centralized place.

Piyush (1:06:47)
Right.

Nikhil Maddirala (1:07:01)
because I want to have maybe a uniform experience and I want to be able to connect. If it's notion AI that's siloed, suppose I want to say something like, hey, find my recent meeting notes with Piyush and send an email summary to someone else. Those kinds of workflows are not possible in if it's just an app level AI. So this is great for consumers, but yeah, I'm...

Piyush (1:07:01)
Right.

Nikhil Maddirala (1:07:26)
I don't know what's gonna happen, whether the apps will...

Piyush (1:07:29)
It'll be very interesting to see, you're right, what will happen, like how many apps or businesses end up exposing their data, both to the semantic and the action layer within Apple intelligence. Yeah.

Nikhil Maddirala (1:07:40)
Mm -hmm. Yeah.

because every app wants to control the user interface ultimately. So think about an example like in my company, right? In meta, like Instagram. Instagram would never expose this functionality. If you can just say to Apple, hey, get me the last 10 photos shared by my friends and show them to me. Yeah, exactly. So.

Piyush (1:07:49)
Yeah.

Yeah, no one's gonna watch the ads, right? Yeah, yeah, yeah, yeah.

Nikhil Maddirala (1:08:06)
That makes no sense. They wouldn't do that. I think recent, so this story is not new to AI. This has been happening a lot. One recent example was Apple TV. They made a decision to try to plug in content from everywhere. So they asked all the other app developers on Apple TV, hey, can you expose your content to this? There are some central Apple TV app that could search across different libraries. So.

Piyush (1:08:08)
Yeah.

Nikhil Maddirala (1:08:33)
Suppose you have Netflix installed, you have HBO installed, and you have some other apps.

Piyush (1:08:36)
Yeah, that would have been such a good thing because I like it's annoying because I have to go inside the app. Like I would rather have a universal thing that just I mean, I'll pay for these services, but just give me a universal interface where if the movie is available. Yeah.

Nikhil Maddirala (1:08:42)
Yeah.

So that's great for consumers, but Netflix actually famously was one of the ones that chose to not adopt that. And they're like, hey, we want our customers to come to our app, engage with our surface because we think we can find the right recommendations for our customers. Maybe we want to show them some ads now that they have an ad supported plan. So they completely lose control.

Piyush (1:09:04)
Right.

Let's say even if Apple agreed to like use their recommendation in whatever, give it full integration, there is some value in like controlling the user experience, right? Like you want that. Yeah, I see that.

Nikhil Maddirala (1:09:19)
Yeah. Think about another example is Tesla. Tesla does not integrate with Apple CarPlay or Android Auto. You can only use their onboard experience because they understand that like you're ceding control to Apple or Google more and more. Like whoever controls the user interface, the rest of it becomes commoditized. It becomes the backend. It becomes something I don't care about.

Piyush (1:09:31)
Right, right.

Hmm. Right.

Nikhil Maddirala (1:09:45)
And actually the CarPlay example is interesting because Apple CarPlay is trying to do more and more. They're trying to convince auto manufacturers to expose functionality like fuel gauges and like all these other controls, system level controls, like maybe air conditioning and things like that, which previously you couldn't do with Apple CarPlay. And they want to integrate that and provide some standard API interface for that. But yeah.

Piyush (1:10:08)
Right. Right.

Nikhil Maddirala (1:10:10)
It's always a question. So Apple is like the giant in the room. They're the aggregator. They aggregate all the user front end and they control the user relationship. So you lose power the moment you give up everything to this like centralized entity. You no longer have a relationship with your customers and you're just.

Piyush (1:10:19)
Right.

But then the risk over there is because of like the people who integrate might not have as good of a product as you do, but because of the integration with Apple and the delightful experience that that enables, that might just be enough for the consumer to be like, I don't care. I mean, yeah, it's likely better, but it's, I would much rather have this delightful experience. So it's a very.

Nikhil Maddirala (1:10:56)
Yeah, but the delightful experience is provided by Apple, right? And then that backend thing.

Piyush (1:11:00)
That's what I'm saying. I'm saying there are maybe other businesses who are willing to expose their data to Apple. And then the people who hold out can't, I mean, it's a tricky situation. So like I'm agreeing with you that it's a very, very tricky situation. And I don't know what the game theory of this, how the game theory of this will play out, but I agree. Yeah. Yeah.

Nikhil Maddirala (1:11:04)
Mm -hmm.

Yeah.

Yeah, it's like a game theoretical thing. Yeah, because you lose your like differentiation when you do it So suppose I become very reliant on Apple for my notes and I'm like notion is this back -end place where I capture my notes But when I need to do something interesting, I ask the Apple assistant Siri to summarize my notes get then in future I might be like, I can just switch out notion with any other notes app or I can just switch out

Piyush (1:11:44)
Yeah, like I mean, Notion would at the end just become like a place where you're typing. Like that's a commodified app, right?

Nikhil Maddirala (1:11:50)
Yeah, or like, you know Adobe Acrobat like I'm like, okay, I can just switch out Acrobat for any other PDF app so they start the it's a shift in the value chain where the front end that controls the user experience is Getting more and more of the value and that that's what Apple is doing right now. So Yeah, I don't know. I think these are kind of

Piyush (1:12:12)
The value chain, that's a very interesting framework. Yeah, that's interesting. Value chain of AI.

Nikhil Maddirala (1:12:23)
Yeah, I think that's an interesting, we can do a deep dive episode on that at some point. We talked about it earlier, like starting from GPUs all the way to like cloud to apps and to like, you know, finally the devices.

Piyush (1:12:27)
Yeah, I would love that. It's just... yeah.

Actually, we should do that. At some point, we should deep dive into the value chain of AI.

Nikhil Maddirala (1:12:41)
Mm -hmm. I think that would be a great episode. I know that we already have a couple of episodes planned.

Piyush (1:12:45)
But this has been so insightful, man. Like just, this has been so insightful. Like we started with that meme, but yeah, it's just so interesting where this is all headed. I'm so excited to just see how this all plays out over the next few months.

Nikhil Maddirala (1:12:59)
And a lot of this is not specific to AI. It's just questions of like platforms and ecosystems, like aggregation that is cyclical. It keeps repeating. And I think people thought that with AI, it's going to be different. It's going to produce opportunities for like new people to come up and disrupt.

Piyush (1:13:05)
Yeah, yeah, yeah.

Nikhil Maddirala (1:13:19)
the existing giants but I think what we've been seeing based on what's happening is that it's the opposite that it's actually a way for the entrenched like players to further become even more dominant so I don't know we'll have to see.

Piyush (1:13:34)
I have faith in Zuck as a challenger. He's trying to create a new modality. You bet the whole company's name on it. It's called Mena now. That's an interesting idea. We'll see how that plays out.

Nikhil Maddirala (1:13:42)
Yeah. And he actually talks about...

I'll add this podcast that he did with Varkesh to the references, but he talks about that in detail. And after this segment that we heard, he talks about how there's always a balance between open and closed systems. Like in the nineties and two thousands in the desktop era, we had open systems that were more common than in the mobile era. The closed model became popular and he's like, well, we don't know what the next platform will be. And he's like, if we control it, we want that to be an open platform.

But yeah, I don't know like even if they do like it's possible that Zuck will realize that hey, there's just so much like Being too open has a high cost for like privacy and security, but maybe it's more like degrees of openness It's not like a binary thing, but Apple is definitely like super closed They do stuff. That's not just security and privacy there

Piyush (1:14:39)
Yeah, yeah. Yeah, actually, that's a good point. We shouldn't like judge and attribute mal intent. It's just that we don't know what goes into making these decisions and there's so many things to consider. So, yeah, it's just, I mean, I don't know.

Nikhil Maddirala (1:14:54)
And it'll be interesting to see like what legal and regulatory frameworks are emerging because this has been a hot topic in regulation, especially in Europe. This kind of stuff, like we talked about how the US Department of Justice filed a lawsuit against Apple. Anti -competition is huge now. There's this new thing called the Digital Markets Act in Europe, which is really trying to crack down on these big tech companies leveraging.

Piyush (1:15:17)
My problem with regulation is just that if it's not done wisely with a lot of wisdom, and I'll give you an example. You know that thing that pops up every time you go to a website? Like it, yeah, it's like, it's a classic example of just regulation, which was in the interest of the consumer, just making the whole internet very shitty. Like just, it's such a horrible experience. So, huh.

Nikhil Maddirala (1:15:22)
Yeah.

The cookie consent. Yeah. Yeah.

I agree, yeah.

Piyush (1:15:40)
I don't know. This is interesting. I mean, I feel like, there's like this heavy burden on my shoulder. Like, what are we going to do? But I mean, it's way beyond us. I'm kind of glad I'm not in the...

Nikhil Maddirala (1:15:41)
Hehehe

Well, I'm actually on a personal level super excited for when these things actually ship that Apple announced. I can't wait on I'm an iPhone user. Like I said, despite all of my complaints about.

Piyush (1:15:59)
Yeah.

Yeah, yeah, yeah.

Nikhil Maddirala (1:16:03)
Why philosophically I'm opposed to it. I can't wait to try this stuff out. It seems really cool I just wish it were more open and it wasn't subject to like Apple's weird controls and rules and what they'll allow and what they won't allow

Piyush (1:16:08)
Yeah.

It's so well said. I think I'm going to, like I said, I think the next thing I'm going to do right after this is I'm going to play with the Apple pencil and this new app if it's out. And I know when I play with it and I have fun and the delightful experience, I'm going to forget all the philosophical things we discussed. I'm like, screw it. Just do what you want. Like, this is great. I want more of this.

Nikhil Maddirala (1:16:20)
Hehehe

Heheheheh

All right, should we end the episode here?

Piyush (1:16:38)
Yeah, this has been such a insightful discussion. Again, thank you so much. Like I feel like I had no clue what was going on in the world of Apple. All I knew was that meme, but like what you unpacked for me, I think I don't need to, like I have a good understanding of exactly what happened and I'm like super excited where it goes. So, and it makes me even more excited about what we're doing here is just like we're meeting up every week to just like discuss what we find interesting about AI and.

Nikhil Maddirala (1:16:57)
Me too.

Yeah.

Piyush (1:17:06)
I will say that again, I feel like I chose a great partner to learn from. Like this has been great, man. Like a great masterclass on Apple's latest AI announcements during dub dub.

Nikhil Maddirala (1:17:19)
All right, you gotta stop calling these things master classes, but this was a fun conversation. Can't wait for next week's episode. I'm still not sure what we'll talk about there. last call for people who are listening. So we officially launched our podcast last week, and I don't know what will be the relation in time between when we're recording this and when it's launched. We still haven't figured that stuff out, but it's out there now. We launched the entire season one back catalog and the intro to.

Piyush (1:17:22)
I don't know.

Nikhil Maddirala (1:17:47)
Season one, it's season two and I think this will go out next. So we're slowly getting some listeners. And anyway, if you're listening to this and you've stuck it out until now, like more than an hour in, you're probably like a fan of our podcast. So please write to us, give us your feedback, your thoughts, questions you have, anything you want to see us discuss in future episodes. I promise you we will, right now our audience base is probably so small that almost any request we get.

we will be able to prioritize it. So if you want to hear us talk about something, just let us know and we'll do it.

Piyush (1:18:22)
Well said. I'll just add one thing to it. And if there's anything that improved your life a little bit even from what you heard from us, let us know. Just share. That would be great. Because I really like what you said at the beginning. Can you repeat that? Your goal or the vision of this is to help.

Nikhil Maddirala (1:18:34)
Yeah, share anything. Let us know what you think.

yeah, is the learning the science of how AI works and the art of using AI to reimagine your life, business and society. So I think it's kind of a mix of things. One is there are some episodes that we're going to do, which is about how you can use AI in your own life to solve your own problems, build your own things. And then the business and society part of it is that's more applicable if you're a business owner.

or you have your own business that you're working on, or maybe you just want to understand like what is the impact that other people are using this for on businesses and societies. So yeah, I think that covers the whole range.

Piyush (1:19:22)
Well said, man. Well said. I think that's a perfect note to end on. That was great. Bye, everyone.

Nikhil Maddirala (1:19:28)
All right, see you everyone.

