Piyush (00:00)
Let's do it.

Nikhil (00:04)
it already started. Okay, I stopped, sorry. I got rid of it because I also put this setting to auto start the recording, but I think that only happens if I join first and not when the guest joins first. It's pretty weird.

Piyush (00:07)
What happened to the countdown?

you froze. Dude, you're gone.

this is a long one.

Nikhil (00:24)
Hey, now you're frozen for me.

Piyush (00:25)
Dude, you went for like 10 seconds you were gone.

Nikhil (00:30)
yeah, I didn't press the pause upload button. Okay, now I press the pause upload.

Piyush (00:33)
Should I do the same as well on my side?

Nikhil (00:37)
I haven't observed problems with you, but it's up to you. I can press it for you if you want, but it'll just be a pain because you will have to sit at the end and wait for the thing to up. I mean, you don't have to sit. You can just leave your computer and go, but yeah. If you click on the right side, do you see a thing that says people?

Piyush (00:55)
Yeah.

Nikhil (00:56)
Then under PUSH there should be a drop down. It'll show your video quality, camera, microphone.

Piyush (01:06)
When I click on people the thing just goes away so... Under PUSH... yeah

Nikhil (01:14)
you see a button that says pause upload.

Piyush (01:21)
no.

Nikhil (01:22)
Okay, I can just press it for you if you want, dude.

Piyush (01:25)
It's fine, if you're not seeing any problems on my side then might as well leave it.

Nikhil (01:29)
Like yeah, in the past I haven't noticed any problems, so I think it's just like for whatever reason my internet issue.

Piyush (01:36)
Okay, sounds good. So it's recording right now. Alright.

Nikhil (01:40)
Yeah, it is. Let's just put some marker to start off at three, two, one, go. Hey, welcome to the Art and Science of AI, a podcast about the science of how AI works and the art of using AI to reimagine your life, business, and society. I'm one of your hosts, Nikhil. I'm an AI product manager and I love talking about AI.

Piyush (02:08)
I'm Piyush, our other host. I'm a sales executive and I love learning about AI. We're two best friends who love talking about AI and here we are. Nikhil, we talked about it in I think two or three episodes now. I've been super curious to learn more about this AI value chain business, because you've mentioned it a few times now and I've just been really curious. So let's talk about that today if you're into it.

Nikhil (02:33)
Cough

Yeah, that sounds awesome. I think we got into it because when we were talking about like Apple intelligence, we talked about how Apple is trying to climb higher in the value chain and take away some value from other players in the ecosystem. And I can't even remember where else it came up. But I think it would be good to understand. I mean, the concept of a value chain is basically understanding the different components that go into delivering an AI application.

to you as an end user from like start to end and understanding what are the different components there, what are the companies that are making those components, what role do each of those play and what's the value added at each of these stages. I think that's what at least I had in mind when I talked about value chain.

Piyush (03:22)
So is it similar to like the concept of supply chain in business operations? Like for example, like this.

Nikhil (03:28)
Yeah, I think it's exactly like the concept of a supply chain. I think it's just focusing on like where the value is. So maybe we could start with a simple example. Like say you have a product, I don't know, like I am drinking tea right now. So if you're drinking tea or coffee,

You would what does a value chain look like there you would start with some raw materials You get that through farming the farmers have to actually get the coffee beans and then there's some steps of processing the raw material it has to be like milled and like roasted and Then there's the process of like packaging and distributing that so I don't know like companies What are some popular coffee brands like Starbucks or I can't even think

Piyush (04:16)
Pints. Let's talk about our local favorite.

Nikhil (04:17)
Yeah. Pete's. Yeah, Pete's. All these companies. So then yeah, there's the packaging and distribution. And then finally there's like the retail layer where you can go and buy coffee. And I guess there's...

So there are different value chains for like buying coffee grounds at the supermarket versus like buying a cup of coffee at Starbucks. They're both similar until the one point and then they diverge. And if you're buying coffee at a supermarket, that's more in the packaging and retail space. And if you're buying coffee at a coffee shop, then the value chain also includes like the building, rent, equipment, labor to pay for that and all of that.

Piyush (05:01)
So what you're describing, I've always understood that to be the supply chain is are those two words the same value chain and supply chain? Can I use them interchangeably or is there a difference?

Nikhil (05:09)
Ahem.

you

I'm actually not sure. I think the concept of a value chain is just to emphasize more on like the value aspect of. So when we talk about value, what does that mean? Right? At each of these stages, there's some value being added. Like when turning the raw material into a process product that adds some value and then turning that process product into the package product that adds some value and just looking at like where is the most value. I think

that's the entire point of looking at it as like a value chain rather than a supply chain because at the end of the day like a customer has a certain willingness to pay for

the coffee that they buy. Maybe if it's coffee that I buy at Starbucks or something, I can pay up to five dollars. Or this obviously varies by which country you live in, who you are and so on. But like that five dollars is spread across all of these different people. And I think the point is trying to think about each person in that

chain wants to get as much of that $5 as they can. And I think the person who can get the most out of that $5 is going to have a lot of power in the industry. So when we talk about...

Piyush (06:30)
That's interesting. That is a unique perspective. So yeah, I'm not sure if I thought about it like that whenever I thought about supply chains. But yeah, I think that is a good way to think about the difference between maybe value chain and supply chain is like which part of the chain commands the most value of the end product.

Nikhil (06:42)
Ahem.

Yeah. And I guess like think about what that's going to depend on, like who's going to command the most value in like a chain like that. It'll depend on which one of those is like ultimately the most crucial. What were you saying?

Piyush (07:07)
irreplaceable.

I was going to say irreplaceable or incremental.

Nikhil (07:15)
Yeah, I think that makes sense. They're probably different and what makes something irreplaceable?

Piyush (07:24)
I don't know the complexity of the thing or I don't know. Yeah

Nikhil (07:32)
Yeah, so there could be various factors. I think it's a combination of like, yeah, complexity, how much uniqueness is there in what you're doing, how much it impacts the end, like user experience, finally, how critical of a component it is.

Piyush (07:47)
Yeah, there's this idea in there is a idea in marketing, specifically digital marketing. Well, not just digital marketing, but marketing general called incrementality, which is that if something were not to be and if I draw that analogy in the value chain world, it would be if there is a part of that chain which we remove from that chain, would that remove the product itself, meaning that

Nikhil (07:58)
Mmm.

Piyush (08:17)
like that thing in the value chain is very incremental. Yeah, so that could be one way of looking at it as well.

Nikhil (08:20)
Yeah.

Yeah, I think that's a good way of looking at it. So yeah, if you were if I was buying coffee at a Starbucks location, let's say, like that experience of going there being able to sit down and have the coffee, that's like a crucial part of the experience for me. So that's kind of irreplaceable. And yeah, I mean, I think it varies, like different customer segments care about different things. So there are like different niches that come up. But I think you can just see trends in

Piyush (08:38)
Right.

Nikhil (08:54)
overall industry of which part is really crucial and which and that kind of determines which company has the most power and like the highest valuations. So that's kind of what's going on in the AI industry right now is there's

Piyush (09:05)
Mm -hmm.

Nikhil (09:12)
a lot of competition to see who can extract the highest value from these AI experiences that people are shipping to customers.

Piyush (09:24)
Yeah, it's a very interesting idea actually to look at the supply chain or the value chain of AI. So most people are familiar with the end product, let's say a chat GBD, but to enable that experience, there's a whole bunch of thing that goes into it. I mean, I have some vague idea that I know Nvidia is obviously very crucial, which is why it's now the most valuable company on earth. As of this recording in June, 2024, like it's the most valuable company.

Nikhil (09:52)
I think it, I mean that keeps fluctuating. It's between Nvidia and yeah.

Piyush (09:54)
on Earth.

Right, that's why I noted the date. But the point is that the reason they're so valuable, they weren't the most valuable company last year or five years back. The reason they are so is I imagine they're very crucial in enabling this new AI boom. And maybe there's other things between NVIDIA and ChatGPT. So I'm very curious for you to unpack this value chain of AI. I like the framing. Yeah, yeah, yeah.

Nikhil (10:18)
Yeah, there's tons of things.

Okay, by the way, I just looked it up and it looks like currently Microsoft and Apple have overtaken Nvidia and Nvidia's third but they're pretty close and these games keep changing because the stock price fluctuates. So yeah, it's one of the top three. yeah, it might even get there again. Like these things will just keep fluctuating.

Piyush (10:34)
Okay, so yeah, right.

I think for a day or two it was the most valuable. It overtook you and Microsoft.

Yeah. Yeah.

Nikhil (10:48)
Okay, cool. So let's talk about AI value chain then. By the way, I think this is a super fascinating exercise to do for like anything. We're gonna do it for AI today, but just thinking about like, I'm wearing this t -shirt. Like where did it come from? I bought it at this store here, but it involved so many people in different industries across the globe making this happen for me. And yeah, we talked about coffee and we tend not to think of that these days, but I think it's,

Piyush (10:57)
Mm.

Nikhil (11:18)
like an interesting exercise to do. But yeah, anyway, let's jump into value chain for AI, or maybe let's start with like value chain for software products in general. Think about in old school software products, like what was the value chain? How were they developed and distributed? One...

Piyush (11:32)
Mm -hmm.

Nikhil (11:42)
Example we can take maybe is a company like Adobe. It was one of the top software companies in like let's say the 90s and early 2000s they made software for working with PDFs working with like media and creative content so

How did that work? And so the first step is the research and development so that you're going to hire a bunch of engineers to actually research how to build the app and actually like build the application and then There's like the packaging and distribution and think about in the old world

People, if a consumer wanted to go buy Adobe software, you have to go to a physical store, like a computer good store or something, and you... Yeah.

Piyush (12:30)
Or even Costco, like to this day during the months of November and December, you can buy software from Costco. By the way, if people are listening to this and not familiar with Costco, Costco is this giant retailer in US and actually it's present across many other countries. But I actually bought a software from Costco and I got a physical thing. It was TurboTax because they were doing a discount and I used TurboTax for my taxes. And I was like, well,

Nikhil (12:51)
What did you buy?

Piyush (12:59)
This is nice. I mean, I get a $15, $20 discount and I know I need TurboTax every year, right? Actually, that was a stupid mistake because it's very annoying. One, it came with a CD and just, I don't know why TurboTax or into the company that... So that wasn't the big problem. Like, I mean, I think they realized that most laptops or computers don't have CD players now. So the problem is...

Nikhil (13:07)
Hehehehe

I don't even have a CD reader. I couldn't, yeah.

Hehehe

Piyush (13:24)
You could only use that activation code for their desktop version, which is very clunky. And I was used to their web version, which seamlessly connected with all the services. And because I already paid for it, I had to use it. So I kind of regretted having got that $15 or $20 discount and getting it. But the point I'm trying to say is, yeah, in the old days, I imagine that's how most people bought their software, right? Like actually go to Best Buy or some place and physically get the software in a...

Nikhil (13:46)
Yeah.

Piyush (13:52)
in a physical format, I guess.

Nikhil (13:55)
Yeah, that's true. So they would get, on the consumer side, you have to walk into a store, buy like a box, you open the box. It's like buying a laptop today. You buy this box, you open it up. There could be a floppy disk or a CD -ROM or something like that, and then you install it. So there was some packaging that went into that, and then it's distributed through traditional retail channels. And...

going back to the research and development side, that's all done in -house by Adobe, both in terms of the staff that they have, their engineers are in -house, and the hardware that they need to use for development, that also is in -house, so they're developing it on their own computers, and if they need like large amounts of data to be processed for things they're doing, they likely have their own like data centers to do that.

So that's like the traditional value chain in the early 2000s, let's say.

Piyush (14:53)
So wait, sorry, before we move forward in the traditional software business, the way you're describing the value chain, it's like two parts to it. One is the development of the product itself. And then there's the distribution of that product, right?

Nikhil (15:05)
Mm -hmm.

Yeah, yeah. So let's break it down into those two steps. Then the next major revolution that happened was, I would say the cloud transformation where we got these like powerful cloud companies like Google and AWS and Microsoft Azure that kind of transformed the value chain for

consumer applications and that is on two things. One is in terms of the consumer experience and second also in terms of the development experience. So let's talk about some of the shifts that happened in the last like 10 to 15 years. The internet took off.

and people were using web browsers more and more. And then also there was the introduction of mobile as a new platform. So back in the day, Adobe probably just made software that you could run on Windows or Mac. Those were the only two platforms they had to make the software for. And now consumers want, like you were saying, you want to be able to run your software on your browser, on the web. You want to be able to probably run it on your mobile applications.

be able to run it across different platforms. So to enable that kind of experience, it cannot be delivered as like a disk that you install or something.

So we've had like platforms like Apple and Google step in and create like app stores that people can use to distribute their applications to end consumers. So that kind of gets rid of the store component of it. And instead now the store is like the person that controls the platform, Apple and Google. And they...

Piyush (17:03)
Actually, this is the first time it kind of hit me the why Apple Store is called that. Like, it's actually like a store like they're trying to. That's funny. I never thought about it like that.

Nikhil (17:14)
Yeah, it's the App Store. And it's interesting, maybe like people in the next generation 10, 20 years ago won't even have this connection of like they just never knew what it was like. So that was one change that happened. And then another, so another change that happened is like,

Piyush (17:24)
Yeah, yeah.

Nikhil (17:35)
Back in the day, like when Adobe wanted to release new features for their application, suppose like they found some cool new way to edit PDFs or they made an improved user interface, like how would they get it in the hands of consumers? The only way to do that is you build another product and then you go ship it to the store again and then your customers have to go and upgrade it. So usually the way it worked was they would have like versions and they would say, okay, you have now like

version 10 of this software and then when I release version 11 I have some improvements and you as a customer can decide if you want to get that upgraded version or not. So it's like when you decide if you want to upgrade your iPhone or Android you look at the new phone and you're like okay do I need these new features but the downside of that is like sometimes in software there are like bugs and things that you want to fix.

Piyush (18:28)
security patches and whatnot.

Nikhil (18:30)
Yeah, security patches and you can't do all of that. So yeah, another need that people had was for the continuous updates to applications that they're distributing. So really the kind of the main solution people figured out to this was, hey, instead of me.

shipping software to you, like the software is going to be hosted on the cloud on the internet and then you can download the software from the internet and then whenever I update it that again like gets updated and you can download the latest version and then that is kind of what changed the model of the

pricing model from like you buy a software once so back in the day like you would just buy software once and then you owned it for life if you bought Adobe Acrobat version 10 that's it you own a license for that but now it's a subscription application and most applications are subscription applications now where they say okay you have to pay

Piyush (19:29)
You know, all the things you've said so far has been really good for the industry. This one I have mixed opinions about. You know, I did really like the fact that you could buy something once and just own it forever. And I really don't like the fact that everyone now wants to move to a subscription model. I kind of miss, you know, there's the idea that like we're both fans of reddits. There's a subreddit called buy it for life. And the philosophy is like, you buy something and you buy it for life, right? Like that.

Nikhil (19:36)
Ahem.

Yeah.

you

Yeah.

Piyush (19:57)
I really like that and there are some softwares that don't need updating and everything is now going to a subscription model. But I see your point.

Nikhil (20:04)
That's true.

I mean, I think the problem is that the rate of change today is so fast that it's not possible to produce static software anymore. Like, so today I'm using web and iOS, like tomorrow iOS is gonna upgrade from version 17 to 18, and then your application may not work with that anymore. Tomorrow, Apple is gonna introduce Apple intelligence, and maybe your application doesn't work with that and you want it to. And also, like there's ongoing

Piyush (20:09)
Mm -hmm.

Right.

Right.

Nikhil (20:35)
cost for developers, for companies that are doing development to just do things like maintenance and bug fixes and kind of hosting their app and all of that. So I think it's like a structural change. Yes, I totally agree. There are downsides to it now.

I also hate it. I was looking just the other day for like, I want a habit tracking app, like just like a checklist to check off that I did these habits every day. And so many of them are subscriptions. There's like, you have to pay two, three dollars a month for a habit.

Piyush (21:04)
We talked about Boost and I forget the one that you mentioned, Apollo, was it the Reddit client that you like? Yeah. And those, the one for Boost, I just paid for life. It was like $3 for life. And I loved that model and that guy had to update it because he had to keep up with Reddit's changes. And he was happy to do that for a lifetime paying customer.

Nikhil (21:09)
Reddit apps.

Ahem.

So that's a specific monetization strategy where the developer is then taking the risk of that the amount of value I get as a one -time payment is gonna be enough to justify my ongoing cost. It may not work out. Then at some point they may just realize that, look, I'm just investing too much time and money into this and I can't do it, but.

Piyush (21:36)
Yeah.

Yeah. Anyways, I digress. I think I take your point that this new model of distribution, which was the cloud model that enabled some really, really amazing thing. And like my venting not withstanding, like by and large for the whole ecosystem. And then, and then the other thing, because I worked for a couple of years for SAP, which is a big enterprise software giant. The other thing that cloud enabled. So I'm not sure if you know this, but back

Nikhil (21:54)
Mm -hmm.

It's fair venting, I agree.

Mm -hmm.

Piyush (22:15)
like before the cloud system, most enterprise softwares were actually, it's called on -prem software. Have you heard of this terminology, on -prem software? So on -prem software literally meant that you had giant machine, on -prem stands for on -premise, like in the premises of your offices, you had these giant rooms which hosted giant servers and giant machines.

Nikhil (22:25)
Mm -hmm.

Piyush (22:41)
And every company had to maintain their own like giant mainframes and servers to run these softwares like big enterprise software. And what cloud did it essentially eliminated the need for all companies to host their own on -prem or on -premise giant hardware and everything could be done on the cloud. So one analogy that we used to do in sales, because I worked in sales, right? And this is almost 10 years back and

Nikhil (22:44)
Hmm.

Piyush (23:07)
we used to introduce the concept of cloud to people. And we would say, it's like every single company is creating their own electricity power generation plan and grid, as opposed to just plugging into an existing grid. Like that was like one analogy we used to explain the benefits of cloud. So like, that's just another thing, right? Like that this shift other transform.

Nikhil (23:18)
Yeah.

Yeah, so that's the other side of it. That's the enterprise side. And actually maybe, so it was driven by both consumer side and enterprise side. The enterprise side is significant as you were bringing up because enterprises, like suppose you were a company that just had like to process tons of data and you had to do that on your own. Or like if you were developing applications that needed a lot of data and a lot of

computational power, you had to go and buy these expensive hardware and maintain all of that. And I think this again goes back to the concept of a value chain, which is that companies ideally want to focus on where they can add the most value. So if you're...

company focuses on developing really good applications, then you probably don't want to be spending your time and energy on figuring out how to manage the hardware and the infrastructure for that. And if you can outsource that, you would try to do that. So I think these are all various forces that like propelled the cloud transformation. And so I think the last thing we didn't touch upon was also like the development side of it.

So if I want to develop an application and I want you to be able to use that application that I developed, I need to be able to host that. So first I have to develop the application and then I have to deploy it somewhere, deploying or host it somewhere so that you can use it. And...

For hosting applications, typically people used to have to have their own servers. So I would buy, so suppose I develop an app, I don't know what it does. Let's say it's this,

like a messaging app, okay? For example, I let people message each other. So the message is going to the server and then the server is sending it to the other user. And in order for that to happen, like I would need to have my own server. And the problem with having my own server is that it's really hard to scale. So suppose today I have a hundred users, my app blows up and I get like a million users. I suddenly need to buy like,

tons of servers now to be able to scale that application that I built. So instead, like cloud companies, often they're known as like hyper scalers. They enable you to like scale easily where you're like, okay, I'm not gonna maintain these servers. I'm kind of renting servers from you and you have an entire farm of them. And...

Piyush (25:41)
Mm -hmm.

Right.

These would be companies like Microsoft Azure, AWS from Amazon, Google Cloud, right? These are the hyperscalers that you're mentioning.

Nikhil (26:11)
Yeah, exactly. So that's the other thing. And then maybe the last thing we should talk about is AI before putting together the value chain of AI. What does it take to get an AI application? So first, you need an AI model.

And we talked about this in our first season, like how you develop an AI model. It's through a process called training. And that process is actually very expensive. You need tons of data and tons of computational resources to train a model. So if you need to train an AI model,

it's like pretty inefficient to do it on your own computer. It would cost you a lot of money. So cloud became like a way to do that kind of easily. And that's kind of what people often use cloud computing resources for. Maybe we can look at a chart that I have, a simple one that kind of ties some of these things together and we can go through them here. Let me share this diagram.

Okay, so this is a diagram called the value chain of AI. I found it, no, I didn't make it. I found it online from someone called Michael Zhang on LinkedIn. And so maybe let's describe what we're seeing here for people who are just listening.

Piyush (27:34)
Did you make this?

do you want me to do this? I would prefer you do it. I see three layers and a bunch of different logos. It's kind of a busy chart.

Nikhil (27:59)
Okay, so it's kind of broken up into three layers. It says first there's the compute layer, then there's the model layer, and then there's the application layer.

So starting with the compute layer, this is broken up into two components. There's the hardware side, and then there is the cloud infrastructure side, which here is called cloud hyperscalers. So on the hardware side, this diagram only shows GPUs, but we have a combination of GPUs and CPUs on the hardware side. And there's more. There's like storage, memory, like all those things.

things. But I think the key thing for AI is the GPU component because GPUs are what are used for training AI models.

Piyush (28:49)
And remind me again, I think you explained this in the first season. The reason why GPUs and why NVIDIA stock is blowing up is that it turned out that GPUs are really great at matrix multiplication, which is at the core of modern AI. Like it's just a bunch of matrix multiplications, right?

Nikhil (29:07)
Mm -hmm.

Yes. Yeah.

And no one knew that when Nvidia first started they were mostly for graphics cards for like video processing gaming and things like that which are graphics heavy but it just later happened to turn out that the kind of computational operations you need to do for training a neural network which ultimately is variations on matrix multiplication they turn out to be very efficient on GPUs

So if I want to do the same thing on a CPU

Piyush (29:44)
interesting. Is it possible that someone comes up with a better processing architecture? I'm sure many startups must be working on this because it just so happened that NVIDIA's GPUs were good at matrix multiplication, but they weren't designed to do matrix multiplication, right? I suppose someone...

Nikhil (30:02)
No, but they've since optimized their GPUs to be optimal for AI workloads. And other companies are trying to, like Google has TPUs, they're called Tensor Processing Units, and people are trying to compete with them, but it's kind of difficult. I actually don't understand too much around the constraints on the hardware space. I think there are some supply chain constraints there.

Piyush (30:06)
Mm -hmm. Okay. Yeah. Right, right. Right, right, right.

Right.

Nikhil (30:29)
I don't know if it's actually materials or the design. So the hardware value chain consists of many components in itself. There's like raw materials for making the hardware. There's design and then there's what's called fabrication, which is you need giant plants that will take the designs that your microchip designers produce and then they'll actually produce.

Piyush (30:51)
Yeah, isn't there some company based in Taiwan which like controls most of these fabrications? I think it's called TSMC stands for Taiwan. Right, right, right. So what you're saying is that there's what I'm looking at right now are three layers. And so one of the layers is the compute layer, which is the most foundational, which itself has two layers, a hardware layer and the cloud hyperscaler. What you're saying is even the

Nikhil (30:59)
Taiwan Semiconductor Company. Yeah. Yeah, I...

Piyush (31:21)
compute layer or so the GPU layer has a value chain within that. So like this GPU is already an abstraction over a GPU value chain. Like each presumably then each one of these layers have their own value chain. And for AI, we have an abstraction on top of these abstractions.

Nikhil (31:41)
Yeah, I mean it's always a question of how deep you want to go. Ultimately if you go deep enough into any value chain you will get to like some raw materials and extracting that. So yeah I think you have to decide what level of abstraction is relevant here.

Piyush (31:50)
Right, right.

I have a question. What is the difference between what we're looking at right now that we're calling a value chain versus an architecture? Like this also looks like the architecture for AI, right? Like modern AI.

Nikhil (32:08)
Yeah, I mean here we're looking at it from like the entire space of the compute layer What are the different companies at each layer if you were looking at architecture? That would select it would be like drawing a line through this value chain and then describing in detail Like how these components are interacting with each other? Yeah, so like I can draw a line from a GPU to one of the cloud

Piyush (32:28)
Okay, got it, got it. So this, yeah, okay.

Nikhil (32:34)
compute layers to one of the models to an application layer. And then we can talk about like exactly how each component is depending upon the other components. That would be an architecture diagram. But yeah, they have some similarities.

Piyush (32:36)
Right.

Right now, the value chain focuses more on all the different companies that come together to enable this AI as opposed to the exact mechanics by which these things play together in the process. Okay, okay.

Nikhil (33:01)
Yes, yeah, that would be an architecture, but that would be case specific, so you can't have a generalized architecture.

Piyush (33:07)
Right. So like we saw the architecture for Apple intelligence in our last episode or one of the previous episodes. So that's an argument. Okay. Okay. Okay. Okay.

Nikhil (33:13)
Yeah, exactly. Yeah. So in this case, yeah, GPUs, their primary role is for training the AI models. And then the, so...

They're part of the compute layer because these GPUs are bought up by the cloud companies and they use them to provide like training as a service to you. So, you know, if I want to train my own model, I don't have to go buy a bunch of GPUs. Instead, I kind of just rent them from the cloud infrastructure companies.

Piyush (33:46)
so you, so let's say I'm a company that is trying to make something an AI and I have to train a train some data or train my model on some of my own private data. I don't go directly to Nvidia and buy GPUs. I go through one of the hyperscalers who then buy the GPUs in the background, but I don't, is that how it works? Like no one.

Nikhil (34:06)
Yes, today that's how it works. Like back in the day in the pre -cloud era, you would have to buy GPUs yourself and now the benefit is you can kind of just rent the GPUs and it's not even that you have to pay a monthly rent, you just pay for how much you use. So that's, yeah, that's how you would use it.

Piyush (34:22)
I see. Okay. So I've been assuming that like most of NVIDIA's revenue is just coming from like these giant hyperscalers like Google, Microsoft, Amazon, they're the biggest customers of

Nikhil (34:35)
Yeah, that accounts for like most of their revenue. I think there are still some companies that buy directly, for example, actually Metta.

Piyush (34:39)
Hmm.

Nikhil (34:46)
has a lot of Nvidia GPUs, Meta does not use cloud compute resources, they have their own data centers. So, and there are like various reasons for that. I think once you reach a certain level of scale, it's just more cost effective for you to buy that than keep renting it. It's like when an individual decides whether to buy a house or keep renting, right? So if you were gonna use this house,

every single day for like the next 10 years, probably makes sense to buy it. But if you're like, okay, I'm just here for like a year or two, then, and you don't know where you will be in 10 years, you probably wouldn't buy a house. So yeah, that's kind of the distinction.

Piyush (35:30)
Yeah.

Nikhil (35:31)
So the one thing then we talked about is the compute layer. Next is the foundational model layer. So let's take the example of a company like OpenAI. So if you look at a product like ChadGBT, they needed to first train their model and they did that primarily using cloud computing resources. In fact, a large part of the reason they got investment from Microsoft.

That investment from Microsoft largely is not paid in cash or stock. It's paid in credits for Azure Compute Resources.

Piyush (36:08)
interesting, I didn't know that. Okay.

Nikhil (36:10)
Yeah, the billions of dollars of investment that they got from Microsoft, a large chunk of that is just they're giving them credits that they can redeem for using cloud.

Piyush (36:20)
Actually, I have a question here. So I've heard that it costs a lot of money to train these foundational models, as you also just said at the beginning of this episode. And I think I saw an interview in which Sam Altman said something like, yeah, GPT -5 is being, or whatever, our next model is being trained. It'll take a few months. And I've just always found that super interesting. Like what that, why does it cost so much? Like why does it cost in the billions of dollars?

to train these foundational models and why does it take months? Like a lot of people said that, GD5 is being trained right now.

Nikhil (36:54)
That's just a factor of like, yeah, I think it's just a factor of how much computational power and data processing is required by these models. Like remember last season, we talked about the concept of like model parameters and how they're used in training a model. Yeah. So

Piyush (37:10)
Yeah, they run into the trillions now. Right, right.

Nikhil (37:13)
For every parameter you have, you're increasing the complexity of training the model because you have to find, you're optimizing every single parameter when you train a model. Essentially a trained model is just a set of parameters. So for...

Piyush (37:24)
Right, right.

which are like knobs on like this giant machine that you're like finding the right setting for.

Nikhil (37:33)
Yes, exactly. So there are trillions of parameters and imagine you're trying to tweak trillions of parameters and combinatorially that just explodes the space. You're like, okay, I can twist this knob this way, this other knob this other way, and then the trillionth knob a different way. So that's one thing plus the volume of data that they're using for the training is ridiculously high. So that's what's leading to this explosion in costs. And I think some people have ideas of

how you can come up with more efficient architectures for model training and of course these companies are researching that stuff all the time so I think in fact consistently if you just compare to like a couple of years ago versus today the cost of training the same exact model is lower today than it was a couple of years ago because of advancements in the training algorithms essentially.

Piyush (38:30)
But I imagine the net cost still keeps going up because you've just increased the order of the data that you're training it on and just the number of parameters. So even though, yeah, yeah.

Nikhil (38:42)
Yes, yeah, yeah. So we keep getting more and more efficient, but we want to do more and more. It's like if you think about...

Piyush (38:49)
It's like that thing about email back apparently, this is something that you will know, Harari. He's the author of the book Sapiens, like one of my favorite books. In one of the interviews he said that when email was invented, everyone was predicting that now our workload is just going to reduce dramatically. Because look, it's so efficient to communicate via email. And the opposite has happened. Even though it's a lot more efficient to communicate via email, essentially zero cost.

We just communicate a lot more and everyone's busier than ever. So I guess it's the same thing here.

Nikhil (39:22)
I think actually this reminds me when I was studying like social sciences and economics in college. They did some experiments where people from different societies, they would introduce labor saving devices and see what the response is. Like suppose you have to do some work and it takes you eight hours a day, say you're farming or doing some manufacturing and I give you a device, a technology that will enable you to do that same work in four hours.

You kind of have two choices. One is you can just work for four hours and then stop, be done with your day, or you can continue to work for eight hours and produce two times the output. And I think what some of the research showed was that people in like capitalist societies, modern societies tend to do the more production. But then if you look at people in pre -capitalist societies that are kind of not in the modern world, often they don't even understand why this makes sense. And they're like, I...

If you're done with your work, why would you do it?

Piyush (40:22)
Yeah. Man, I hope this is not the same thing does not repeat with AI, because a lot of people are promising that look, AI is going to take away all the busy work and the annoying work from you, and that's going to open up time for you to do other things. And maybe people are envisioning a three -day work week or whatnot. And I wonder if we're heading towards the email situation where people will just get

a lot more busier. I don't know. Maybe it'll be different with the other.

Nikhil (40:52)
I... Yeah, so this is a big open question. We can probably do a whole episode on this at some point. So yeah, maybe let's save this. I think it's really fascinating, this topic. There's so many possibilities. Let's park it for like a future discussion.

Piyush (41:04)
Yeah.

Yeah. So in terms of the value chain of AI, so there's the compute layer, which includes the hardware, the GPUs, and then the hyperscalers. Then there's the foundational model. And then the application layer is, I guess, what is like the Adobe analogy, then that's what like the new companies will be doing.

Nikhil (41:20)
Ahem.

Yeah, that's the part we didn't talk about yet. Yeah. So we would have to think about like what are...

Or actually, sorry, let me just look at my notes and see some points I wanted to make. right. One of them is when we think about model training, it has a huge impact on electricity and energy usage right now. I think pretty soon AI is going to be one of the biggest consumers of energy in the world. And we're just like, mm -hmm, yeah.

Piyush (41:54)
Wait, really?

Nikhil (41:56)
We just don't have enough like energy resources. And that's why a lot of the investment in AI is going into just data centers and even more fundamental problems like solving for energy. Like because, and there's a huge problem in the US.

Piyush (42:13)
That's a bold claim, no? Like the biggest consumer of electricity? Like... Okay, yeah, that's like compared to what? Like...

Nikhil (42:17)
one of the biggest.

Yeah, I'm not sure what the basis of comparison here would be, but just think it's going to be using a significant chunk of the world's energy consumption. Maybe right now, I don't know, I would say transportation probably is the biggest consumer of energy. If you think of energy broadly, including like fossil fuels and all that, so like cars, airplanes and stuff. So yeah, I think it's very possible that in future AI will consume more energy than transportation.

Piyush (42:38)
Yeah.

Yeah. Yeah.

Really? I mean, that's insane.

Why?

Nikhil (42:59)
just you said it yourself, like the cost of trading the models is so much and we wanna train so many more models with more data. So it's really exponentially increasing. But on the positive side, I forgot who said this, but some thought leaders in this space like are thinking that this might provide motivation for us to solve the energy problems that we have today.

Lot of people in the tech world are very optimistic about nuclear energy especially nuclear fusion based energy which we still don't know how to do and I think there's an idea that this now might provide sufficient incentive for people to go figure out the nuclear fusion

Piyush (43:42)
This reminds me a lot like when Bitcoin was being hyped up like some two years, three years back, a lot of people were envisioning like these Bitcoin cities because in order to mine Bitcoin, you have the same problem, right? Like you spend a lot of compute and then which requires a lot of energy. And then people are saying that, you know what, we should form these Bitcoin cities because we need so much energy. We'll create these cities which will be close to these new forms of creating energy like hydroelectric power plants, nuclear energy and whatnot.

Nikhil (43:54)
Hmm

Piyush (44:12)
And then that will boost another level of productivity for civilization. And they were calling it industrialization 4 .0, 5 .0. So this reminds me a lot like that. But in this case, at least the compute, you can see the benefit that comes out of it. For Bitcoin, the compute is basically like guessing a number from one and like between one and one trillion. And that's just for the sake of Bitcoin. So maybe there's something to it.

Nikhil (44:19)
Hehehe

I completely agree with you. I think that's exactly the right way to look at it. Yes, abstractly you could make the same comparison and they're both going through these hype cycles, but fundamentally the difference is that in the case of AI, the usage is something that's directly beneficial. I can see what's the benefit of it. In the Bitcoin case, it's kind of like mining gold and

Yeah, I think the hypothesis was that well, Bitcoin will be like a digital gold and then the effort you spend is as valuable as mining digital gold, but there are obviously a lot of problems there and it didn't pan out as people expected. So yeah, that's an interesting thing to think about and a lot of the...

Piyush (45:07)
Right.

Yeah. Yeah.

That's mind blowing that that's the level of energy that will be required. Like how soon do you think this transformation is coming out? Is it like something 100 years in the future that will?

Nikhil (45:29)
I actually have no idea what the relative costs or relative consumption of transportation versus AI is. I think I was just trying to be hyperbolic, but the idea is that it is growing rapidly and it's soon going to be really big if it's going at the current pace. And yeah, currently the world does not have sustainable energy to support the needs of AI development. And that's a problem that we have to solve.

Piyush (45:44)
Right.

So coming back to our value chain point, it seems to me that one layer that wasn't in this chart, which should exist in this chart is also energy, right? Like just as a more foundational layer even, it's just because the more this blows up and the bigger our models will get, the more complex our training will get, energy is critical and crucial as we discovered, right? Like when we were describing a value chain, like what is crucial in that process?

Nikhil (46:08)
Yeah.

it

And actually it's leading to potential environmental problems also. Like I've heard of some people who are environmentalists and who really believe in...

taking personal responsibility for not impacting the environment. Like think about people who try to reduce their carbon footprint, try to avoid flying and driving if they can. And some people who are passionate about that seem to be also quite opposed to using AI these days for the same reasons, because they're worried that it has a pretty large carbon footprint, energy footprint in general. So yeah, I think it is a thing to be concerned about.

optimistically.

Piyush (47:08)
Yeah, that's something that I was just going to say that that's something I've always noticed is a lot of things that drive our civilizations towards development require energy. Like there's one hypothesis that says that the progress of our civilization can also be mapped on our energy usage per capita. Like that's so fundamental. And then that's in conflict with like this whole idea of

Nikhil (47:26)
Hmm

Piyush (47:34)
climate change and how our usage of energy is driving that. And I don't have an answer for that, but I just find that conflict so interesting that like our progress is in conflict.

Nikhil (47:44)
I agree, yeah. I think the whole purpose of sustainable energy as an industry right now is to find a way beyond that conflict and find ways in which you can produce and...

Piyush (47:55)
Yeah.

Nikhil (47:57)
I think the most optimistic scenario for that is if we can actually crack nuclear energy in a way that's safe and efficient, especially nuclear fusion, which we have not yet figured out how to do. But there's like, I think foundations like the Bill Gates Foundation and the Zuckerberg Initiative and those kind of philanthropic organizations are investing a lot in nuclear research. So hopefully, yeah, it remains to be seen where that goes.

So that's on the compute layer. And then in the model layer, I think the only distinction I wanted to draw is there are some models that are closed source and some that are open source. And this distinction is something worth paying attention to. People have been talking about it a lot lately. Open AI, famously, is a closed source model.

Piyush (48:49)
Which is the biggest irony in the whole ecosystem, like the digital ecosystem ever. Open AI is a closed source.

Nikhil (48:56)
Yeah.

Basically what that means is it's actually similar to the distinction we were talking about earlier between buying Adobe software versus renting it through a cloud subscription. The only way you can use OpenAI models is by using their API or their UI chat interface. So if I want to build a product that's based on the OpenAI model, I have a variable cost every time

I make an AI call in my code, I'm paying some money to OpenAI. Yeah, so the advantage of open source models on the other hand is it's more like the original case of you buying a piece of software and just owning it and you don't have to pay rent to someone on an ongoing basis. So the most famous open source model today is Llama, which is produced by Meta and

Anyone can download the model and you can run it on your own server. You can run it on like a cloud server and you only pay your

Piyush (50:07)
Can you help me understand that? So I understand that training is very expensive, both in terms of compute and just energy and money in general. Is running these models also as compute expensive?

Nikhil (50:21)
It's not nearly as expensive as training. It is... No.

Piyush (50:24)
So I could run it on my computer. Like I could run Meta as open source.

Nikhil (50:28)
Yes, I mean there are smaller versions like meta has I think two versions of llama There's the 70 billion parameter model which is the large model and then there's a small model which is like 6 billion parameter So yeah in general people are so the small models you can run it on your computer That's exactly we talked about with Apple and Apple intelligence, right? So they've developed also some small models that can be run on the iPhone directly So that's actually another way of saving

Piyush (50:49)
Right.

Nikhil (50:58)
on energy in some sense because if everyone... So yeah, think about two different scenarios. One is every single person... Actually, I faced this scenario when I worked at Adobe Acrobat AI. We were building AI in Adobe Acrobat. And initially when we first built it, it used to run on our cloud.

Adobe was using Microsoft Azure cloud at that time so when you opened your Acrobat app and You did some AI stuff with it at that time it would do is like lay out your PDF in a mobile -friendly format

Piyush (51:35)
Right.

Nikhil (51:36)
that would be processed by Microsoft servers. So the PDF would be uploaded to Microsoft server, and then we would call the model that does this processing, and then we're paying for those cloud compute costs, and then the response goes back to the user. But one of the big changes I actually worked on when I was there was transitioning that to on device. So we were able to put the model.

in the app on the iPhone so that when the user opens the PDF and wants to do the AI stuff, it just doesn't have to send it to any cloud, doesn't need an internet connection, it just happens on your device. So that's one. So it's a trade -off. It's faster and cheaper, but it's less powerful.

Piyush (52:15)
It's both faster and cheaper.

Nikhil (52:21)
So because you can only put small models on the devices. So yeah, this concept is called edge computing these days. So in the cloud era, we talk about compute that happens on the cloud and on the edge. Edge is like the devices you use as an end user. So yeah, the open source versus closed source distinction is not specifically about cloud versus on device. Although one of the implications is that

Piyush (52:22)
Right. Right, right. Right. Okay. Let me see.

Hmm, interesting.

Nikhil (52:51)
that there's no way to run a closed source model on device because you don't have the model and the only way you can use it is through the company's APIs. But yeah, basically like you own it rather than renting it. So if I want to build an AI application and I use an open source model, I'm just paying for whatever it costs me to run that model.

Piyush (53:08)
Right.

Nikhil (53:18)
And I can do that on my own server. I can do that on a cloud server somewhere. That's up to me, but with Like open AI for example, that's not the case like for every single use I'm paying so it's like it's a

Piyush (53:18)
Right.

Nikhil (53:33)
you couldn't think of it as like a variable cost versus a fixed cost. It's kind of like renting versus buying, which is what we were talking about earlier. So yeah, that I think is an interesting distinction. Yeah, and then the last part that we didn't talk about is the application layer itself, right? So we talked about how like AI exists in different forms. Like there's just standalone AI, like chat GPT kind of stuff. And then there's

Piyush (53:39)
Right, right. That makes sense.

Nikhil (54:02)
AI that's purpose -built AI that's embedded into applications. So for the application layer, one of the decisions you have to make is whether you need to train your own AI model or whether you can just use an existing model. And increasingly, I think what people are finding is that you can, it's more efficient to start with an existing model and maybe like customize that to your

Piyush (54:03)
But first, meet me high.

or use the rag architecture. Yeah.

Nikhil (54:32)
like, yeah, or use like the rag architecture for like text and generative AI that that's the way it works. So on the application side, what's happening is that they most applications these days are hosted on the cloud, which means that again, the applications are using like Google or yeah, the hyperscalers to to host their applications. And then also, that's where the

Piyush (54:54)
these hyperscalers.

Nikhil (55:02)
models are being served like on the cloud. I guess the only difference is if you have an open source model, then you can do that all on your cloud server. You don't have to externally make a...

Piyush (55:14)
Right. I think I understand the way you were explaining earlier, you use the Adobe example on the transformation that happened between like software 1 .0 to like software 2 .0. I'm just making this up. I don't know. But the transformation was that two things fundamentally changed the way you develop the software and the way you distributed the software. I suppose that's still the same on the application layer. What's unique about the AI value chain is all about the compute.

Nikhil (55:35)
Mm -hmm.

Piyush (55:43)
and the foundational model layer. That's something new and unique about AI.

Nikhil (55:47)
I think there's one more. Yes, that's correct. That's very true. I think there's one more thing that's unique about AI, which is like, where is the end user's value or like benefit coming from? Is it coming from the AI or from the app itself? And that's something we were talking about in the

Piyush (56:06)
Right.

Nikhil (56:08)
Apple intelligence episode also like if you take an example like if you have Gmail, right and You have some AI in that that will read your emails and understand them and you know help you write them and so on Mmm It's on so Gmail is an example where that's integrated They just have their own AI model in their own application but I think it's becoming a competition almost between the two to

Piyush (56:10)
Right.

Right.

Nikhil (56:38)
see like who adds more value. And so for example, if we talked about Apple trying to become the user interface for the user, like instead of me going into my Gmail application, or instead of me going into my notes application, I can just use the AI and say, Hey, AI like,

go do this for me, get me this information. And in that case, like that decreases the amount of like market power, like pricing power that applications have and AI has more value in that case. So yeah, I think that that's the interesting thing to think about in the application layer.

Piyush (57:20)
Mm -hmm.

That's not settled yet though. That's to be seen. Like this thing is evolving in front of us as we speak. And it's to be seen who ends up extracting the value here. Will it be the NVIDIAs, the hyperscalers or the, I don't know, apples with the application, right? Because...

Nikhil (57:29)
Ahem.

And to be clear, they're not all in direct competition with each other. Maybe like in some indirect sense, there's a competition. The ones that are like neighboring each other are the ones that are like more in direct competition. So think about applications are kind of coming into competition now with like the platform layer as the platforms start to build in their own AI. And by platforms, I mean like Mac and Windows and iOS and Android and things like that. So.

Piyush (57:57)
That makes sense.

Right.

Yeah. And then I was reading somewhere that NVIDIA is now so valuable that in order to keep up with their growth, which has been insane, they'll have to maybe start competing with the hyperscalers and offer their own cloud services. That could be one way to go about it.

Nikhil (58:26)
I think they're trying to do that because I think in general the strategy wherever you sit on the value chain is to try and get the next or previous step of it. So that's what's called like integration. So if you're like, hey, they're paying for the Nvidia GPUs and they're also paying for the Google's cloud infrastructure.

Piyush (58:38)
Right. Right. Right.

Nikhil (58:49)
then both of those guys are gonna think like, why can't I just eat the other person's share of this and do it myself? So yeah, I think that is, and similarly on the other side, Google is developing their own hardware. I don't know like how intensely they're going after that, but yeah, so that's another.

Piyush (58:54)
Right.

drain.

Yeah. Everyone's trying to grab territory with their next neighbor. It sounds like... That's very interesting. Yeah. This is such an insightful framework to understand how modern AI works. Or if you go back to the analogy of supply chain, like take this bottle, for example, for you to enjoy this bottle.

Nikhil (59:12)
Yeah. Yeah. Yeah.

Piyush (59:34)
And for you to get access to this bottle, there's so much that went in it, from the materials to if you bought it from a retail store like Costco or Target, and everything in between, for it reaching the end retail store and then all the stuff that constructed it. So using that same framework of supply chain on the modern AI to understand modern AI is like, you're using chat GPD and you love hearing

Nikhil (59:39)
Hmm.

Yeah.

Piyush (1:00:01)
Carl at Johansson like assistant voice, like talking to you and telling you all these things. But what goes into like enabling that experience for the end user is the AI value chain. And yeah, that one chart was an amazing way of learning about it. But it's just one level of abstraction and then you can keep going down the rabbit hole, right? Each one of the subcomponent within that layer also has its own thing. So yeah, that's, but I like the framing of it, like just the...

Nikhil (1:00:03)
You

Beep.

Piyush (1:00:30)
analogy to a supply chain. Never thought about it like that.

Nikhil (1:00:32)
Yeah, I think that's interesting. I'm personally most curious about what happens at the application layer and how is there going to be one AI that works across all the applications? Will the applications have their own AI in them? How that will emerge? I am really curious about that. And yeah, I can't wait to see what develops.

Piyush (1:00:40)
Mm -mm.

Yeah, like are we going to end up five years down the line with everything being consumed by Nvidia? Because people realize that like Apple couldn't subsume this whole AI chain because Nvidia does something that no one can replicate. Same with Google, but Nvidia figured out that they can do phone hardware like an iPhone. They can also do like the hyperscalers. So, okay, this is pure speculation on my part, but I'm like trying to say.

Nikhil (1:01:20)
Hehehe

Piyush (1:01:21)
It's interesting. Everyone's trying to grab territory. Like these are the biggest, most valued company on earth and they need to be growing, right? Like it's an obligation they have to the shareholders. And it'll be interesting to see how we end up five or 10 years down the line. My money is that Nvidia ends up subsuming the whole value chain. Cause I was like, I go back to that Taiwan semiconductor thing. I think it's just really, really, really hard to manufacture. Well, I mean,

Nikhil (1:01:30)
Yeah.

Yeah, for sure.

Piyush (1:01:49)
Does Nvidia do its own manufacturing or do they rely on another partner?

Nikhil (1:01:53)
I'm actually not sure. I don't know the details of how. I think they have fabrication partners. I am not entirely sure. I have a different view of this though. Like I actually do not believe that Nvidia's ridiculously high valuation is sustainable because I think ultimately it comes down to how unique or differentiated is the thing that you're offering. And I think that in today's world, the hardest thing to

get control over is consumers' mind share and attention share and just consumer usage. And so I think it's more companies like Apple and Google that are closer to the customer. I think in general, products that are closer to the customer tend to have higher value because the customer values their interactions with that product.

Piyush (1:02:43)
Right.

Nikhil (1:02:49)
Not so much with what's underlying or at the back end of that product. So I don't know. I mean, of course it

Piyush (1:02:54)
Right. So if you go back to your coffee example, that's why Starbucks ends up extracting so much more value in this whole coffee supply chain than a coffee farmer in Colombia, right? Even though one might say that if they hadn't extracted that coffee bean, none of this would have happened. Still, Starbucks ends up... Yeah.

Nikhil (1:03:05)
Yeah.

Yes, exactly.

And that's exactly why like other people are trying to disrupt this. And actually we talked about in the Apple intelligence episode, like Zuck's vision for Meta, he's like, Hey, the next platform is probably going to be around the corner. And then we don't know who's going to capture that next platform. Right now it's mobile and Apple and Google control that the next platform might be something like wearable tech. It could be like glasses. It could be VR. It could just be like a.

that you talk to that's there anywhere. And so yeah, I think once, so I think the most fundamental shift will be if the user experience and user interaction with technology changes in a fundamental way, that opens up like a whole new set of opportunities. So I'm really curious to see that.

Piyush (1:04:02)
Yeah. Yeah. And now that I'm reflecting on it, especially because the inference part isn't that expensive computationally. It's the training with the expensive, right? So yeah, maybe.

Nikhil (1:04:10)
That's right. Although inference is getting expensive, like...

Piyush (1:04:17)
because of the larger context window.

Nikhil (1:04:20)
I mean, it mostly, yeah, it depends on the context window, but also just on volume, like how much AI am I using? Suppose I have an application that is helping read your emails. Like, do I want it to read like, you know, two gigabytes worth of emails every time I give you a response? So there are a lot of like choices you have to make and to balance, like you could say I'm going to make the most powerful AI ever that'll read all the data all the time, put that into its context and give you like the

Piyush (1:04:30)
Yeah.

Yeah, man.

Right.

Nikhil (1:04:50)
best possible answer that would be the most expensive thing you could make and you could even enhance it further you can say if I have a multi -step workflow first there's one AI agent that retrieves your email there's another one that process it and does something so you can always make things more and more powerful actually this reminds me someone commented on our LinkedIn

Piyush (1:04:55)
right.

Nikhil (1:05:10)
I forgot their name. They were like, hey, you talked about chain of thought prompting, right? And chain of thought is a way to improve the accuracy and output of the model. But it comes with this cost of increasing the cost, like because you're asking it to explicitly produce a lot more tokens than it was initially going to.

by making it think out loud. So sure, you're increasing accuracy, but at some point you have to make design decisions about what's the right level of accuracy that I need here that's good enough for this user experience and can I trade off some accuracy for cost and things like that. And I think these are the really interesting decisions that ultimately application developers will have to make, the people who are controlling the end applications. And that's why I think

Piyush (1:05:47)
Right.

Nikhil (1:05:59)
They in the end will have like a lot more control over this. But yeah, I don't know. We have to see how this turns out.

Piyush (1:06:06)
Whatever it is, it's going to be interesting to see how this all plays out. None of this is decided yet. Or it could be something completely different that neither of us in our wireless imaginations can anticipate.

Nikhil (1:06:11)
Mm -hmm.

Yeah, yeah.

Yeah, I'm curious to see how this turns out. Alright, I think that's it for today.

Piyush (1:06:28)
This is great. Thank you so much. Again, a very insightful episode, a very insightful perspective, a new way of thinking about AI and understanding the modern AI ecosystem.

Nikhil (1:06:40)
Yeah, thank you, dude. This was a fun discussion. And as usual, I'm gonna make a call to anyone who is listening out there. If you're enjoying this podcast, please leave us a rating and or review wherever you're listening to podcasts and send us comments, questions about anything you wanna learn about or hear about in future episodes.

Piyush (1:07:03)
Alright.

Nikhil (1:07:04)
Okay, see you next time.

