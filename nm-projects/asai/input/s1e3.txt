00:00:00:00 - 00:00:01:22
Nikhil Maddirala
one of the key breakthroughs there

00:00:01:22 - 00:00:03:10
Nikhil Maddirala
is called embeddings.

00:00:03:10 - 00:00:12:08
Nikhil Maddirala
you can take a word and turn it into a vector, and you can do it in a way such that it preserves the semantic meaning and relations.

00:00:12:08 - 00:00:12:28
Nikhil Maddirala
And

00:00:12:28 - 00:00:16:00
Nikhil Maddirala
you can do vector algebra.

00:00:16:00 - 00:00:22:19
Nikhil Maddirala
one cool example is if you take these these vectors, you do king minus man plus woman.

00:00:22:25 - 00:00:25:06
Nikhil Maddirala
The result it gives you is the vector for queen.

00:00:25:19 - 00:00:33:10
Piyush Agarwal
You're saying independence. Field of study in mathematics. Vector algebra. And

00:00:33:10 - 00:00:36:23
Piyush Agarwal
the researchers realized that if you were to create these embedding.

00:00:36:24 - 00:00:40:14
Nikhil Maddirala
Yes, you could use words. Two vectors. Yeah. You can use the.

00:00:40:19 - 00:00:55:04
Piyush Agarwal
The algebra that they have figured out. Yeah for sure. And this this pattern keeps seems to repeat a lot in science in general. Right. Like there would be some independent field of study somewhere and then will be like some emerging tech somewhere. And then they realize, oh, we could like, use all this stuff from this,

00:00:55:04 - 00:00:55:28
Piyush Agarwal
other field of study.

00:00:55:29 - 00:01:13:23
Speaker 1
Hey, welcome to the art and science of AI journeys. In the season one, which we recorded in May 2023 as a continuous three hour long conversation. And season two is now live. So if you're enjoying this discussion, please subscribe for new episodes every week.

00:01:13:23 - 00:01:16:23
Nikhil Maddirala
So we wanted to talk about generative AI right.

00:01:16:25 - 00:01:17:04
Piyush Agarwal
Yeah.

00:01:17:04 - 00:01:30:07
Nikhil Maddirala
yeah. So we can then next move into like how text is dealt with okay. So first question is how do you encode text. Right. like in this the first question you had about image was how do you encode an image. Right. And then we said, okay, we look.

00:01:30:07 - 00:01:32:20
Piyush Agarwal
At the pixels. Yeah.

00:01:32:22 - 00:01:34:28
Nikhil Maddirala
And each pixel is encoded in

00:01:34:28 - 00:01:40:27
Nikhil Maddirala
RGB value if it's color or like 0 to 1 if it's grayscale. Now how do you encode text.

00:01:40:27 - 00:01:45:20
Nikhil Maddirala
so this is actually very complicated. There's two main steps to encoding text.

00:01:45:23 - 00:01:53:08
Piyush Agarwal
That's not hard. No. Like encoding of text is something that computer scientists have like Ascii and like binary. All that is encoding of text.

00:01:53:10 - 00:01:58:26
Nikhil Maddirala
yeah. Sorry, I mean to say like encoding it in a way that can preserve some semantic relation.

00:01:58:26 - 00:02:00:24
Piyush Agarwal
Oh, I mean, how do you infer meaning from.

00:02:00:24 - 00:02:02:01
Nikhil Maddirala
Yes, exactly. Because so.

00:02:02:01 - 00:02:03:10
Piyush Agarwal
Far it's only been manipulation of.

00:02:03:10 - 00:02:18:26
Nikhil Maddirala
Yeah, you can arbitrarily come up with some encoding that doesn't like. Yeah. But the key is can I come up with a way of encoding text that preserves semantic relationships? Right. Meaning of words. Right. And I think one of the key breakthroughs there

00:02:18:26 - 00:02:20:14
Nikhil Maddirala
is called embeddings.

00:02:20:14 - 00:02:30:27
Nikhil Maddirala
it's basically word vectors. It's a method of turning a word into a vector, like how we take an image here and turn it into a 784 length vector.

00:02:31:00 - 00:02:40:17
Nikhil Maddirala
similarly, you can take a word and turn it into a vector, and you can do it in a way such that it preserves the semantic meaning and relations. You, me.

00:02:40:18 - 00:02:41:23
Piyush Agarwal
An example if you can.

00:02:42:00 - 00:02:43:15
Nikhil Maddirala
Yeah. So that's actually in the next

00:02:43:15 - 00:02:52:19
Nikhil Maddirala
slide. So for these this is called word embeddings okay. So for each word is turned into a vector like this.

00:02:52:19 - 00:03:03:08
Nikhil Maddirala
in this case these are the dimensions of the vector. There are like seven dimensions. But in the case of an actual model like GPT three, like I wrote down how many how.

00:03:03:08 - 00:03:07:10
Piyush Agarwal
It looks very similar to like a concept that Google has and maybe others have, as.

00:03:07:13 - 00:03:15:24
Nikhil Maddirala
The embedding dimension in GPT three is over 12,000. So this thing, the seven that you have here, they're like 12,000 dimensions. Yeah.

00:03:15:24 - 00:03:38:22
Piyush Agarwal
Like just by seeing your first example, it says cat and it is it a cat is a living being to feline human. Oh but it's not those things. Yeah. Like you have these groups. So like internally at Google we have this thing called a knowledge graph. I don't know if it's internal, but like we have a concept of knowledge graph where like like, you know, on Google search, a lot of times you will see a knowledge panel when you search for something.

00:03:38:22 - 00:03:54:16
Piyush Agarwal
So let's say if you search for Barack Obama will be special results will be pictures of Barack Obama and will say American president like it has all these things. Yeah. So, for example, the way to do that is by having a knowledge graph where it knows that this person is an American president, like there is a knowledge graph.

00:03:54:22 - 00:04:00:09
Piyush Agarwal
So every entity has a graph with many connections. Okay. Right. It sounds like a similar.

00:04:00:09 - 00:04:00:18
Nikhil Maddirala
Yeah

00:04:00:18 - 00:04:21:14
Nikhil Maddirala
I think they could be related. I do not know much about knowledge graph, but it's possible that there are related concepts. Yeah. Basically what's happening here is word for each word you're figuring out. Like what other words and what context does it appear in. Right. That's what an embedding is okay. And you can set a number of dimensions for an embedding.

00:04:21:14 - 00:04:42:02
Nikhil Maddirala
In this case there there are only seven dimensions. And they're all like very interpretable which is unreal. Istic in reality they're going to be thousands of dimensions and you can't really interpret them. But the key point is like what you're doing is figuring out this word, what contexts does it appear most frequently in? And that's what an embedding is.

00:04:42:02 - 00:04:47:02
Nikhil Maddirala
It's saying in these contexts it appears more frequently. So you go through your entire,

00:04:47:02 - 00:04:52:22
Nikhil Maddirala
corpus of training data and figure out in which context a word appears more versus less.

00:04:52:28 - 00:04:58:22
Piyush Agarwal
So yeah, in this case, also, you could just give it a lot of unstructured data and then you can figure this out, meaning you give it

00:04:58:22 - 00:05:02:28
Piyush Agarwal
all the text that's ever been written on Reddit. Which is a lot.

00:05:03:01 - 00:05:03:22
Nikhil Maddirala
Even more.

00:05:03:22 - 00:05:04:11
Piyush Agarwal
Like yeah.

00:05:04:13 - 00:05:07:03
Nikhil Maddirala
Trained on 3 billion or some

00:05:07:03 - 00:05:09:17
Nikhil Maddirala
number of billion tokens. Three I think.

00:05:09:17 - 00:05:20:21
Piyush Agarwal
I don't know what tokens is but I see what you mean. Meaning you can give it super unstructured and it will create an embedding out of whatever data you give it, which is and will that happen for every single word within that training data?

00:05:20:21 - 00:05:22:19
Nikhil Maddirala
Yes, absolutely. So GPT.

00:05:22:23 - 00:05:23:13
Piyush Agarwal
Three.

00:05:23:15 - 00:05:23:27
Nikhil Maddirala
Has

00:05:23:27 - 00:05:29:26
Nikhil Maddirala
the vocabulary size of GPT three is 50,000 words and the embedding dimension is,

00:05:29:26 - 00:05:34:09
Nikhil Maddirala
about 12,000. So in fact, that leads to it having six.

00:05:34:14 - 00:05:36:18
Piyush Agarwal
That means every word has 12,000.

00:05:36:25 - 00:05:37:07
Nikhil Maddirala
Yeah.

00:05:37:11 - 00:05:43:00
Piyush Agarwal
Columns. And it's relation like how frequently does it come with those 12,000. That's insane. So what is that.

00:05:43:00 - 00:05:54:18
Nikhil Maddirala
50,000 multiplied by 12,000. About 600 million. That's the number of parameters. Yeah, but that's only like the beginning. Remember it has billions of parameters. So every number here is a parameter.

00:05:54:20 - 00:05:55:02
Piyush Agarwal
Right.

00:05:55:02 - 00:06:06:21
Nikhil Maddirala
Of the model. Yeah. The model can then find what is the right value for this parameter. So right here they're going to be as we said 600 million plus parameters right. GPT three. But

00:06:06:21 - 00:06:16:17
Nikhil Maddirala
before talking about parameters let's think about what is the value of creating these word vectors. As I said, they preserve the semantic relationships between,

00:06:16:17 - 00:06:18:09
Nikhil Maddirala
words and concepts.

00:06:18:13 - 00:06:20:03
Nikhil Maddirala
So to give you an example,

00:06:20:03 - 00:06:31:20
Nikhil Maddirala
look at this graph here. This is a visualization of these word vectors for man, woman king and queen. And what you can do is you can do vector algebra.

00:06:31:20 - 00:06:34:04
Nikhil Maddirala
probably you learned this in high school like,

00:06:34:04 - 00:06:44:27
Nikhil Maddirala
vector algebra is you can add and subtract vectors from each other. And one cool example is if you take these these vectors, you do king minus man plus woman.

00:06:45:03 - 00:06:47:14
Nikhil Maddirala
The result it gives you is the vector for queen.

00:06:47:14 - 00:06:47:26
Piyush Agarwal
you do.

00:06:47:26 - 00:06:51:06
Nikhil Maddirala
Father minus man plus woman.

00:06:51:09 - 00:07:02:29
Piyush Agarwal
You're saying independence. Field of study in mathematics. Vector algebra. And like the researchers realized that if you were to create these embedding.

00:07:03:00 - 00:07:06:20
Nikhil Maddirala
Yes, you could use words. Two vectors. Yeah. You can use the.

00:07:06:25 - 00:07:21:10
Piyush Agarwal
The algebra that they have figured out. Yeah for sure. And this this pattern keeps seems to repeat a lot in science in general. Right. Like there would be some independent field of study somewhere and then will be like some emerging tech somewhere. And then they realize, oh, we could like, use all this stuff from this,

00:07:21:10 - 00:07:22:04
Piyush Agarwal
other field of study.

00:07:22:04 - 00:07:23:22
Piyush Agarwal
Sounds like that's what happens here.

00:07:23:22 - 00:07:26:18
Nikhil Maddirala
I think one of the earliest times this happened was with,

00:07:26:18 - 00:07:36:29
Nikhil Maddirala
Descartes in the 16th century, when they got really stuck with geometry and they realized that geometry and algebra could be related if this happened,

00:07:36:29 - 00:07:39:16
Nikhil Maddirala
with what's called Cartesian math.

00:07:39:16 - 00:07:46:06
Nikhil Maddirala
Descartes in, like, the 16th century, realized that there are a lot of problems you're having in geometry that can't be solved.

00:07:46:12 - 00:07:51:04
Nikhil Maddirala
But once you map geometry onto algebra, like you say, the geometry is just like,

00:07:51:04 - 00:07:53:16
Nikhil Maddirala
algebra on like a graph.

00:07:53:16 - 00:08:04:24
Nikhil Maddirala
you can solve a lot of, like, geometric problems that you previously couldn't solve by converting them to algebraic for problems, because there are a lot of results in algebra that directly you could apply to, to geometry. Yeah.

00:08:04:24 - 00:08:16:04
Piyush Agarwal
I mean, I'm sure you would appreciate that because you studied logic, but like, that's what sort of the genesis of boolean logic, right? Some guy was independently creating Boolean logic. I think his pursuit was to like, prove the existence of God.

00:08:16:04 - 00:08:18:15
Piyush Agarwal
George Boole no. Yeah, I don't know. It could.

00:08:18:15 - 00:08:18:29
Nikhil Maddirala
Be, I don't.

00:08:18:29 - 00:08:24:06
Piyush Agarwal
Know, some interesting story. Maybe I'm butchering it, but, like, his pursuit was to, like, prove God or something, and he was

00:08:24:06 - 00:08:37:15
Piyush Agarwal
trying to find out. Oh, I'm going to take all these statements from Bible, and then I'm going to apply some logic and then drive conclusion. And then he discovered Boolean logic. And then over here, these people who are dealing with computer science are like, oh, we could use this existing field of study.

00:08:37:15 - 00:08:37:21
Piyush Agarwal
And

00:08:37:21 - 00:08:40:29
Piyush Agarwal
look what we've made. So it's yeah, looks like something similar is happening here.

00:08:40:29 - 00:08:57:19
Nikhil Maddirala
Absolutely. And I think ultimately all of it is just mathematics. Like there are a lot of results in mathematics, like a lot of relations shapes that people. It's about encoding different objects into a mathematical formulation and then being able to like, leverage those,

00:08:57:19 - 00:09:03:22
Nikhil Maddirala
results in relationships. And that's exactly what's happening here. We know how vectors are related to each other.

00:09:03:22 - 00:09:07:16
Nikhil Maddirala
Once we convert words to vectors, then we can leverage those.

00:09:07:16 - 00:09:08:15
Piyush Agarwal
Is very cool. Like those.

00:09:08:15 - 00:09:09:01
Nikhil Maddirala
Relationships.

00:09:09:01 - 00:09:16:13
Piyush Agarwal
You're saying that if you were to do all this, then you come up with the vectors of man, woman, king and queen. And if you apply that vector logic like the way.

00:09:16:13 - 00:09:18:16
Nikhil Maddirala
You preserves these relationships, yeah, you put in them.

00:09:18:16 - 00:09:23:15
Piyush Agarwal
Yeah. Like because that's how you think about it. It's like, okay, man. Woman. Minus that then that's. Yeah, that's a king. That's cool.

00:09:23:15 - 00:09:26:21
Nikhil Maddirala
Okay, absolutely. So then,

00:09:26:21 - 00:09:29:07
Nikhil Maddirala
this is the first part of how,

00:09:29:07 - 00:09:46:18
Nikhil Maddirala
this is the encoding problem. We talked about how to encode our input into features. Right. That can go into the model for images. It was the pixel values for words. Now it's you start with first tokens. A token is like an individual word. Think about it that way.

00:09:46:18 - 00:09:50:24
Nikhil Maddirala
Like cat kitten. These are tokens. Yeah. That step one.

00:09:50:24 - 00:09:52:12
Piyush Agarwal
Is that a common parlance in the.

00:09:52:12 - 00:10:10:21
Nikhil Maddirala
Yes in this. So in fact if you go to GPT three or ChatGPT, it'll always describe its limits in terms of the number of tokens. So the context size is one of the important limiting factors of GPT. With GPT four I think the context size is.

00:10:10:23 - 00:10:11:23
Piyush Agarwal
55,000.

00:10:12:00 - 00:10:24:26
Nikhil Maddirala
No, it's 4000 or 8000 tokens. And then there's an expanded version that's like 32,000 tokens, but that hasn't been released yet, which means that the total of the input and the output that it can generate at max, it can have 4000 people.

00:10:24:27 - 00:10:28:15
Piyush Agarwal
Why don't they use, words like words like, well,

00:10:28:15 - 00:10:32:06
Piyush Agarwal
with words. Yeah. I think it's between words and tokens.

00:10:32:07 - 00:10:44:26
Nikhil Maddirala
That's a good question. I don't know the exact answer. I think there is a difference. Like, for example, the word man and the word men are the same two different words, but they're the same token.

00:10:44:28 - 00:10:47:04
Piyush Agarwal
Oh, I see what you mean. Yeah. Okay. Okay.

00:10:47:05 - 00:10:57:07
Nikhil Maddirala
So like man, or if you have like man man's man apostrophe s like plurals and all that. So those are like concatenated into the same token.

00:10:57:07 - 00:10:57:13
Piyush Agarwal
Right.

00:10:57:18 - 00:11:01:26
Nikhil Maddirala
Because ultimately whether it's man or like man's, they.

00:11:01:29 - 00:11:04:13
Piyush Agarwal
They're but actually it

00:11:04:13 - 00:11:12:18
Piyush Agarwal
why are they treated the same way in the model. Because they have different semantic meaning. No, no. Well not sorry, different semantic meaning, but they have different usages.

00:11:12:20 - 00:11:13:19
Nikhil Maddirala
That's true.

00:11:13:19 - 00:11:34:07
Nikhil Maddirala
actually, I don't know the exact. I could look it up, but I don't know the exact relationship between words and tokens. I know that it's not a 1 to 1 relationship. There are some things that are bundled together. Yeah, like different words into the same token. Okay. And sometimes the same word is multiple tokens based on if a word has two meanings like then those are separate tokens.

00:11:34:07 - 00:11:35:18
Nikhil Maddirala
So okay.

00:11:35:18 - 00:11:37:18
Nikhil Maddirala
so yeah, we were talking about

00:11:37:20 - 00:11:42:29
Piyush Agarwal
Actually if you backtrack a little. Yeah, I want to go. Let's stick to our story. Yeah. Classical ML goes to,

00:11:42:29 - 00:11:47:01
Piyush Agarwal
sorry, classical approach to programing, then classical ML, then,

00:11:47:01 - 00:11:52:04
Piyush Agarwal
neural nets, then deep learning. And now we're moving to like, generative stuff.

00:11:52:06 - 00:11:57:22
Nikhil Maddirala
This is still deep learning. This is still deep learning. Yeah. But this is now a basis for like a generative analyze text.

00:11:57:22 - 00:12:02:07
Piyush Agarwal
And how do you encode text. Yeah. So vector algebra is came to the rescue.

00:12:02:10 - 00:12:20:16
Nikhil Maddirala
You can put it in this same thing here. Again you can put all those vectors here. And you can run it through this. And you could run like a classification model like this where instead of like zero through nine, suppose you have your spam problem. You can have two classes zero and one spam, not spam. You can put those inputs here.

00:12:20:16 - 00:12:21:26
Nikhil Maddirala
All those vectors.

00:12:21:26 - 00:12:43:29
Nikhil Maddirala
it's a little more complicated because you're just putting the individual vectors there. You need a way to get the sequence and order and things like that. So the architecture becomes a lot more complicated. But the basic concept is the same. You have a way to encode text. You can now feed that into your machine learning models, and you can use it to perform tasks like classification prediction.

00:12:44:02 - 00:12:50:04
Nikhil Maddirala
So that's how you encode text and that's how that fits into like deep learning, right? Yeah.

00:12:50:04 - 00:12:55:25
Nikhil Maddirala
yeah. And then like so I want to go back to this thing here. So we talked about like

00:12:55:25 - 00:13:03:25
Nikhil Maddirala
features right. And now let's think about what are some of the other things that are going on for a language model.

00:13:03:27 - 00:13:07:15
Piyush Agarwal
actually we didn't even come to language model. How do we get to language model. So

00:13:07:15 - 00:13:08:11
Piyush Agarwal
what is the language.

00:13:08:11 - 00:13:09:26
Nikhil Maddirala
Sorry. Yeah, I guess now if you.

00:13:09:26 - 00:13:10:20
Piyush Agarwal
So this is a model.

00:13:10:20 - 00:13:34:05
Nikhil Maddirala
Yeah. Exactly. So then let's talk about like what is generative AI. Right. Like generative AI is just types of models that create new data that mimic characteristics of like the training data. So it's like instead of doing a prediction task, the goal is generate something new that's similar to what was in the training data, images or text. The most popular use cases are images and text.

00:13:34:05 - 00:13:37:09
Nikhil Maddirala
There's also audio and video, which are like more complex. And,

00:13:37:09 - 00:13:38:29
Nikhil Maddirala
I think they're a little harder to understand.

00:13:38:29 - 00:13:43:25
Piyush Agarwal
Yeah. But it's it's actually it's mind boggling. Like with Midjourney, it's able to

00:13:43:25 - 00:13:49:14
Piyush Agarwal
like imagine new image. I mean, you need a prompt obviously, but it's crazy. Like the output is,

00:13:49:14 - 00:13:53:11
Piyush Agarwal
is so esthetically pleasing and it's,

00:13:53:11 - 00:13:57:23
Piyush Agarwal
it never existed before. It's like something that our minds imagine, like, how the hell does it do that?

00:13:58:00 - 00:14:02:08
Nikhil Maddirala
Yeah, that honestly, even I don't understand. It's a combination of,

00:14:02:08 - 00:14:03:22
Nikhil Maddirala
images and text.

00:14:03:22 - 00:14:11:12
Nikhil Maddirala
I mean, through using the concepts that we discussed. But yeah, I don't exactly understand how Midjourney specifically works. It's a combination of the image. Yeah, but like.

00:14:11:12 - 00:14:16:25
Piyush Agarwal
Just the general idea of like, forget Midjourney, but even GPT four, for example,

00:14:16:25 - 00:14:35:01
Piyush Agarwal
the output it has, it's not. So for example, if I'll go back to the, my first example where I was asking is like, oh my baby girl, I want to yeah, start solid foods. It's answer. It's not as if it's copy pasting that answer from like the billions of training data that is found somewhere, like, oh, I found this Reddit thread that someone was asking the same thing.

00:14:35:08 - 00:14:53:13
Piyush Agarwal
So I'm going to copy paste. It actually uses the context in which I've presented the question and then answers accordingly. So it's like it's it's like a, it's like almost like this conversation. If you take all the words, it's a novel thing. It's never happened before. That's what we do, right? How is machine able to do that? I don't like that's the magic for me.

00:14:53:16 - 00:15:04:18
Nikhil Maddirala
So yeah, I don't know if I'll be able to answer exactly that. I hope like we have some building blocks that we built up so far, and we can talk about specifically how ChatGPT is trained. Right.

00:15:04:18 - 00:15:08:09
Nikhil Maddirala
there are a couple of more concepts that we can cover there, and then we can discuss what.

00:15:08:12 - 00:15:10:03
Piyush Agarwal
So so this is model I think I yeah.

00:15:10:03 - 00:15:20:21
Piyush Agarwal
Like based on what you explained, I am getting a good understanding of this. Then what is a language model. What is a large language. Because I keep hearing this word LMS everywhere I don't know. So that means a language model.

00:15:20:21 - 00:15:31:05
Nikhil Maddirala
We talk about generative models. Generative models goal is to generate something new that resembles the training data language model. The goal is just to generate text,

00:15:31:05 - 00:15:51:19
Nikhil Maddirala
that resembles text that was found in the training data. So the very basic function of a language model is to predict the next word given a set of words. So if I give it a string of like, you know, some ten words, it'll predict what is the most likely next word to come out of it based on,

00:15:51:19 - 00:15:57:09
Nikhil Maddirala
what it learned from its training data that that's at a very base for the language model does.

00:15:57:16 - 00:16:06:12
Nikhil Maddirala
And you can extend that to instead of predicting the next word, I can say, predict the next 100 words or predict that that's the token size. That's what we were talking about.

00:16:06:12 - 00:16:08:12
Piyush Agarwal
But even a word.

00:16:08:14 - 00:16:15:17
Nikhil Maddirala
You can say anything given it. Yeah. So when you go to ChatGPT, you can type in just one word if you want. Yeah. Press enter and it will generate something.

00:16:15:23 - 00:16:25:26
Piyush Agarwal
That seems ineffective. No. Like it should be given like a oh, you think it could work even with the word. Yeah. But obviously the more input the better the more input. You can do that.

00:16:26:02 - 00:16:28:18
Nikhil Maddirala
But all it's doing is like if you say if.

00:16:28:18 - 00:16:31:28
Nikhil Maddirala
so I had one example here. If you have a word like,

00:16:31:28 - 00:16:34:15
Nikhil Maddirala
I don't remember, like this

00:16:34:15 - 00:16:46:22
Nikhil Maddirala
is a blank. Okay. Then it'll look at all the past instances in the training data where this combination of words existed. This is a followed by what was the next word there.

00:16:46:25 - 00:17:09:09
Nikhil Maddirala
And look at what is the most probabilistic outcome on that next word based on my training data okay. That's the first thing it does. And then if you ask it what's the next word again it'll say now the context is this I've put it into my context. What's the most likely next word to come out of it. So what it's doing is trying to predict the next word based on its training data.

00:17:09:12 - 00:17:12:08
Nikhil Maddirala
And this is the way the training data is,

00:17:12:08 - 00:17:31:22
Nikhil Maddirala
encoded in the model. And the architecture of GPT three is extremely complicated. I have like this slide on it. Right? I cannot explain it to you, unfortunately. It is too complicated. But I think the key thing I want to emphasize is there are multiple loops and layers of like feed forward network.

00:17:31:22 - 00:17:51:27
Nikhil Maddirala
This thing that here, this is feed forward network. What that is is this thing, this is called a feed forward network. Right. This is the most simple kind of like neural network where everything is just going in this direction. There are way more complex neural networks. They're called like recurrent neural networks or long short term memory networks that have more complex architectures.

00:17:51:27 - 00:18:03:23
Nikhil Maddirala
But what is happening here is there are a bunch of different neural networks that are combined together, and they're probably like, you know, like n number of different layers of neural networks here.

00:18:03:25 - 00:18:21:23
Piyush Agarwal
So you're saying that like if you go back to that one neural network slide where you have like the 784 pixels predicting. So with GPT, the level of complexity is so high that it has many of such neural networks. And the hidden layers between them is also insanely large.

00:18:21:23 - 00:18:47:14
Nikhil Maddirala
Yes. And that's how you get to 175 billion parameters, because, as I said, the starting point for the number of parameters is here. And that's actually 617 million, because we discussed that there are 50,000 vocabulary words, and then there are about 12,000 embedding dimensions. Right. So that itself is 617 million parameters. And then that's going through and getting multiplied.

00:18:47:14 - 00:18:49:19
Nikhil Maddirala
But remember how when we talked about,

00:18:49:19 - 00:18:50:06
Nikhil Maddirala
here

00:18:50:06 - 00:19:01:04
Nikhil Maddirala
each layer was getting multiplied several times. So similarly how this 784 led to 13,000. So in GPT we're starting with 617 million instead of 7084.

00:19:01:04 - 00:19:16:18
Piyush Agarwal
So help you understand this just just because it's it's like mind boggling the the amount of computation that is going through this. So every time I'm asking a question to ChatGPT GPT like it must be doing an insane amount of computation to answer.

00:19:16:20 - 00:19:19:25
Nikhil Maddirala
Yeah, so we need to separate. Or is that part that only.

00:19:19:25 - 00:19:20:22
Piyush Agarwal
Yeah. So machine.

00:19:20:22 - 00:19:22:08
Nikhil Maddirala
Learning there's training and.

00:19:22:14 - 00:19:30:01
Piyush Agarwal
That's what I was going to come to. Yeah. Is the computation only required for training. And once you've trained the model then the answers are not very computationally intensive.

00:19:30:07 - 00:19:37:16
Nikhil Maddirala
No. Again like going back to this example here, the training is the process of finding the parameters.

00:19:37:17 - 00:19:37:29
Piyush Agarwal
Right.

00:19:37:29 - 00:19:55:05
Nikhil Maddirala
It finds that 150 are the right parameters. That's what training is. And in the case of this neural network training or learning is finding the right weights and biases. That's finding the right value for all these 13,000 parameters. That's training. Inference is given a new training,

00:19:55:05 - 00:20:03:03
Nikhil Maddirala
example or a new example, calculate all these 13,000 parameters and output the final value.

00:20:03:05 - 00:20:05:06
Nikhil Maddirala
That's a much simpler computation, right.

00:20:05:06 - 00:20:15:08
Piyush Agarwal
But in all of these previous examples the final value was limited. Right. It was either a like a concrete discrete. Yes. Orange. Yes. No. Apple.

00:20:15:09 - 00:20:15:21
Nikhil Maddirala
Yeah.

00:20:15:21 - 00:20:16:26
Piyush Agarwal
Or

00:20:16:26 - 00:20:26:23
Piyush Agarwal
it was like a set of values in the home value price. It could be like between one and infinity but infinity. But it's still like arithmetic right. Yeah. But in case of generative AI it's,

00:20:26:23 - 00:20:30:14
Piyush Agarwal
I mean, it's still like a permutation of combination of words, but it's.

00:20:30:17 - 00:20:38:19
Nikhil Maddirala
No, do remember, it's multi-step at every stage. It's just predicting what is the next most likely word. At every step is just one prediction that's coming.

00:20:38:19 - 00:20:41:19
Piyush Agarwal
So you're saying it's actually as simple as that. It's just predicting the next.

00:20:41:26 - 00:20:54:10
Nikhil Maddirala
So that's what a language model does. You give it some input text. It takes this text and it says what is the next most likely word to come out of that. First it does that then now that word that it output.

00:20:54:15 - 00:20:56:05
Piyush Agarwal
It's always a word like literally it's.

00:20:56:05 - 00:21:03:00
Nikhil Maddirala
Just a token. Yeah. Then that word becomes part of the context. And then it says, now given this entire context, what's the next.

00:21:03:05 - 00:21:10:14
Piyush Agarwal
Thing to this day, the way ChatGPT or ChatGPT force is working? It's like at the algorithm level, it's only predicting the next word every day.

00:21:10:17 - 00:21:16:17
Nikhil Maddirala
It's only predicting the next word every time. Yeah. That's the basic language model.

00:21:16:17 - 00:21:33:07
Nikhil Maddirala
there's some like reinforcement learning on top of that to input human preferences and stuff for like the style of response it gives you. But yes, at every stage it is just predicting the next word. Given a context, what is the most likely next word to come out?

00:21:33:10 - 00:21:35:17
Nikhil Maddirala
That's the prediction task. And that's what the.

00:21:35:21 - 00:21:51:05
Piyush Agarwal
Who doesn't even consider. Okay, here's the next 4 or 5 words. Because know a lot of times your next word might is not just influenced by the previous words or the context, but you might choose what your next word should be based on what the other following words could be as well. Right?

00:21:51:07 - 00:21:53:29
Nikhil Maddirala
yeah. That's how a human would. Yeah, but that's not how.

00:21:53:29 - 00:21:55:21
Piyush Agarwal
Maybe that's the next evolution.

00:21:55:24 - 00:22:03:18
Nikhil Maddirala
Yeah, I don't know exactly how that would happen, but right now all a language model just predicts the next word. and,

00:22:03:18 - 00:22:05:14
Nikhil Maddirala
there are a couple of steps in this that,

00:22:05:14 - 00:22:10:25
Nikhil Maddirala
I wanted to talk about. So how chat. So this actually talks about how GPT three.

00:22:11:01 - 00:22:13:00
Piyush Agarwal
Moves the mic a little bit close to, oh, this.

00:22:13:00 - 00:22:16:09
Nikhil Maddirala
Is GPT three, how it's trained. The output of this.

00:22:16:09 - 00:22:21:19
Piyush Agarwal
Actually before we jump into all this, what is GPT stand for? Is that,

00:22:21:25 - 00:22:26:19
Nikhil Maddirala
Like a generative pre-trained transformer?

00:22:26:19 - 00:22:38:23
Nikhil Maddirala
or it might be generalized pre-trained transformer, but I think it's generative. But the transformer is this type of architecture. It's the model architecture. Like how we had linear regression. And then there was

00:22:38:23 - 00:22:47:02
Nikhil Maddirala
feedforward neural networks. Transformer refers to this type of architecture. Generative just means like it's generating text. Pre-trained

00:22:47:02 - 00:22:51:26
Nikhil Maddirala
refers to the fact that it is trained and it has these parameter values already fixed.

00:22:52:03 - 00:22:58:11
Piyush Agarwal
Okay. And is that something that open AI came up with or like GPT is like a general term, like everyone can have?

00:22:58:11 - 00:23:00:18
Nikhil Maddirala
No, they just came up with their own,

00:23:00:18 - 00:23:00:26
Nikhil Maddirala
name.

00:23:00:27 - 00:23:03:24
Piyush Agarwal
So when, when, when I hear the word typed in the way

00:23:03:24 - 00:23:09:21
Piyush Agarwal
it's always to do with the open eyes, GPT like, it's not that Google will have its own GPT and.

00:23:09:23 - 00:23:10:01
Nikhil Maddirala
Yeah.

00:23:10:01 - 00:23:10:28
Piyush Agarwal
Facebook will have it.

00:23:10:28 - 00:23:15:21
Nikhil Maddirala
Know they'll have different names, different names. And that's actually an interesting question, because recently,

00:23:15:21 - 00:23:23:25
Nikhil Maddirala
OpenAI has been trying to enforce their trademark on GPT because a lot of people have been publishing applications with the name GPT in it.

00:23:23:25 - 00:23:28:09
Nikhil Maddirala
and OpenAI wants to avoid this name becoming generic size. Right.

00:23:28:09 - 00:23:29:03
Nikhil Maddirala
so too bad.

00:23:29:03 - 00:23:30:16
Piyush Agarwal
Gets out of the bag.

00:23:30:18 - 00:23:34:01
Nikhil Maddirala
Yeah. I mean, I think there are some legal methods they can use.

00:23:34:01 - 00:23:37:21
Nikhil Maddirala
there is this, I don't know, trademark law is very complicated.

00:23:37:21 - 00:23:49:19
Nikhil Maddirala
there's this thing where if people are using this word in a generic way, then you can't enforce that trademark anymore. So I think Xerox was one example. People started using Xerox in a generic way.

00:23:49:19 - 00:23:51:07
Nikhil Maddirala
It's like, I'll Xerox this.

00:23:51:07 - 00:23:52:22
Piyush Agarwal
Yeah, Airbnb is another one.

00:23:52:26 - 00:24:00:05
Nikhil Maddirala
Yeah. So in those cases you lose your trademark ability. So there I read recently there are.

00:24:00:05 - 00:24:01:09
Piyush Agarwal
Pros and cons.

00:24:01:09 - 00:24:09:00
Piyush Agarwal
because it's a nice to be in a position where your, your company's name has turned into a verb, like, oh yeah. And be it, I'll Google it.

00:24:09:00 - 00:24:11:09
Piyush Agarwal
I'll gpt maybe, but I think they.

00:24:11:11 - 00:24:16:00
Nikhil Maddirala
Text me associate, like if I make an application called chaos GPT. Yeah.

00:24:16:02 - 00:24:16:08
Piyush Agarwal
Like,

00:24:16:08 - 00:24:17:19
Piyush Agarwal
yeah, yeah. You don't want to be they.

00:24:17:19 - 00:24:18:19
Nikhil Maddirala
Don't want to be a service.

00:24:18:19 - 00:24:20:20
Piyush Agarwal
Yeah. That's okay. Yeah.

00:24:20:23 - 00:24:24:21
Nikhil Maddirala
But okay, let's just finish this thing. So this is GPT three.

00:24:24:21 - 00:24:43:26
Nikhil Maddirala
Chad, GPT is one step beyond GPT three. So this thing here is initial language model that is like GPT three, okay. It's what it starts with. And then it does this thing called reinforcement learning based on human feedback. And it comes up with a reward model.

00:24:43:28 - 00:24:48:18
Nikhil Maddirala
What that is is not just predicting the next word, but like it's,

00:24:48:18 - 00:24:51:12
Nikhil Maddirala
taking human preferences into account.

00:24:51:12 - 00:25:09:00
Nikhil Maddirala
so the humans evaluate a bunch of samples of prompts and responses, and there are a bunch of like, basically they hired like contractors to evaluate like prompts and responses, rate. Is this a satisfactory response or not? And that's the second step on top of the language language model.

00:25:09:00 - 00:25:12:19
Nikhil Maddirala
All it does is predict the next word based on,

00:25:12:19 - 00:25:36:22
Nikhil Maddirala
the training data and the model. It just predicts the next word and then the next word, and then it produces a string of text. This process, it's called RL. If reinforcement learning with human feedback, that's like the next innovation on top of language models where they input human preferences into the style of response the GPT gives you.

00:25:36:24 - 00:25:49:24
Nikhil Maddirala
So it's not just about predicting what is the most likely next word, but you have to predict the most likely next word. That is like liked as an output by human beings generally. So you can't give output that.

00:25:49:26 - 00:25:59:26
Piyush Agarwal
Help me understand this. So GPT three, it doesn't have that human feedback. No. But is it gibberish that it produces or.

00:25:59:26 - 00:26:00:14
Nikhil Maddirala
Is it this.

00:26:00:20 - 00:26:04:09
Piyush Agarwal
Is like too rude and you need for human feedback to like make it more polite.

00:26:04:09 - 00:26:10:20
Nikhil Maddirala
Like, yeah, it's like either too rude or it's like not super context aware.

00:26:10:20 - 00:26:16:11
Nikhil Maddirala
Like is is not the style. Yeah, actually I don't have a good example of like what kind of response? But it's not.

00:26:16:11 - 00:26:17:02
Piyush Agarwal
Gibberish.

00:26:17:09 - 00:26:18:28
Nikhil Maddirala
No, no, it's not gibberish that GPT.

00:26:19:01 - 00:26:23:11
Piyush Agarwal
Three could very well work as ChatGPT. You might not like it, but it's going to be legible.

00:26:23:11 - 00:26:25:14
Nikhil Maddirala
It's not conversational. It's not,

00:26:25:14 - 00:26:40:01
Nikhil Maddirala
intended to be because the way GPT three is trained is like, you gave a snippet of text. It's like that text was in the middle of an article, and then it's predicting like the next text from that. That's not conversational. So this process just makes it conversational.

00:26:40:01 - 00:26:41:14
Piyush Agarwal
That's all right okay.

00:26:41:16 - 00:26:49:02
Nikhil Maddirala
GPT three is like normal tech. What it can predict the flow of text. Right. But it's not optimized for conversational text.

00:26:49:03 - 00:26:57:26
Piyush Agarwal
Right. So the innovation with ChatGPT was using GPT which is a language model, and make it more conversational, which is what I mean, like exactly.

00:26:58:00 - 00:27:05:14
Nikhil Maddirala
In fact, it's not. The model itself is called instruct. GPT, which is supposed to be like taking instructions and,

00:27:05:14 - 00:27:10:20
Nikhil Maddirala
fulfilling those instructions. So yeah, but ChatGPT is based on that basically. Welcome.

00:27:10:20 - 00:27:13:18
Nikhil Maddirala
yeah. So basically that's the.

00:27:13:18 - 00:27:15:21
Nikhil Maddirala
That's everything I wanted to cover on,

00:27:15:21 - 00:27:23:10
Nikhil Maddirala
language models and I, I think I just have 1 or 2 more slides that talk about now

00:27:23:10 - 00:27:30:28
Nikhil Maddirala
what this means now, how you can use GPT to like, build applications and do cool things.

