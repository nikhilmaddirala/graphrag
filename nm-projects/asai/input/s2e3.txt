Nikhil Maddirala (00:10)
Hello and welcome to the Art and Science of AI, a podcast about the science of how AI works and the art of using AI. I'm Nikhil Matirala. I'm one of your hosts. I'm an AI product manager and I love helping people learn about AI.

Piyush (00:26)
I'm Piyush Agarwal. I'm your other host. And Nikhil and I are best friends, and we love talking about AI. So should we jump into it, Nikhil?

Nikhil Maddirala (00:33)
Yeah, let's do it.

Piyush (00:35)
Okay, so I think we talked about it in the last episode. Help me understand how does one get started with AI? Meaning, let's assume that someone doesn't know anything about AI. How does one go from a zero to a hero of AI?

Nikhil Maddirala (00:49)
Yeah, that's a great question. I think a good way to get started with AI, and we talk about the art of using AI, right? Like that's what it is. It's about applying AI to your own life, to change things, personal projects that you're working on, your work or your business or anything in the world that you're working on. So I think really the first step is to figure out.

where you can use AI, even before you get into what you're gonna do with AI and understanding AI. So maybe let's talk about that. My view is that where you would look is at things that you're doing repeatedly, things that are tedious and boring for you, things that are time consuming and complex, or anything that needs feedback and iteration. Ideally, if there's some combination of these, it's a good...

place where you can think about using AI. And we can talk about some examples. But what do you think?

Piyush (01:47)
You don't mean just at work though, right? You mean like even in your personal life you could find these patterns.

Nikhil Maddirala (01:53)
Yeah, I think it's just about looking for problems that you're facing, anything that you find annoying, frustrating, time consuming, whether you're doing it at work, you know, it could be like reading documents, like doing some analysis, it could be at home, it could be like writing emails, processing some stuff on your computer, filling up some forms. Yeah, or it could be like side project ideas that you have, you might have your own business and you're thinking about how to improve.

your efficiency there. So there's a whole range of use cases, I think. And we can talk about some examples, but that's kind of a starting point. But you also use AI a lot. You know, you've been using it for the last year. So what are your thoughts? Where do you think people should look?

Piyush (02:37)
Yeah, ever since you... actually, I think it was you who introduced me...

to the ChatGPD app. I mean, I knew about it and I knew what was going on, but I think you were the first person to really show me how you were using it in your daily life. And ever since then, I feel like I'm somewhat of a power user of these LLMs. I actually pay for a subscription for Gemini, I pay for a subscription to ChatGPD. So I think in total, I pay $60 a month. I have three separate subscriptions. I have a perplexity one as well. Yeah, what I think is, and this is very interesting, I'm curious to hear what you think about this.

Nikhil Maddirala (03:03)
Wow, okay, that's a lot more than me.

Piyush (03:12)
I feel like $60, and by the way, we're grateful to be in a position that we can say that about $60 a month, so I'm mindful of that. But I feel like the benefit that I get out of these services are so much more than the $60 a month that they charge. So I've been very happy with all of these LLM, but I'm very curious. You mentioned AI. Am I right in assuming that you mean these LLM chatbots when you mention AI, or does AI come in other forms as well?

Nikhil Maddirala (03:40)
Right, so I think when we're talking about someone who doesn't know how to use AI or is a beginner, the first entry point is going to be the AI chatbots that are based on LLMs, because we had AI even before that. It was always there in big tech companies and apps you use, you know, when...

Piyush (03:42)
you

Nikhil Maddirala (04:02)
You open up Spotify or Netflix and they're recommending content to you when you open Meta and they're recommending ads to you. So AI has always been around, but it was never accessible to end users, to people who are not comfortable with technology and with math and advanced programming skills. So I think really the change that happened with the LLMs is that it made it a whole lot more accessible to just the average person.

to start using AI. Before that, it existed and you probably encountered it in apps and devices that you were using, but it was not something you could control or is not something you could use or create or shape in the way you wanted to as a user. It was something that big tech companies were using to control your experience in some way, often to make it better and more engaging for you. But I think for the first time now with

these LLMs and chatbots, it's given the ability to, the average user, to go and start using AI to solve their own problems and to create interesting solutions with it.

Piyush (05:13)
Yeah, I can see that's true for an average user like me. Like I, for example, never really used AI in my life before these chatbots came out. But I'm curious, was it the same for you? Were you a power user of AI before these chatbots? What I'm asking is, for an average user like me, certainly it's helped a lot because it's an easier way to access it. But is it the same for an advanced user like yourself as well? Like, have you started using AI more with these easier to use applications?

Nikhil Maddirala (05:35)
So yeah, maybe we can break it down into two things. One is I've been working as an AI product manager at tech companies for the last over five years now, like before this LLM revolution came about. So yeah, I've always been in a work context using AI and using it to improve products that we're building. So in that sense, this new wave of AI,

is wasn't revolutionary there for like, for example, if I'm building an existing product, like, recommending the right show for you to watch, then yes, this new capability adds a little bit on top of that. But it's not like fundamentally a transformative shift. But for me as like an individual user, like in my personal life, yeah, I used to tinker with AI, even

before LLMs were around, but it was much more complicated. I had to use complex, so first of all, you had to know programming. That was the one requirement. There's no way you could do anything with AI if you don't know how to program. That's one thing that's changed. And even if you do know how to program, you have to use very complex programming frameworks to build AI solutions. Originally, you had to use frameworks like TensorFlow and PyTorch.

But then later on, people made a high level abstractions of these that you could easily use. There was Keras and a couple of others. And then, yeah, there was a lot of advances in foundation models for images and stuff where you could just fine tune those models. But it's definitely not, it was something that if you're a programming enthusiast, you could easily get into it, but not someone who doesn't know programming. So I think now what's happened is for the first time, someone who doesn't know anything about programming.

can use AI to solve a lot of problems and you can even implement some workflows and automations without any programming, like no code whatsoever. And if you know even basic programming, you can do a lot more advanced stuff. And that's actually what I was hoping we could get more into in this podcast episode. Like we can start with, first imagine you don't know any programming. What are the ways you can get started with AI? What can you do with it?

and then we can talk about a little more advanced stuff.

Piyush (07:56)
Yeah, I would like that actually. Yeah, let's so let's do this. Let's start by talking about someone who doesn't.

work with AI a lot and how might they benefit from using these AI technologies. So maybe I can share a little bit about what mostly, we talked about it at the abstract level, but let me make it more concrete. So the way I use it mostly these days is one, to clarify my own thinking. So let's say I'm writing an email, right? Like I'll usually spend, I mean, if it's an email where it's a quick response, that's fine, but sometimes I have to send emails to my clients where I do a lot of thinking before I write the email and I reword everything and I'll make sure that the email is clear.

I'm clearly able to articulate what I'm thinking in my head and is actionable for the next person. So what I'll do is I'll draft my email and I'll ask ChadGBD or Gemini or someone to basically reread my email and paraphrase it so it's more clear and actionable. So that's a very popular use case for me. And that itself I found to be so transformative for my career because I send a lot of emails, I work in sales, so that's improved my life quite a bit.

say most of my use cases are very text -based where it's like trying to clarify my thinking and like modifying text so I'm curious just what are some other types of use cases that I haven't explored yet and like can you help me understand like what are some basic use cases?

Nikhil Maddirala (09:20)
Yeah, I think it goes back to what we were talking about earlier, looking for your workflows and things that you do in your day to day life, especially things you do repeatedly and things that are time consuming and complex. I'll give you some examples. So recently I and you have become podcast creators, or I mean, you were always a podcast creator, but I've recently got into this. And so I realized that there's a lot of work that has to be done.

For every podcast you want to create so you have to come up with ideas for the podcast You have to write an outline of the podcast then you have to record the podcast you have to edit it and then once you finish that then you have to produce Summaries and show notes to make it more engaging to your audience So for all of these steps actually, I've been using AI to help me we can talk about in more detail how I've been doing that but just take one example like writing a

Show notes and summaries of the podcast so I can just take the entire podcast transcript and I feed it into Chat GPT. We can talk about more advanced ways to do that, but just something as simple as that So this is a task that I have to do repeatedly because now we're doing this podcast and we're gonna do an episode a week Hopefully so every week I have to do it. It's a repeated task It's time -consuming and annoying like I wouldn't want to listen to the whole episode and manually write the summary

so I am just automating it now. I use chat GPT and it gives me a summary and the first summary it gives me may not be the best one, the one that I want to actually publish. And then I further edit it, but it's like, I have an assistant who is doing the first draft. Yeah. It gets me started. Gives a first draft to me and then I can edit that. So that's one example, like me as a podcast creator.

Piyush (11:00)
Guess you started.

Yeah.

Nikhil Maddirala (11:09)
then me as a product manager, or this is also applicable to like entrepreneurs maybe, or startup founders, often I wanna do things like an industry analysis, competitive analysis, opportunity identification. So to very quickly get started with that, I often use AI tools to just give me a summary of like I say, okay, here's the broad overview of what I'm trying to do.

help me understand what does the industry look like, give me a breakdown of like, what are the different segments of the industry, what are some problems and opportunities in each of these spaces, and that just helps me very quickly get started. So this is an example of like a research task that I do on a somewhat regular basis. So I'm using it there. I often use it for...

Many other things, like sometimes idea generation, like sometimes when I wanna cook something, I'm like, well, I have these ingredients, like what can I make with it? So there are like a range of use cases for it. The one you mentioned I think is a really good one. I've also been getting into, I've always been a geek about personal knowledge management and I'd love to do a dedicated episode on that one day.

But I'd love to have an AI help me understand all of my notes that I've captured over the years and help me find new knowledge and connections. But that's some more advanced stuff. So the basic stuff, as I said, for me is identifying any workflow or process that I'm doing repeatedly that I don't want to be spending so much time on and making that easier. I'm...

Piyush (12:49)
Why repeatedly?

Nikhil Maddirala (12:50)
because that's when you get the most value from it. Like if it's just a one -off task, then often the time I invest in using AI, because sometimes I also customize how the AI is gonna handle this task, right? So in general, the kinds of things in your life you wanna automate are the things that you do repeatedly because that upfront investment you make in trying to automate it will have a longer payoff over time, whereas if it's just a one -off task.

there's not a huge benefit to automating it.

Piyush (13:21)
Interesting. Yeah, I can, yeah, I see what you're saying, but -

Isn't the advantage of using these chat GPT type things that we don't have to make a lot of investment in using it? Meaning even if it's a one -time thing, you just need to ask it. In fact, I would say you might stand to save more time with a one -time thing because with the repeated thing, perhaps over time you kind of found your own groove and you made things easy for yourself. But when it's a one -time thing, you have to build the conceptual framework to do that thing. So you spend a lot of time.

Nikhil Maddirala (13:37)
That's true, I -

Piyush (13:53)
in the LLM can actually help you figure a lot of the unknown unknowns for a first time class, right?

Nikhil Maddirala (14:00)
I think maybe we're talking about two different things. You're talking about using the LLM to give you guidance on exactly how to do the thing. You're like, okay, I need to figure out what's, yeah. But I'm talking about actually doing the thing. So in this case, like I know how to write a summary from a podcast episode. That's not an unknown for me. I know how to do it. And it's just that, but I don't want to spend time every week doing it. So that's why I'm using a...

Piyush (14:08)
Right.

Nikhil Maddirala (14:26)
An AI LLM to do it. But to your question of like, why do you need to invest time in it? You don't need to. And I think for someone who's just getting started, you don't need to do this at all. Just go get started and work, ask your questions or provide your task to the chat bot and see what output you get. But like I said, because the outputs I get when I do this, I'm not always happy with the output. So then I spend some time crafting.

the instructions that I'm giving to the chatbot and that gives me better results. And so I invest more time. Sometimes I invest time into creating like.

Piyush (15:03)
What do you mean you spend time in crafting the instruction? Like are you talking about the prompt itself? Like you spend time in coming up with a good type of a prompt? Okay.

Nikhil Maddirala (15:11)
Yeah, mostly it's about the prompt itself. Sometimes it's more complex things than that. I might make a custom GPT that has a prompt and some previous knowledge that I want it to use. So it's just like, if you invest more time, you can get more predictable, better results. But maybe let's first just go into, forget about that advanced stuff of how you can control the AI. Let's just say at a basic level.

Piyush (15:38)
Well, let's circle back on it. At some point, I want to learn more about this custom GBT business.

Nikhil Maddirala (15:41)
Yeah, for sure. So let's just start with like the very basics. Like, so like we said, you've identified some area in your life where you think you could use AI to help you with it. So how are you going to use AI for that? I talked about this example of me as a podcast creator and also as a product manager. So in general, there are like two approaches to this. One is you can use a general purpose AI or you can use a purpose built AI.

Piyush (15:54)
Excuse me.

Right.

Nikhil Maddirala (16:11)
So a general purpose AI is like the AI chatbots that we've been talking about. So like chat GPT by OpenAI, there's Gemini by Google, there's MetaAI, there's Claude by Anthropic, and then there's also like AI search tools like Google search, Bing, Copilot, Perplexity, and so on. These are like general purpose AIs. You can use them for almost any task that you have, and that's a good starting point.

But another way a beginner can get started using AI is through purpose -built AI. And purpose -built AI also exists in two ways. One is there's AI built into existing applications that you already use, or there are dedicated AI applications where there are new apps that do AI things. So an example of existing applications with AI would be Gmail, Notion, WhatsApp.

Slack, all these kinds of applications are building AI into it. So Gmail recently announced AI features. Notion has been one of the, or Notion is a note taking app that I really like and it was one of the first apps.

Piyush (17:18)
Yeah, WhatsApp has been... And WhatsApp has been overhauling their app so much recently. Yeah, that makes sense.

Nikhil Maddirala (17:22)
Yeah. So the advantage of purpose built AI is that, so let's take the example of Notion. Notion, if you don't know, is a note taking app and they introduced AI into Notion, which lets you chat with your notes and help you write better notes. So the advantage of that is your notes are already in Notion and you can ask it questions about the notes or when you're writing a note, like say the example you gave of writing an email, right?

So you probably write your email in some other document somewhere and then you copy and paste that email into one of the chat bot applications and then you get that response and you copy and paste that thing back into wherever you want to send it. So that's fine. There's not too much friction there, but the advantage of having AI in your workflow is that I don't need to do that. I can just write the email in Notion and I can say, hey, edit this thing for me, give me feedback and it'll directly edit it. I don't need to move it to another app and copy it back and stuff. So.

And then there's also like dedicated AI apps which do things like For example, there's apps that transcribe your audio into text using AI There are apps that generate music for you. Suno is one of them I recently discovered there are apps that use AI to so whatever task you have I think the point I'm trying to make is Whatever task you're trying to do you can either accomplish that through a general purpose AI or

or you can find like a purpose -built AI for that task. And the general purpose AI is like the easiest way to get started, but increasingly there are gonna be purpose -built AIs for each and every task that you wanna do because that will just ultimately reduce the friction. But there are trade -offs because that's not as customizable as the general purpose AI. So I would say like, if you're a beginner and just getting started using AI,

just start with the general purpose AI. That'll help you understand what the possibilities are, what you can do with it, and what are the limitations, and then it'll help you understand it better. So that's where I would recommend people start.

Piyush (19:26)
There's a very interesting distinction, the general purpose AI versus the purpose built AI. Never thought about it like that, but now that I'm thinking about it, I am more of a general purpose AI user. Yeah. Yeah. Do you use any purpose built AIs? I know one example you gave is transcribing or making show notes for the podcast. What are some other types of purpose built AIs that you use?

Nikhil Maddirala (19:40)
Yeah, me too. But for some things...

Yeah, I think for text. So for text based tasks, the general purpose AI is roughly okay right now, because it's not that hard to copy text to one place and then get the response back. But actually one text based task for which I use purpose built AI is for coding when I'm doing programming work. Like there's GitHub Copilot.

Piyush (19:58)
Right.

Nikhil Maddirala (20:13)
And at Meta, we have our own internal version of it. It's called MetaMate. But like GitHub Copilot, it exists in your development environment in VS Code, which is the most popular IDE. And it's aware of your workspace and your code base. So I don't need to, previously what I was doing is copying snippets of my code, pasting it into ChatGPT. And then ChatGPT would say, okay, but this function points to some other function. You need to go look there.

Piyush (20:25)
Hmm, so it's aware of your existing code

Nikhil Maddirala (20:41)
But if you're using like GitHub co -pilot, it's still not great at it, but it's aware of your whole workspace and it can actually look and find like, well, what's the right function that you need to go edit or fix. So that's one place. A second one is when you're doing non -text based things like video, for example, that's a lot more difficult to use a general purpose chat bot for. So one thing with podcasting is I'm using this, we're using this app right now called Riverside to record our podcast. And.

It has a bunch of AI features built into it. It can use AI to enhance the audio. It uses AI to automatically find pauses and silences in your podcast and it trims them. And it can automatically find highlights from your podcast that you can share as like short form videos and so on. So yeah, I think over time there will be like better purpose built AIs. But I think that you'll have a mix of both.

Piyush (21:41)
Yeah, what I'm hearing you say is for someone who's getting started, I think they'll stand to benefit the most with just getting started with these general purpose tools like ChachiPD, Gemini, and stuff like that. And as and when they find specific use cases or specific purposes where they need automation, maybe there are some repeated tasks that they have to do, they can perhaps look for more purpose -built AI. Is there a place they can, I mean, they could...

You could always just do a Google search. But is there a specific place one can find purpose -built AIs for tasks that they might be doing? Like is there a repository or something? Or?

Nikhil Maddirala (22:17)
no, not, not that I'm aware of. I think one thing is like whatever existing application you're using for that task, probably they are already going to build some purpose built AI over there. So.

Piyush (22:29)
So you're saying everyone's thinking about building AI into whatever they offer.

Nikhil Maddirala (22:34)
Yeah, every company is thinking about already building AI. So that's actually one of the things that makes it hard as an entrepreneur, as a startup finder, is finding a space where you can add value because often tasks that people do are embedded in existing workflows. So for example, if I'm editing video, I'm using a particular software to do that. I'm comfortable with it. I have an established process. Now, if you try to come in and say, look, I'm going to...

do better AI video editing, that's fine, but the software I'm using, like whether it's by Adobe or whoever it is, they are also likely to put in AI. And since I already use that software, I'll probably just stick with that. So yeah, I think that's one thing that's happening. Everyone is putting in AI into their things, but I still think everyone should like start experimenting with general purpose AI so that you, it's kind of like,

you know, you get to be like a tinker or you get to play around with it. You get to instruct the AI and get the kind of responses you want out of it. And then if you enjoy that, like you might even go on to build your own purpose -built AIs. So I think that could be the next evolution. This at least gives you some foundation for doing that. So the first way you would start, if you just want to start using general purpose AI, right? Like how, if you open up any one of these,

Piyush (23:33)
Yeah.

Nikhil Maddirala (23:57)
chat applications, you're just faced with a text box and you have to type something in there. So that's really the first place where you can get started and that's called the prompt. Earlier we were talking about like optimizing the prompt. So there are a couple of different approaches to that, but just to get started with you would enter whatever question it is you have or whatever task it is you have. So,

One example of that would be say I want to take a podcast transcript and get the summary of it. I would just copy in that text and say, hey, give me a summary of this. So that's like the basic way, or as you were saying, like you just copy this email that you're writing and ask it for improvement. So that's like the basic way to get started.

Piyush (24:42)
The prompt is the interface to these general purpose AIs basically.

Nikhil Maddirala (24:46)
Yeah, the prompt is the starting point and interface. But yeah, I wanted to talk about like, what are some strategies you so once you start doing that, like how to get better.

Piyush (24:56)
Yeah, I've been always curious about that. So I've read a lot that the quality of the prompt.

really matters because the quality of the output will depend on the quality of the prompt. And I'm curious why that's the case. Well, I mean, the LLM is so smart. Why does the quality of the prompt matter so much? Because there's a bunch of stuff around it, right? Like there's prompt engineering, there's prompt templates, and perhaps you should talk a little bit about all of those aspects and why they matter so much.

Nikhil Maddirala (25:27)
I think it's possible that in future a few years down the line they won't matter and the LLMs would have gotten good enough such that they can take an ill -formed prompt and then do stuff with it and give you a good response. But right now we're not there yet. The quality of the prompt really matters because we talked about this last time, LLMs can only do the system one thinking which is just like immediately giving you a response. They don't give you like a slow considered response.

which is what we try to accomplish with prompting. Actually, Andrew Ng, who's a really famous AI educator, and also now he is investing in some startups, he had a famous quote recently about the limitations of just using a general purpose AI. He's like, it's like asking a student to write an essay, but you tell them that they have to sit at the keyboard.

and continuously type without ever pressing the backspace key or without ever pausing and then end at the end of that. And that's the output you're getting. So that's the analogy he's making. And I think that's, yeah. So just imagine if you had to write an essay, it requires you to maybe write a few lines and then you think about it and you pause and then you write some more and then you restructure your thoughts. You delete something you wrote and at the end, maybe you just got a first draft and then you take a day to think about it.

You come back to it the next day and then you have some more thoughts and you revise it and that's how you come up with like a good essay. But LLMs right now are not there yet. So if you gave it a task like write an essay, the output is, I mean, it's surprisingly good compared to a student who...

Piyush (27:06)
Yeah, I'm surprised that that's how it works. I just thought, you know, when you get the output from these chatbots, it comes as like word by word. I thought that was just something that they designed to make it seem like that. But it was the output that it produces seems very considered. It seems like it's gone through the process of thinking about pondering about what it's saying. But it's interesting to learn that it's literally actually doing that. It's just...

spitting out the next word as it predicts the next word. Yeah.

Nikhil Maddirala (27:36)
Yeah, that's all it's trained to do. Yeah. And I mean, I think if you just ask a generic question, sure, like you may think it's a pretty decent quality, but you'd be surprised once you get more specific with the questions you're asking and the type of response you want, you'd be surprised how poor the quality is in comparison to like how much of a better response you can get if you implement some more advanced strategies for.

giving it better instructions and making it think differently.

Piyush (28:07)
Yeah, there's a feature I don't know if you've noticed within Gemini. When you type your prompt in Gemini, there's a little magic wand that appears now. And if you click on that magic wand, it transforms your prompt into a better written prompt. And I use that quite a bit. In fact, I actually now use that. So typically what I do is I'll keep like two chatbots in parallel. I'll like use a spitscreen.

Nikhil Maddirala (28:22)
I didn't even know that.

Piyush (28:32)
and I'll type my prompt in Gemini, use the magic wand so it creates like a nicer prompt, and then I'll enter that prompt in Gemini and also copy that prompt and enter it in ChatGBD. Because I completely agree with you. I've noticed that when, because I've done an experiment where I'll just type what I thought of, and then I'll type the magic wand version, which is a better, more improved prompt. And you're right, you certainly see that you get a better quality output if the prompt is richer. So I'm like, okay.

Nikhil Maddirala (28:41)
Got it.

Hmm.

Piyush (29:00)
Let me use Gemini for making my prompt and I'll use it across. So maybe that's a tip for someone who's listening that they could do that.

Nikhil Maddirala (29:06)
Yeah, that's actually a really good tip. I didn't know Jim and I had this feature. I've seen it in Claude. I know that Claude has a specific tool you can use to optimize your prompt, where if you give it a general prompt, it'll try to optimize it further. So yeah, I guess you can use these tools. Beyond that, I would say.

Piyush (29:24)
The other thing, sorry to cut you off just before you jump into your next...

at whatever you're thinking next. Like I was thinking about what you said, you know, that eventually maybe the quality of these prompts wouldn't be such a big deal. And whatever you actually initially type with your train of thought as it came to you might be enough for the LLM. And as you were saying that I was thinking of this code, which is a code by Larry Page. We set this in 2006 in the context of Google search and like kind of trying to encapsulate what his vision is for

Nikhil Maddirala (29:50)
Mm -hmm.

Piyush (29:57)
for Google search or any search engine and the code goes something like this. Larry Page said that the ultimate search engine will know exactly what you mean and will give you exactly what you want. And I feel like I love that code because it's such a beautifully summarized code on what the, and I feel like the last 20 years that's what Google has been trying to do, right? Like trying to build a search engine which more and more just knows. So I think it could be true for these chatbots as well. Eventually,

Nikhil Maddirala (30:10)
Hmm.

Yeah.

Piyush (30:26)
these chatbots will know exactly what you mean in your prompt and will give you exactly what you want. And you won't have to like jump through these hoops of prompt templates and prompt engineering and whatnot. But in the meantime, I think it's a good practice to do so.

Nikhil Maddirala (30:39)
Well, I mean, another limitation is that it can never read your mind. So whatever you type in, if you didn't give it sufficient instructions, yeah, yet. So there's Neuralink.

Piyush (30:46)
yet.

I don't know man, maybe in some futuristic world, yeah I was just gonna say that maybe the thing is connected to the waves of your brain and it knows exactly what you mean even before you try the prompt. So...

Nikhil Maddirala (30:59)
Yeah, that's possible. We're pretty far from that. But if you think about it, this even occurs in human to human interactions. Like when you're working with, let's say a colleague at work and you ask them to do something, the quality of what they do for you is highly correlated to the quality of the instructions you provided. Like if you provide more context, more motivation, more information.

they're likely to give you better output, whereas if you just say, you know, like here's something abstract I want you, you might not get a good output for that. So, yeah, in terms...

Piyush (31:35)
That's a good point. And then these tools also provide you so much context window to provide a very rich prompt. Like we mostly...

My prompts are, I don't know, like three lines to at max maybe 100 lines, but you can actually go up to a thousand if not a hundred thousand lines. So the limitation for the quantity of the words you can use for your prompt is actually quite high, even in the most basic free versions. So there's a lot of opportunity to enrich your prompt.

Nikhil Maddirala (32:04)
Yeah, absolutely.

So one way is to just enrich, I would say there are a couple of types of prompting that you can do. One is called zero -shot prompting and one is called few -shot prompting. And what that refers to, the shot refers to how many examples you're giving of the kind of response you want. So zero -shot prompting is when you just ask a question and then you try to get a response from it.

Piyush (32:17)
Hmm. Hmm.

Nikhil Maddirala (32:33)
Whereas a few shot prompting is when you give detailed instructions of like the kind of response you're looking for and then you give it a new scenario and you say I want a response like this. So an example would be if you wanted to let's say revise your emails, you know, you have a rough draft of an email and you're like I want a final draft of this. If you just provide that email and say revise it, that's a zero shot prompt. You can include a lot more context. You can say look here's

Piyush (32:46)
interesting.

Nikhil Maddirala (33:02)
everything I want you to do to this email. I want you to make the tone friendly. I want you to improve the grammar. I want you to improve the vocabulary, whatever you want. But all of that, that's a more descriptive zero shot prompt. You can do all that. A few shot prompt would be if you actually gave it examples. If you say that here's a sample input and a sample output. So give it examples of like, here's a rough email and then here's like the corrected version of that email.

Piyush (33:09)
Right.

Nikhil Maddirala (33:31)
that I wanna see and give it like three or four such examples, that would help it understand much better how to do the specific task you wanna do. And again, I think this goes back to the case of like humans also. Imagine your manager gives you a task at work, but imagine they gave you some examples of like past work products that were good, that would enable you to like do a much better job because you actually know what exactly you're trying to do. You can see examples of it. So.

Piyush (33:42)
Wow.

Nikhil Maddirala (34:00)
in the same way with LLMs. So if you're asking an open -ended question, then you don't know the answer you're expecting, so this doesn't work there. But if you know the structure of the answer you're expecting, like in some of the cases we discussed, like getting summaries, getting revised emails, or like if I'm asking for some analysis and I want it in a particular format, generating ideas for podcasts or anything like that, always give it.

as many examples as you can. I mean, not as many as you can, but like give it at least three or four.

Piyush (34:31)
That's so interesting. I mean, that's wow. So what I've just realized now, even though I've used these LLMs for so long, is I've always done zero -shot prompting. Actually, most of the time, and I don't know if there's a name for it, what would you call something which is not even as descriptive in its zero -shot as you described? Sometimes I'm so lazy, I will just say, here's a draft of an email, make it better.

without defining what better even is. So I feel like maybe zero minus one is what I have been doing most of the time. But sometimes when I'm not that lazy, I'll be like, okay, here's an email. Can you please make this more clear, concise, professional, and make it so that the action items are very clear? So I guess that's still zero shot. And I didn't even think of the, what is it again? Few shot where you, example, so this is.

Nikhil Maddirala (35:21)
few shot prompting where you give examples.

Piyush (35:25)
draft of an email that I first thought of and here's the actual output that I really like right and then now take my actual draft from now and then try and create an idealized version based on the example that I get wow that's interesting man is there a way to automate this

Nikhil Maddirala (35:29)
Here's the ideal output,

Yeah, I think I used this... Sorry.

Yeah, I think it's actually not that hard to automate it. And that's what you can do with custom GPTs actually. So we'll talk about that next, but yeah, part of the problem is that the tools we have right now make it really difficult. So, cause when you open up chat GPT, the default interfaces, every time you press a new chat and this new chat has no context of what you previously discussed. Now they introduced a new feature called memory where it does remember some key things, but it's still very,

Ideally, I would want it to behave like if I had an actual human assistant, they're like, okay, once I've given you some sets of instructions for previous tasks, you understand what kind of output I'm looking for and you can infer that. But right now we're not there yet. The general purpose AI tools don't have that capability. If you want to do that, yeah, actually let's go to the next thing, which is the custom GPTs. So you can easily...

Piyush (36:40)
Hmm.

Nikhil Maddirala (36:41)
accomplish this by creating what's called a custom GPT. And I think this is probably the most advanced thing you can do if you don't want to get into any coding, but it already gets you pretty far. So just to recap, like we talked about how to get started with using AI and we said, okay, first identify what are the use cases for you. Look for things that are text -based, like you said, things that are frustrating, repeatable.

And then we talked about how to actually do that just using basic chat bots like chat GPT. And you can either do a zero shot prompt and just ask you what you want, or you can do this few shot prompting techniques where you give examples. And then one last thing is on that is to always engage in a conversation, which is that once you get the output from the chat bot, like if you follow up and correct it and say, hey, this is not what I'm looking for.

Piyush (37:35)
Yeah, that's a good tip.

Nikhil Maddirala (37:37)
I actually want something else. Usually I found that most of the times to get a productive output out of a chatbot session, it comes at the end of like a thread of four or five at least messages where we go back and forth. How's your experience been with that?

Piyush (37:55)
Yeah, I do a lot of back and forth. I'm curious, like, my back and forth is more like, this is very interesting. Can you unpack this idea further? It's not so much that can you refine the previous output. It's more... Right.

Nikhil Maddirala (38:03)
Hmm.

Okay, because these are two different use cases we're talking about. One is where you're kind of having an open ended conversation with it, trying to learn something. And the other is where I'm trying to get it to do a specific task for me. So yeah, I think in both of them, like,

Piyush (38:15)
Yeah.

Right.

Well, I think what I'm realizing now is I've just been so impressed with the outputs that I've been getting.

I didn't realize that there's a way to improve the output even further. So the thing is, I told you, right, most of my use cases are very tech space. And even with my very lazy zero -shot prompt, I'm so impressed. Maybe it's because I got the premium version. So that's the reason I pay for all of these, because you get the latest model, right? Like for example, with ChatGPD, you'll get access to GPT -4 or the latest version of GPT -4. With Gemini, you get access to Gemini Advanced. With Perplexity, you can get access to Cloud.

Nikhil Maddirala (38:43)
Mm -hmm.

Mm -hmm.

Mm -hmm.

Piyush (39:04)
three or opposite you don't have to pay entropic so maybe they thought honestly the output I've been getting with my very lazy zero short I just created this name by the way I don't know you know what I mean by very lazy right make it better that's my problem basically lazy prompting it's been so good I haven't had it well I mean maybe one or two instances like can you make it this or that but I've just been very happy but now I'm realizing there's so many more ways for me to get my output better in the first

Nikhil Maddirala (39:14)
Yeah, yeah, let's call it lazy prompting.

Piyush (39:33)
try itself or keep evolving it by doing a back and forth. So I mean that itself is a great tip I think for me as a user of these LLMs.

Nikhil Maddirala (39:40)
I think it also has to do with the fact that we're talking about slightly different use cases where there's one is like a task where I'm assigning it a task and I'm treating it as like an assistant. I'm like, I have in mind some kind of output that I'm looking for. And that's why I'm giving it more instructions and correcting it. The other type of use case, what you're referring to as more like as a thought partner or like as someone who you can learn from, in which case it doesn't really make sense to.

give much more detailed instructions or feedback because you're, you just actually don't even know what it is you're looking for.

Piyush (40:14)
No, I -

Well, in my use cases, it's mostly a task and the task maybe is a simple task where the task is here's an email. And now basically my emails are my chain of thought, my stream of consciousness. So what I do is like in this email, I wish to convey da da da da da da da without putting too much thought into it. And then I'll be like, Hey, make this better. And sometimes I'll add, make it more clear, concise. And it does, it's like, it's like that Larry Page code. It knows exactly what I'm trying to convey. And it

Nikhil Maddirala (40:19)
Okay. Mmm.

Mm -hmm.

Mm -hmm.

Mm -hmm.

Piyush (40:45)
It gives me exactly what I want, which is a more professional and a concise output. It's a task. I do use it as a thinking partner as well. But perhaps my tasks are just very simple tasks. Because they're core to...

Nikhil Maddirala (41:01)
Or perhaps you're not a perfectionist in the output you want and you're very accepting of whatever output you get. Like whereas I think maybe I'm more picky and I really have something in mind that like, okay, like I don't like this and I want it to. So I have a lot of specifications.

Piyush (41:08)
Possibly. Yeah. Yeah, that's true.

Actually, one of my life's biggest guiding philosophy is exactly what you said. It's don't let perfect be the enemy of good. So maybe there's something to that. I'm like, all right, this is great. Way better than what I had in mind.

Nikhil Maddirala (41:25)
Yeah. Yeah, for sure. But I think in some cases though, like, yeah, it just depends on the specific task and what is the type of output you need. So yeah, I think the key is to know when lazy prompting is okay and when you want to do something more structured.

Piyush (41:41)
Yeah.

Alright, so I think, so let's build on that. So...

There is a first, the simplest way to get started by using AI is to just get started with these general purpose tools like chat, GPD, Gemini and whatnot. Start by lazy prompting, but then there are other cool ways of doing it. So you can do a zero short prompt where you can give it more descriptive instructions, or you can do a few short prompt. The way you describe it is give it some examples of here's what the ideal output would look like and do this for this input, right? Then you mentioned something like,

Custom GPD. What is that? It sounds very cool, but I hope it's not...

Nikhil Maddirala (42:27)
Yeah, so a custom GPT is when you're going beyond just a basic chatbot and it's actually an agent. It can do more things than just respond to your message. So there are basically like three main features that a custom GPT gives you. One is you can give it custom instructions. So you can tell it. So let's take your example. Like you want it to refine your emails and.

Probably you have a specific pattern of usage where you dump in some raw ideas and you want to get an output that looks a certain way and that has maybe your tone or style of voice or something like that. So the way you're doing it right now is just every time you open a new chat prompt and you give it these instructions. And if you were giving it any of these custom instructions, you would have to keep putting them in every time. So instead, if you create a custom GPT,

I think it's just called a GPT, but the concept is like it's like an agent so you can think of it as like your assistant You can give it specific instructions so you can say hey you are an email writing GPT your job is to take emails that I give you in rough draft format and output very nice looking emails that have these

Piyush (43:47)
Wait, where are you doing this? Are you doing this in the prompt itself or is this somewhere outside of the prompt?

Nikhil Maddirala (43:51)
No, yeah, let's open this up. So this is called a custom GPT. Here, let me share my screen.

Piyush (43:57)
Is this a feature of chat GPD or?

Nikhil Maddirala (44:00)
Yeah, this is a feature. I mean, I don't know if it's a chat GPT feature or an open AI feature, but it is a feature. Sorry, give me one sec.

Piyush (44:16)
Because I've heard of, I mean, I've seen prompt templates before where the template starts by assigning the LLM a role.

Nikhil Maddirala (44:20)
right here.

Here we are. If you just go to chadgpt .com slash gpt's, here you are. So here you can see the gpt's that other people have created. So let's look at some examples of this. This one says write for me. And it says this writes tailored, engaging content with a focus on quality, relevance, and precise word count. So that's one example. Here are the ones for writing.

Piyush (44:48)
Hmm.

Nikhil Maddirala (44:51)
generator, text, video maker, productivity.

Piyush (44:55)
So help me understand what's happening here. When I click on using one of these things, are they basically just appending a prompt to the...

Nikhil Maddirala (45:06)
Yeah, so like I said, there's three components. There's a custom instruction is one component. The second component is a custom knowledge base optionally, and a third component is tool usage. So actually, let's just go on the right here and click the create button. So if we click create, it lets you create your own GPT. And there are two ways to do it. One is this default flow where you can chat with it to build it.

Piyush (45:30)
cool.

Nikhil Maddirala (45:34)
or you can go into this configure flow. Let's look at this configure flow first to understand what the components of this are. You can give it a name, a description, and here's where you put in your custom instructions. And here's a place where you can upload files. And also you can give it these capabilities or tools. So you can say, okay, this one is allowed to browse the web, it's allowed to generate images, it's allowed to do code interpretation.

So in this case, we probably don't need code and data analysis, but you can.

Piyush (46:07)
I have a great use case. Can we use a real life use case that I actually have? And can we, we don't have to build like a full fledged thing, but maybe using an example this way will help me understand better on what the capabilities are. So I, I, no, go ahead. What were you thinking?

Nikhil Maddirala (46:20)
Mm -hmm. Wait, can we just start? Okay, sorry, go ahead, actually.

No, no, you go ahead.

Piyush (46:27)
Okay, so the use case that I have because I work in sales, right? Like I have to, let's say if I get a new customer that I have to work with, I do a lot of research, right? Like I want to know more about the company, what are the products they sell, how do they make money, who the C -suite executives are, the CEO, CFO, CMO. So I will do a bunch of different types of Google searches. Could I build a custom GPT where basically all I would need to do is enter the name.

of the company and it would just the agent would do all of these things for me so it would

Nikhil Maddirala (47:01)
Let's try it out. So let's name this GPT. What do we want to call it? Like company research GPT. Okay. So the description is a GPT that researches companies. Okay. And then let's give it some instructions. So let's say you are a company research AI. Your job is to let's say take

Piyush (47:09)
Yeah. Yeah.

analyze.

Nikhil Maddirala (47:31)
Let's start with what it takes. Take a company or let's say the user will provide a company name as input. And then now let's define what's your, what's its job.

Piyush (47:43)
Yeah.

Let's keep it simple. So the job is one, to find out where the company is headquartered at. Let's start with something simple, right? Where the company is headquartered at.

Nikhil Maddirala (47:54)
Okay.

Piyush (47:58)
How big is it, meaning if it's a public company, find out how much revenue it has, what not, who's the CEO, what are the types of products they sell, and this one might be difficult, but I'm curious to see if it can do this. Can you figure out how the company makes money? What is the business model, basically?

Dude, if you can do that, that would be awesome. Like you would have actually solved a huge, and this thing meets all of the criteria that you mentioned. It's a repeatable thing that I have to do. It's a repeatable thing I have to do. I mean, I won't say it's annoying because I obviously have to do research, but it is some, it's time consuming, right? Like if I had a report which had all of these things, I would save hours.

Nikhil Maddirala (48:29)
Okay so let's try this. You're a company research AI... yeah.

But it's time consuming. Yeah. Yeah.

All right, so let's start with this. And just to be clear, we've currently given it a zero shot prompt. It would be better if we gave it a few shot prompt, but for the purpose of this podcast, let's just say that that would take a lot of time. And.

Piyush (48:57)
I don't even know what's happening. Where are you entering? Like what is this? What does it mean to enter these instructions? Are we... Okay.

Nikhil Maddirala (49:02)
It's just a custom prompt. So in chatbots these days, there are two types of prompts. There's what's called a system message and then a user message. So this is the system prompt. That means this will guide the entire chat session and it will keep this in mind when answering any questions you have. So it's just a way of customizing the experience. So just to be clear for people who I guess are listening to this and can't see the...

Piyush (49:17)
Okay.

cool.

Nikhil Maddirala (49:31)
the video that we're sharing. We just went to a chatgpt .com slash GPTs. That's where you find custom GPTs. We clicked the create button and we entered these custom instructions here. And we didn't even do anything else. Like you could upload files, you could give more examples and so on. But in this case, that is all we're doing. So, okay. So let's get, let's press, okay. You have to first press create and you can either share this.

with only yourself or with anyone with the link or you could put it on the GPT store and this is kind of like OpenAI's app store or they're trying to make it like that they haven't been very successful so far. For now let's just leave it with anyone with the link and I can share it with you as well. So let's save this GPT. Alright. Yeah, it is. So give me a company name.

Piyush (50:20)
Like is it ready to be used now?

Let's try and give it a simple one. So think of which is your favorite brand. Give it a... Yeah, let's do Apple.

Nikhil Maddirala (50:32)
I'll say apple.

Okay, so we just typed in the word Apple and now it's answered the four questions in the format that we gave it. It says, where are the company's headquarters? Yeah. So basically this saves you, you could have done this in a normal like chat GPT workflow where if you just like copied this instruction and put it in a chat prompt, it would have given you the same result.

Piyush (50:44)
wow, this is awesome. Dude, this is great.

Nikhil Maddirala (51:04)
But the advantage is you don't have to repeat that step every time now. Every time you go into it, you just type in a company name and it gives you this. So.

Piyush (51:14)
So that's why I pay $20 for Perplexity. Actually, that's how I use Perplexity. So I have a prompt template where I'm like, all right. But what I do is every time I have to replace the name of the company, which for some reason I use it four times in the template. So I'm like Control -F, replace the name, copy it, paste it in Perplexity, run it. But this is so simple. Now that we have it, all I had to do was just add Apple. And now.

Nikhil Maddirala (51:20)
Hmm.

Mm -hmm.

Piyush (51:40)
Do you think there's a way to scale it even further? Meaning, could I add a bunch of names in a spreadsheet and execute a custom GPT on all the rows? You know what I mean? So like a spreadsheet with 20 rows with 20 different company names and basically the custom GPT takes the spreadsheet as an input.

Nikhil Maddirala (52:03)
This would be extremely easy to do via the API. I'm not sure if you can do that via UI. I don't think you can. Actually, I was hoping that in this episode, we could also get into advanced use cases of what you can do with the API versus the UI. But I think since we're almost at the end of the hour, let's just wrap this up. And that can be a good topic for next time or for a future episode. But this is pretty sophisticated already for what you can do as someone who doesn't know.

Piyush (52:12)
Okay.

Yeah.

Nikhil Maddirala (52:32)
anything about APIs or programming. And so he, yeah.

Piyush (52:35)
What are you talking about? This is fantastic! You undersell things, man! This is... No, you literally saved me hours, because... This is amazing, I'm gonna use it now. I didn't even know that this option existed, and this is...

Nikhil Maddirala (52:46)
So I think everyone should do this. And I was actually thinking about your email writing GPT. So you could make an email editor GPT, give it instructions for how it should edit emails for you. And you could even give it a few shot examples like we discussed. And you could also upload files that could be examples of like previous emails that you've written that you were happy with.

So yeah, there are many things you could do. You could also upload files for it to use as a knowledge base. Like suppose a task that you're often doing is reading a textbook and finding some information in it and trying to understand that textbook. You could instead upload a textbook here. Let's say you have, I don't know, an economics textbook. You upload it and you make an economics expert GPT. Suppose you're a student.

And then you say, look, you're an economics expert GPT. Your role is to read and understand this book and help me understand the content within it. And then I come and ask you questions about concepts in the book. So there are a lot of things you can do with it. So again, if we go back here, let's see the types of examples people have. So.

Piyush (53:57)
Do you have any custom GPDs that you use often? Do you have any favorites in the list?

Nikhil Maddirala (54:02)
I made one for the podcasting. I made it myself. So I for this podcast that we're doing. Yeah, so in.

Piyush (54:06)
Really? Sure.

What does it do? You don't have to show it. What does it do?

Nikhil Maddirala (54:13)
Here is a podcast show notes generator. Let's go to the editing flow. So it says, you're a podcast show notes generating AI for a podcast titled, The Art and Science of AI. And I gave it the description of our podcast. And then I said, the user will provide subtitles for the podcast episode. Please carefully review the subtitles to understand the content and the flow of the episode from beginning to end, then generate show notes for the episode.

including the following. Titles, descriptions, chapters and time stamps. And I gave it detailed instructions for each.

Piyush (54:49)
This is so great. This is so impressive. Yeah, I mean, this is perfect because you're using exactly what we talked about for the podcast. It's kind of like a meta self -referential thing going on. But this is awesome. I'm going to definitely use that custom GPD that you made. I'm going to change the instructions a little bit, make it more robust. This is such a great tip.

Nikhil Maddirala (54:56)
And then it generates, it finds the references.

Yeah, so

Mm -hmm. Yeah. And think of, so this is perfect for anything that's repeatable. So using the general chatbot interface is fine for like one -off things, but if you find that you are doing something again and again, the same kind of task, then it's really good to make a custom GPT for that and give it your custom instructions. And over time, just if you go back through your conversation history with that GPT,

Piyush (55:23)
Right.

Nikhil Maddirala (55:39)
you can easily create a few shot example because just look at in the past at outputs it's given you that you're happy with, copy those outputs and put it back into the instructions and then you get the exact quality that you're looking for.

Piyush (55:49)
That's a great idea.

Actually, that's a great idea. I'm going to do that, actually. I'm going to go through my history and find, well, do you have a best practice of how many examples?

Nikhil Maddirala (56:04)
So I actually wanted to talk about one last thing which actually touches upon this topic. It's called chain of thought prompting. It's a way to use a few shot examples in a structured way to get even better results. So usually you need about three or four examples. I think that's good enough to get start with, but like the way in which you provide the instructions really matters a lot. So here's.

An example of like standard prompting. So this is a, this is a standard few shot example. So as the input, I give it an example of one question and answer. In this case, they're trying to answer mathematical questions. It says Roger has five tennis balls. He buys two more. Each can has three tennis balls. How many does he have now? And it gives an answer. And then you ask another question and then you ask for the answer.

Piyush (56:47)
Hmm.

Nikhil Maddirala (57:00)
In this case, it got it wrong because it's actually pretty complex what's going on here. It has to figure out how many cans, how many balls in each can. But in general, this is what a few shot prompt looks like. So in the input, you provide at least one example of a prompt and a response, and then you just provide the prompt and ask it for the response. So this is, I would call this a one shot prompt because it has one example.

Two or three is a good number to start with. I think that gets you pretty good results. But what's interesting here is this thing called chain of thought prompting, which is they are teaching the LLM to think out loud. You know, like when kids are doing math, you always tell them to show their work, like write down everything they're doing. So that's exactly what we're training it to do here. So in the example that we gave in the answer, we provide...

Piyush (57:30)
Okay.

Right. Right.

Nikhil Maddirala (57:56)
a response that actually talks out loud about the answer. So it works through the thinking. It says, Roger, actually, let me explain the question. It says Roger has five tennis balls. He buys two more cans of tennis balls. Each can has three tennis balls. How many does he have now? So, and then in the explanation we say he started with five balls, then two cans of three tennis balls each is six tennis balls.

So 5 plus 6 equals 11 and the answer is 11. So you're training it to think out loud and then you see when you ask it this complex question, the answer it gives is it's trained to think out loud. So it gives this thinking out loud answer. And for LLMs, thinking out loud is what makes their responses better. The more like reasoning they can produce like on the page, the better their quality of the response will be. That's why

if you're just training it to give you concise answers, like here's the answer, it'll often result in something wrong. But when you give it detailed instructions like this, you will get a much better answer. So let's think about how we can apply this to your company research example.

Piyush (58:51)
Interesting.

This is very cool. No, before we go there, this is so cool because when you first showed this to me, I was thinking...

that the chain of thought prompting, what you're trying to do it is you're trying to get a better, more verbose answer from the model to help explain like how it arrived at the answer. But not only does it do that, in addition, it also increases the probability that the model will arrive at the right answer. So that's the insightful thing is. So in this example, let's say in the standard prompting, it got the correct answer, 23.

Nikhil Maddirala (59:35)
Yes.

Mm -hmm.

Piyush (59:44)
Even then, this approach of chain of thought prompting is a great approach because you're not producing a richer answer, right? Like, hey, in the earlier example, the answer is 23, versus in this example, it's 23 because da -da -da -da -da, here's the train of thought. But what's interesting is not only is it a better output, but it's also a more accurate output. Well, in case of math, it's accurate or not, but this is so insi - Why does this happen? I'm so curious.

Nikhil Maddirala (1:00:09)
And the reason, okay, the reason it happens is because the more the LLM thinks out loud, the better it is at reasoning. In fact, let me show you, okay, here. Here's, Jeremy Howard is one of my favorite AI educators, like even before the days of LLMs, like.

Piyush (1:00:18)
But why? Like, help me understand the signs of it.

Yeah, you mentioned him in our three long marathon.

Nikhil Maddirala (1:00:32)
Yeah, he's been really passionate about educating people in AI. So he made this post on Twitter a couple of months ago, or it's been almost a year maybe, yeah, August, 2023. And I've been following it ever since. So this is his set of custom instructions that he gives to ChatGPT. And let's read it out. It says, you are an autoregressive language model that has been fine -tuned with instruction tuning and RLHF.

Piyush (1:00:59)
Hehehehehe

Nikhil Maddirala (1:00:59)
You carefully provide accurate, factual, thoughtful, nuanced answers and are brilliant at reasoning. If you think there might not be a correct answer, you say no. Since you are autoregressive, each token you produce is another opportunity to use computation. Therefore, you always spend a few sentences explaining background context, assumptions, and step -by -step thinking before you try to answer the question. So,

Piyush (1:01:26)
Wow.

Nikhil Maddirala (1:01:26)
That contains both the explanation and the solution. The explanation is this, that's how autoregressive models work. The more tokens they produce, the more computation they're doing, and the more background and context they can think through, the more likely they are to come to a correct answer. So.

Piyush (1:01:46)
Are they also... wait, so... You explain to me how it's basically a next token prediction model, right? So, by doing this train of thought, is it also making the prediction of the next token better if you have the train of thought embedded? Okay.

Nikhil Maddirala (1:01:56)
Yes.

Yes, absolutely, because the chain of thought, otherwise the question and the answer, they're not as closely connected, right? So you're trying to bridge the gap more and more and go through the step -by -step reasoning. So one takeaway for you is, or for anyone who's listening, go copy paste this instruction into your custom GPT, or into your default chat GPT instructions. Your responses will be a whole lot more accurate, I think.

Piyush (1:02:14)
Hmm interesting Wow

This is good life advice as well, I feel like. This could be, like I should be teaching this to my daughter when she grows up. It's like, this is how you should be in life is, well, not with all of this technical language like autoregressive, but the fact that be as accurate, factual, thoughtful, and nuanced as possible, be a good reasoner. And if you think you don't know the correct answer to something, just say so, it's okay. Like, you know what I'm trying to say? This is like good advice in general for people to communicate.

Nikhil Maddirala (1:02:39)
Yeah.

I

Yeah, I agree. And it's great for LLMs. And yeah, and the thing is, like, often, like, sometimes all I want is, like, the answer to the question. But I want to know that it's the answer is the result of a careful process of reasoning. So think about at work when I am a product manager at a large tech company at Metta, right? Like, often,

Piyush (1:03:01)
Wow.

Nikhil Maddirala (1:03:25)
I'm trying to communicate with high level executives and convince them to do something. So when I'm communicating with them, they want it to be like very succinct because they don't have time to read like, you know, the entire analysis. So one thing that we always emphasize that meta is you have to put a TLDR at the top of your document. So which summarizes in one line what it is you're saying if someone just doesn't read the entire document, but.

Imagine if you were just writing the TLDR. You can't do that until you've write the entire document. So the entire document is the background and context for the final TLDR that I produced. And at the end, the VP or executive who I'm sending this to may just read the TLDR, but they wouldn't trust it unless they know that like I've gone through this whole process. So it's the same thing here. Like you wanna make sure that it's gone through that entire process.

Piyush (1:04:02)
Yeah.

Yeah.

Tell me the truth, do you have a custom GPT called TLDR where you add stuff to it and it produces the TLDR? You do, don't you?

Nikhil Maddirala (1:04:26)
Well, not GPT for it, but internally we have a tool called MetaMate at Meta and we also have these capabilities like custom GPTs internally. It's really cool. I have a couple of those.

Piyush (1:04:40)
Interesting. This is so cool. I'm gonna share this with me because it looks like this is an image I'm not on any social media. I'm not on Twitter, but share this snippet with me. I want to append this to literally every single template I use

Nikhil Maddirala (1:04:51)
Yeah, let's definitely include this in our show notes as well so that everyone has it. Yeah, for sure.

Piyush (1:04:57)
Yeah, this is awesome. I learned so much today and I feel like I've been like I'm like I have owned a Ferrari all this while and I've been only going to a max of 40 miles per hour and it can do so much more.

Nikhil Maddirala (1:05:13)
Hmm. That's interesting. I think like, cause I remember when we were talking about this episode, so I wrote this outline for the episode and then you were a bit concerned that, hey, maybe this would be like too much of like beginner content. And I guess like, that's not the case. Like, because like, cause we thought about, I wanted to cover this and then talk about API stuff. Actually, I thought in this episode we could get into.

how can you use AI APIs to build things like retrieval augmented generation apps and stuff. And I think we thought let's quickly go into that because this topic might be too boring or low level, but it's really interesting that just so much stuff has come out of it.

Piyush (1:05:56)
Yeah, what you're saying, that's true. That's what I was thinking as well. Have you heard of this thing called the Dunning -Kruger effect?

Nikhil Maddirala (1:06:03)
Mm -hmm, yeah.

Piyush (1:06:05)
I think this whole series will be a realization that I'm on Mount Stupid and this is a great example of that. So for people who don't know, Donnie Krueger, there are two scientists who basically came up with this phenomenon where someone who doesn't know much about a subject and is confident, and that would be me in this case, thinks that they know everything about the subject and is very confident about it. And someone, and this would be you, who knows a lot about the subject,

Nikhil Maddirala (1:06:12)
Well, but -

Piyush (1:06:35)
knows how much they don't know about that subject. So I think when I assume that, well if you just talk about prompts and all, that might be too basic, I've been using this for a year, so I wrongly assume that I know everything about prompts, what are you talking about, I pay 60 bucks. There isn't anything I don't know about prompts. And I, like everything, I mean, yeah, I mean.

Nikhil Maddirala (1:06:42)
I'm out.

Hehehehe

Piyush (1:06:55)
Yeah, everything today was new and insightful for me. So, admittedly, I'm on Mount Stupit right now, but it's so exciting. I love being there. So I'm so happy that I've discovered that I'm on.

Nikhil Maddirala (1:07:04)
That's the first step of like, yeah, learning is figuring out the things you don't know. I also love getting there. I'm probably on that with a different part of it, like around API usage and stuff.

Piyush (1:07:09)
Yeah.

You're probably in the valley of despair if you're using the Dunning -Kruger methodology, but I love it. I've just realized I'm on Mount Stupid. So I want to...

Nikhil Maddirala (1:07:23)
Well, but also think about the fact that like you actually are like way more advanced at using AI than probably like 50 % of the world. Like how many, like I think 50 % of the world is not even doing basic things like putting their emails into.

Piyush (1:07:37)
About an hour back I thought so but maybe not anymore.

Nikhil Maddirala (1:07:41)
no, I mean this is like I'm Work at meta in AI. I follow a bunch of like nerds who love to optimize the hell out of Tiny things they're doing so I I don't think the average person is really doing Even as much as like what you're doing like I mean I think about for example my parents or Relatives that I have were not like older people who are not super who don't work in tech who are not very

into the latest like tech and tools. Yeah, I think they're probably not using it and I would love for more people to start like seeing the power of what they can get out of it and just start doing some basic things and then, you know, if you want get into this. Because it's like what I was saying in the beginning of the episode earlier, like a few years ago, this stuff was only limited to people who had

programming knowledge and I mean of course anyone can go and get programming knowledge But it's a huge barrier to entry and now you have the power to like create your it's like you're building your own app But without any programming it's like a really cool. No code like app or automation solution. Yeah

Piyush (1:08:52)
Yeah, very interesting. You decided to call this episode from zero to hero. I wonder if there's a pun here with the zero and the zero shot. That's... Yeah, that's... Yeah.

Nikhil Maddirala (1:09:01)
Yeah, possibly. And we only got through half of what I wanted to cover because the hero part was supposed to cover what you can do when you use the API. But.

Piyush (1:09:12)
What are you talking about? This is hero for me. I think I'm, yeah, I love this already. So I'm so interested in learning more about the API aspect and how I was talking about, can we automate it further? Can I give you like a list of 20 or 200 company names? And you said that APIs can help achieve that. And I've always been curious, like how does API work in the context of LLMs? So let's talk about that next.

Nikhil Maddirala (1:09:21)
Hmm.

Okay, let's do one thing. Let's talk about that next, but why don't you chat with me before the next episode, send me some basic requirements you have, and I'll try to code up like a basic version of doing that with the API and we can demo that in. I'm not sure if we'll cover it in the next episode.

Piyush (1:09:48)
Well, actually, let's do this. Let's use the same example. So let's do this. So right now you entered Apple and it gave you that thing. So can you come up with a solution, a very simple solution, where I will give you a simple spreadsheet with a few company names and the output should be this little snippet about the company and all of these things that we had for each one of those inputs, basically. So it should be...

Nikhil Maddirala (1:09:54)
Mm -hmm.

Mm -hmm. Okay, let's do it. That will literally take like 10 minutes to do. And let's do it in the next episode. We can give a live demo.

Piyush (1:10:18)
Yeah, for you.

But it might take longer for you to explain how you did it because I'm on Mount Stupid, remember? So it might take you 10 minutes to do it. But I'm just, yeah, I want to know more about this. I'm just so interested now. And I'm even more motivated now to learn more because I mean, this is not just satisfying my curiosity, which was the original intention of this podcast for me or the motivation for me. But you actually like made me more productive at my work by introducing me to this concept. So I'm like, I'm really hopeful that whoever

Nikhil Maddirala (1:10:25)
Hahaha.

For sure, let's do that in the next episode.

Piyush (1:10:50)
ever listens to this, if anyone ever listens to this, also find something that can make them more productive.

Nikhil Maddirala (1:10:55)
yeah, and let's ask, what do we want to hear from our listeners? Like if, for people who are listening to this, I'm really curious if you want to reach out to us, let me know what are, or let us know what are you currently using AI for? What do you wish you could do with it that you're currently not able to do? Yeah, those are my two questions. Do you have any questions that you'd like to hear from our listeners?

Piyush (1:11:18)
Well, it just I would love to know if they also uncovered some new insight from this podcast and what was that insight like how did they better their lives Change their lives using some of the insights that we've shared in this episode and I mean that's generally what I would want to know for every episode is like Hopefully we produce something where people can I don't know use the art and science of AI and improve their lives a little bit

Nikhil Maddirala (1:11:41)
Yeah.

That's my whole goal. Understand the science of AI and the science of how AI works and the art of how you can use AI to change your life, change the world, change your business, like affect whatever kind of transformation you want. That's the power of AI. So yeah.

Piyush (1:12:03)
And like you said in the first episode, there is some beauty to that. So I think that's a great place to end. Yeah, that's very well said. All right.

Nikhil Maddirala (1:12:06)
Ahem.

Alright, well, see you everyone in the next episode. That's a wrap.

